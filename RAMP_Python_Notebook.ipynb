{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNnUXc3UsHy/reUuCwdF2BJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alexiamhe93/RAMP_method/blob/main/RAMP_Python_Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The Recursive Adjustment of Measurement Protocols (RAMP) method: Case study code for replication\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "The notebook was designed using Google Colab on an Nvidia T4 GPU (free with log-in). The code works locally but all dependencies from the \"Load packages\" will have to be installed.\n",
        "\n",
        "This Python notebook is used to replicate the results of the paper titled:\n",
        "\n",
        "\"Recursive Adjustment of Measurement Protocols (RAMP) method for developing high-validity text classifiers\"\n",
        "\n",
        "The notebook is structured in terms of the RAMP stages:\n",
        "0. Install and load data / model for analysis\n",
        "\n",
        "1. Manual coding stage. This notebook runs inter-rater reliability statistics on the final shared subset of data.\n",
        "\n",
        "2. Computation stage. Uses the coded dataset to develop three different text classifiers (rule-based, supervised machine learning, LLM few-shot).\n",
        "\n",
        "3. Evaluation stage: Identify and evaluate surprises and outliers in classifier development, with the goal of identifying construct and content validity issues. The code for this section prints the manual coding disagreements and classifiers.\n",
        "\n",
        "> Each stage is structured in three phases, an input (defines the parameters), a throughput (development stage), and an output (final validation).\n",
        "____________________________\n",
        "\n",
        "The notebook applies RAMP to a case study on measuring misunderstandings in online dialogue data.\n"
      ],
      "metadata": {
        "id": "Ht0MhYw8ggZq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0. Initiate notebook\n",
        "\n",
        "This section installs all the necessary Python packages to complete these analysis. We also download the data and pre-trained BERT model for replicating the results.\n",
        "\n",
        "The rule-based classifier\n",
        "\n",
        "--------------------\n",
        "A few packages require mention as they are non-standard:\n",
        "\n",
        "> spacy ([Honnibal et al., 2022](https://github.com/explosion/spaCy)).\n",
        "\n",
        "This package is used for creating a rule-based dictionary classifier, similar to LIWC ([Pennebaker et al., 2001](http://downloads.liwc.net.s3.amazonaws.com/LIWC2015_OperatorManual.pdf)). This\n",
        "\n",
        "> ktrain ([Maiya, 2022](https://github.com/amaiya/ktrain)).\n",
        "\n",
        "This package is a Keras wrapper for streamlining many tasks related to fine-tuning and deploying deep learning models. In this notebook we use it to fine-tune Google's BERT ([Devlin et al., 2019](https://arxiv.org/abs/1810.04805)) base model.\n",
        "\n",
        "> eli5 ([Korobov, 2017](https://av.tib.eu/media/33771);[Korobov & Lopuhin, 2024](https://github.com/eli5-org/eli5)).\n",
        "\n",
        "\"Explain like I'm five\" is a package used for running the LIME ([Ribeiro et al., 2016](http://arxiv.org/abs/1602.04938)) algorithm to examine how a supervised classifier is making its predictions.\n",
        "\n",
        "> openai ([OpenAI et al., 2024](https://platform.openai.com/docs/api-reference/introduction\n",
        " )).\n",
        "\n",
        "This package accesses the OpenAI API for using GPT-4o within the notebook.\n",
        "\n",
        "> textstat ([Shivan & Chaitanya, 2024](https://pypi.org/project/textstat/)).\n",
        "\n",
        "This package calculates simple statistical information relating to raw text data.\n"
      ],
      "metadata": {
        "id": "0NK-mCzVj-K0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0.1 Install and load packages"
      ],
      "metadata": {
        "id": "l1uWzkOxkBaG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tf-keras\n",
        "import os\n",
        "os.environ['TF_USE_LEGACY_KERAS'] = '1'"
      ],
      "metadata": {
        "id": "gSL_QCLYXKXO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3xHt9VHlgZMO",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# For Supervised classifier\n",
        "!pip install ktrain\n",
        "# For revealing under the classifier black box\n",
        "!pip install https://github.com/amaiya/eli5-tf/archive/refs/heads/master.zip\n",
        "# For LLM classifier\n",
        "!pip install openai\n",
        "# For summary statistics\n",
        "!pip install textstat\n",
        "# This is a port from Gwet's R package with the same name\n",
        "!pip install irrCAC"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# General use packages\n",
        "import requests, zipfile, io, os, psutil, random, time\n",
        "import torch\n",
        "import pandas as pd\n",
        "# This deactivates a warning from Pandas that frequently prints\n",
        "pd.options.mode.chained_assignment = None  # default='warn'\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "from tqdm import tqdm\n",
        "# For descriptive statistics\n",
        "from textstat.textstat import textstatistics\n",
        "import re\n",
        "# Performance evaluations for binary classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report, precision_recall_curve, auc, roc_auc_score, matthews_corrcoef\n",
        "# For calculating inter-rater reliability\n",
        "from irrCAC.raw import CAC\n",
        "#for troubleshooting\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from wordcloud import WordCloud\n",
        "from nltk import agreement\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "# Plotting\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams['figure.dpi'] = 120"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KJGGvaNX8hPy",
        "outputId": "02564e4c-e8d1-4f66-8045-ea0dcc03683d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for rule-based classification\n",
        "import spacy\n",
        "from spacy.matcher import Matcher\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "metadata": {
        "id": "wViVC6AFS19y"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for supervised classification\n",
        "import ktrain\n",
        "from ktrain import text\n",
        "# for LLM classification\n",
        "import openai"
      ],
      "metadata": {
        "id": "_BQVFG7MKqJi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check system GPU (recommended if possible)\n",
        "# CPU cores\n",
        "num_cpu_cores = os.cpu_count()\n",
        "print(f\"Number of CPU cores: {num_cpu_cores}\")\n",
        "# GPU details\n",
        "if torch.cuda.is_available():\n",
        "    gpu_name = torch.cuda.get_device_name(0)\n",
        "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / (1024 ** 3)  # in GB\n",
        "    print(f\"GPU Name: {gpu_name}\")\n",
        "    print(f\"GPU Memory: {gpu_memory:.2f} GB\")\n",
        "else:\n",
        "    print(\"No GPU available.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mT0gjhlD8lsl",
        "outputId": "d0e2b5e9-d105-4b40-928b-fe51f8ce0df8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of CPU cores: 2\n",
            "No GPU available.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load in openai keys for few-shot classifier\n",
        "oai_k = \"your-API-key-here\"\n",
        "openai.organization = \"your-organization-key-here\" #if applicable\n",
        "openai.api_key = oai_k\n",
        "os.environ['OPENAI_API_KEY'] = oai_k"
      ],
      "metadata": {
        "id": "ifDAz7zT9Co3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0.2 Download data and pre-trained BERT model\n",
        "\n",
        "All the data for replication (<50mb) is accessed through a GitHub link and the pre-trained BERT model (1.03GB) from dropbox"
      ],
      "metadata": {
        "id": "9NbRD_KokEAA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download data from GitHub"
      ],
      "metadata": {
        "id": "fUH0ETcp-P6p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download empirical data\n",
        "r = requests.get('https://github.com/alexiamhe93/RAMP_method/blob/main/Dataset/data.zip?raw=true')\n",
        "z = zipfile.ZipFile(io.BytesIO(r.content))\n",
        "z.extractall()\n",
        "\n",
        "# Load train (70%) and test (30%)\n",
        "try:\n",
        "  train = pd.read_csv(\"data/Train.csv\")\n",
        "  validation = pd.read_csv(\"data/Validation.csv\")\n",
        "  St1Through = pd.read_csv(\"data/RAMP_Stage1.csv\")\n",
        "  St2Through = pd.read_csv(\"data/RAMP_Stage2.csv\")\n",
        "  out = pd.read_csv(\"data/RAMP_Stage3.csv\")\n",
        "except:\n",
        "  train = pd.read_csv(\"Train.csv\")\n",
        "  validation = pd.read_csv(\"Validation.csv\")\n",
        "  St1Through = pd.read_csv(\"RAMP_Stage1.csv\")\n",
        "  St2Through = pd.read_csv(\"RAMP_Stage2.csv\")\n",
        "  out = pd.read_csv(\"RAMP_Stage3.csv\")"
      ],
      "metadata": {
        "id": "nTn-uqu8kIS4"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Validation n before cleaning: {len(validation)} texts\")\n",
        "# Delete any duplicates\n",
        "validation = validation.dropna(subset=[\"text\"])\n",
        "validation = validation.drop_duplicates(subset=\"text\")\n",
        "print(f\"Validation n after cleaning: {len(validation)} texts\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--VnA5j2IhmM",
        "outputId": "ad02afd2-8ed1-4690-fdb1-58515be6ca86"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation n before cleaning: 6599 texts\n",
            "Validation n after cleaning: 6420 texts\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We removed 179 sentences that are duplicates or empty values."
      ],
      "metadata": {
        "id": "wWk0GcaOJP7I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download model from Dropbox (can take some time if internet is slow - aprox 1.1GB - downloads weights and pre-processing)"
      ],
      "metadata": {
        "id": "3GFOZlP3-Eg-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O supervised_model.zip https://www.dropbox.com/scl/fi/5wtuor1ag1gktg6eukqwr/supervised_model.zip?rlkey=nfwxyataobjzt708m3gf27o3s&st=cz5r9lq0&dl=0 --quiet\n",
        "!unzip supervised_model.zip"
      ],
      "metadata": {
        "id": "i6URMHD9-GOY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0.3 Load classes and functios\n",
        "\n",
        "The notebook uses two class objects for performing most of the operations across the three stages of RAMP. The classifier object is used to calculate inter-rater reliability (manual coding); run a dictionary word classifier (computation), a supervised classifier (computation) and an LLM classifier (computation); calculate accuracy metrics (computation); access disagreements and misclassifications (evaluation)."
      ],
      "metadata": {
        "id": "BHYCi1z_kFl3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Classifier object and functions\n",
        "\n",
        "This class does the heavy lifting for the notebook. It integrates the three types of classifier (rule-based, supervised, LLM) into one function so that there is a common language across the examples.\n",
        "\n",
        "The classifier produces a development report, including the following variables:\n",
        "\n",
        "1. `TP`,`TN`,`FP`,`FN`: number of true positives, true negatives, false positives, and false negatives\n",
        "2. `Precision`: TP/TP+FP - ratio of true positives to all predicted positive class. Reported for positive class only.\n",
        "3. `Recall`: TP/TP+FN – ratio of true positives to all true positive class.Reported for positive class only.\n",
        "4. `F1_avg`: Weighted harmonic mean of precision and recall (all classes - this F1 is not the precision and recall reported).\n",
        "5. `F1_var`: Weighted harmonic mean of precision and recall for positive class.\n",
        "6. `AUC_ROC`: Area under the receiving operating characteristic (ROC) curve\n",
        "7. `AUC_PR`: Area under the precision and recall curve.\n",
        "8. `MCC`: Matthews Correlation Coefficient\n",
        "\n",
        "\n",
        "Each metric highlights a different aspect of the classifier's performance. For instance, the weighted F1 (`F1_avg`) is sensitive to imbalanced classes. For misunderstandings, the class is imbalanced (8% of turns are misunderstandings) so the MCC is more appropriate.\n",
        "\n",
        "The development report is geared at binary classification and alternative accuracy metrics should be sought for other methods."
      ],
      "metadata": {
        "id": "Os-aIAYQDBZq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Classifier:\n",
        "  def __init__(self, texts, true_scores):\n",
        "    \"\"\"\n",
        "    Initialize the Classifier class with texts and true scores.\n",
        "    \"\"\"\n",
        "    self.texts = texts\n",
        "    self.true_scores = true_scores\n",
        "    self.train_size = len(texts)\n",
        "    self.type_ = None\n",
        "    self.pred_scores = []\n",
        "    self.nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "  def add_pred_scores(self, pred_scores):\n",
        "    self.pred_scores = pred_scores\n",
        "  def get_pred_scores(self):\n",
        "    return self.pred_scores\n",
        "  def add_rule_based_terms(self, terms, pattern_type):\n",
        "    \"\"\"\n",
        "    Configure terms and pattern matching type for rule-based classifiers.\n",
        "    \"\"\"\n",
        "    self.terms = terms\n",
        "    if pattern_type == \"pattern\":\n",
        "        self.type_ = \"rule-based-1\"\n",
        "    elif pattern_type == \"lemma\":\n",
        "        self.type_ = \"rule-based-2\"\n",
        "    else:\n",
        "        raise ValueError(\"Invalid pattern type specified.\")\n",
        "  def classify_with_spacy_pattern(self):\n",
        "    \"\"\"\n",
        "    Classify texts using SpaCy's pattern matcher based on predefined terms.\n",
        "    \"\"\"\n",
        "    matcher = Matcher(self.nlp.vocab)\n",
        "    for term in self.terms:\n",
        "        matcher.add(term[\"label\"], [term[\"pattern\"]])\n",
        "    self.pred_scores = [bool(matcher(self.nlp(text))) for text in self.texts]\n",
        "  def classify_with_spacy_lemma(self):\n",
        "    \"\"\"\n",
        "    Classify texts by checking if any lemmas from the terms are in the texts.\n",
        "    \"\"\"\n",
        "    lemma_doc = self.nlp(\" \".join(self.terms))\n",
        "    lemma_set = set(token.lemma_ for token in lemma_doc)\n",
        "    self.pred_scores = [bool(set(token.lemma_ for token in self.nlp(text.lower())) & lemma_set) for text in self.texts]\n",
        "  def add_SML_classifier(self, predictor, **kwargs):\n",
        "    \"\"\"\n",
        "    Configure the supervised machine learning classifier with a predictor and training parameters.\n",
        "    \"\"\"\n",
        "    self.type_ = \"supervised\"\n",
        "    self.predictor = predictor\n",
        "    self.sml_params = kwargs\n",
        "    print(\"Supervised ML classifier configured with parameters:\", kwargs)\n",
        "  def classify_with_SML(self):\n",
        "    \"\"\"\n",
        "    Perform classification using the configured supervised machine learning predictor.\n",
        "    \"\"\"\n",
        "    preds = self.predictor.predict(self.texts)\n",
        "    self.pred_scores = [0 if \"not\" in pred.lower() else 1 for pred in preds]\n",
        "\n",
        "  def add_few_shot_classifier(self, GPTmodel, prompt, role):\n",
        "    \"\"\"\n",
        "    Configure the few-shot classifier with a GPT model, prompt template, and user/system roles.\n",
        "    \"\"\"\n",
        "    self.type_ = \"LLM\"\n",
        "    self.GPTmodel = GPTmodel\n",
        "    self.prompt = prompt\n",
        "    self.role = role\n",
        "    self.cost = 0\n",
        "    self.total_tokens = 0\n",
        "    self.LLMScores = []\n",
        "\n",
        "  def gptActualCost(self, response):\n",
        "    \"\"\"\n",
        "    Calculates the GPT cost for different models\n",
        "    \"\"\"\n",
        "    engine = self.GPTmodel\n",
        "    total_tokens=response.usage.total_tokens\n",
        "    total_tokens_1k_units = total_tokens/1000\n",
        "\n",
        "    if engine=='gpt-3.5-turbo':\n",
        "        cost=total_tokens_1k_units*0.0005\n",
        "    elif engine=='gpt-4-turbo':\n",
        "        cost=total_tokens_1k_units*0.01\n",
        "    elif engine=='gpt-4o':\n",
        "        cost=total_tokens_1k_units*0.005\n",
        "    elif engine=='gpt-4-32k':\n",
        "        cost=total_tokens_1k_units*0.12\n",
        "    else:\n",
        "        print('getCost error: engine not found')\n",
        "        return\n",
        "    return cost, total_tokens\n",
        "\n",
        "  def get_llm_response(self,messages,temperature=0, max_tokens = 100, max_attempts = 3):\n",
        "    '''\n",
        "    Function that takes messages format for ChatGPT input and returns the response text.\n",
        "    '''\n",
        "    GPTmodel = self.GPTmodel\n",
        "    for attempt in range(0, max_attempts):\n",
        "      try:\n",
        "        #. request timeout ADD IN\n",
        "        response = openai.chat.completions.create(model=GPTmodel, messages = messages, temperature=temperature, max_tokens=max_tokens)\n",
        "        response_text = response.choices[0].message.content\n",
        "        self.LLMScores.append(response_text)\n",
        "        response_cost, token_count = self.gptActualCost(response)\n",
        "        self.cost += response_cost\n",
        "        self.total_tokens += token_count\n",
        "        break  # If analysis was successful, break out of the retry loop\n",
        "      except Exception as e:\n",
        "        print(f\"Error processing text on attempt {attempt+1}: {e}\")\n",
        "        if attempt + 1 == max_attempts:\n",
        "          print(f\"Skipping text after {max_attempts} failed attempts.\")\n",
        "          response_text\n",
        "    return response_text\n",
        "  def define_messages(self, text_to_classify):\n",
        "    '''\n",
        "    Function for creating a basic messages format from a prompt, a role, and a text to classify (all strings)\n",
        "    '''\n",
        "    prompt = self.prompt\n",
        "    role = self.role\n",
        "    prompt = prompt.format(text_to_classify)\n",
        "    messages = [{'role': 'system', 'content': role},\n",
        "                {'role': 'user', 'content' : prompt}]\n",
        "    return messages\n",
        "  def convert_llm_scores_binary(self, return_scores = False):\n",
        "    '''\n",
        "    Function for converting a string \"Yes\" or \"No\" into binary format - used for the clarification requests\n",
        "    '''\n",
        "    llm_scores = self.pred_scores\n",
        "    new_scores = []\n",
        "    for s in llm_scores:\n",
        "      if \"yes\" in s.lower():\n",
        "        new_scores.append(1)\n",
        "      else:\n",
        "        new_scores.append(0)\n",
        "    if not return_scores:\n",
        "      self.pred_scores = new_scores\n",
        "    else:\n",
        "      return new_scores\n",
        "\n",
        "  def classify_with_fewshot(self,  max_tokens = 100, max_attempts = 3, temperature = 0):\n",
        "    '''\n",
        "    Function for running a prompt over a series of texts (expects a list)\n",
        "    '''\n",
        "    prompt = self.prompt\n",
        "    role = self.role\n",
        "    input_texts = self.texts\n",
        "    GPTmodel = self.GPTmodel\n",
        "    scores = []\n",
        "    for txt in tqdm(input_texts):\n",
        "      message = self.define_messages(txt)\n",
        "      try:\n",
        "        response = self.get_llm_response(message,temperature=temperature,\n",
        "                                        max_tokens=max_tokens, max_attempts=max_attempts)\n",
        "      except:\n",
        "        response = \"Error in response\"\n",
        "      scores.append(response)\n",
        "    self.pred_scores = scores\n",
        "    self.convert_llm_scores_binary()\n",
        "\n",
        "  def run_classifier(self):\n",
        "    \"\"\"\n",
        "    Execute the classifier based on the configured type.\n",
        "    \"\"\"\n",
        "    if self.type_ == \"rule-based-1\":\n",
        "        self.classify_with_spacy_pattern()\n",
        "    elif self.type_ == \"rule-based-2\":\n",
        "        self.classify_with_spacy_lemma()\n",
        "    elif self.type_ == \"supervised\":\n",
        "        self.classify_with_SML()\n",
        "    elif self.type_ == \"LLM\":\n",
        "        self.classify_with_fewshot()\n",
        "        cost = self.cost\n",
        "        total_tokens = self.total_tokens\n",
        "        avg_tokens = self.total_tokens / self.train_size\n",
        "        print(f\"This run cost {cost:.2f}$ for {total_tokens} tokens. Average tokens: {avg_tokens:.2f}\")\n",
        "    else:\n",
        "        raise ValueError(\"Classifier type is not configured.\")\n",
        "\n",
        "  def get_model_report(self, display=True):\n",
        "    \"\"\"\n",
        "    Generate and display or return the classification report and metrics.\n",
        "    \"\"\"\n",
        "    # Generate confusion matrix\n",
        "    cm = confusion_matrix(self.true_scores, self.pred_scores)\n",
        "    # Generate classification report\n",
        "    report = classification_report(self.true_scores, self.pred_scores, output_dict=True)\n",
        "    # Precision-recall curve and AUC for precision-recall\n",
        "    precision, recall, thresholds = precision_recall_curve(self.true_scores, self.pred_scores)\n",
        "    auc_pr = auc(recall, precision)\n",
        "    # AUC for ROC curve\n",
        "    auc_roc = roc_auc_score(self.true_scores, self.pred_scores)\n",
        "    # Matthews Correlation Coefficient (MCC)\n",
        "    mcc = matthews_corrcoef(self.true_scores, self.pred_scores)\n",
        "\n",
        "    if display:\n",
        "        print(f'AUC-PR: {auc_pr:.2f}\\n')\n",
        "        print(f'AUC-ROC: {auc_roc:.2f}\\n')\n",
        "        print(f'MCC: {mcc:.2f}\\n')\n",
        "        print(classification_report(self.true_scores, self.pred_scores, output_dict=False))\n",
        "    else:\n",
        "        return {\n",
        "            \"precision\": report['1']['precision'],\n",
        "            \"recall\": report['1']['recall'],\n",
        "            \"auc_pr\": auc_pr,\n",
        "            \"auc_roc\": auc_roc,\n",
        "            \"mcc\": mcc,\n",
        "            \"f1_avg\": report['weighted avg']['f1-score'],\n",
        "            \"f1_var\": report['1']['f1-score']\n",
        "        }\n",
        "  def get_misclassification(self, return_all = False):\n",
        "    \"\"\"\n",
        "    Function to fetch misclassifications\n",
        "    \"\"\"\n",
        "    df = pd.DataFrame({\"text\":self.texts,\"true\":self.true_scores,\n",
        "                       \"pred\":self.pred_scores})\n",
        "    # Function to classify each row\n",
        "    def classify_row(row):\n",
        "      if row['true'] == 1 and row['pred'] == 1:\n",
        "        return 'TP'\n",
        "      elif row['true'] == 0 and row['pred'] == 1:\n",
        "        return 'FP'\n",
        "      elif row['true'] == 1 and row['pred'] == 0:\n",
        "        return 'FN'\n",
        "      elif row['true'] == 0 and row['pred'] == 0:\n",
        "        return 'TN'\n",
        "    df['Classification'] = df.apply(classify_row, axis=1)\n",
        "    if return_all:\n",
        "      return df\n",
        "    else:\n",
        "      return df[df[\"Classification\"].isin([\"FP\",\"FN\"])]\n",
        "\n",
        "  def preprocess_text(self, text):\n",
        "    \"\"\"\n",
        "    Function to process the texts.\n",
        "    \"\"\"\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    words = nltk.word_tokenize(text)\n",
        "    cleaned_text = [lemmatizer.lemmatize(word.lower()) for word in words if word.isalnum() and word.lower() not in stop_words]\n",
        "    return ' '.join(cleaned_text)\n",
        "\n",
        "  def plot_misclassifications(self, df, FN_FP=\"FN\"):\n",
        "    \"\"\"\n",
        "    Function to generate a wordcloud\n",
        "    \"\"\"\n",
        "    df['cleaned_text'] = df['text'].apply(self.preprocess_text)\n",
        "    if FN_FP == \"FN\":\n",
        "      print(\"Word Cloud for False Negatives:\")\n",
        "      texts = \" \".join(df[df['Classification'] == 'FN']['cleaned_text'])\n",
        "    else:\n",
        "      print(\"Word Cloud for False Positives:\")\n",
        "      texts = \" \".join(df[df['Classification'] == 'FP']['cleaned_text'])\n",
        "    wordcloud = WordCloud(width = 800, height = 400, background_color ='white').generate(texts)\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.imshow(wordcloud, interpolation='bilinear')\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "7_s_-YmtkItR"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The below class was used to develop the different classifiers. Example usage hashed out below the classifier."
      ],
      "metadata": {
        "id": "F1DcqS2vf3S6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import wandb\n",
        "#import ConfusionMatrixDisplay\n",
        "def display_confusion_matrix(human_labels, predicted_labels):\n",
        "  '''\n",
        "  Function for displaying a confusion matrix from results\n",
        "  '''\n",
        "  conf_mx = confusion_matrix(human_labels, predicted_labels)\n",
        "  disp = ConfusionMatrixDisplay(confusion_matrix=conf_mx)\n",
        "  disp.plot()\n",
        "\n",
        "\n",
        "class log_wandb:\n",
        "  \"\"\"\n",
        "  This class logs the classifier training/development runs to a wandb session.\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self,wandb_project):\n",
        "    run = wandb.init(project=wandb_project)\n",
        "    \"\"\"\n",
        "    wandb_project = ID str: name of the wandb project to initiate\n",
        "    \"\"\"\n",
        "\n",
        "  def add_KeyVariables(self,train_size,Precision,Recall,\n",
        "                       AUC_PR,AUC_ROC,F1_avg,F1_var,\n",
        "                       TP,TN,FP,FN,type_):\n",
        "\n",
        "    # variables for all classifier types\n",
        "    wandb.log({\"ClassiTypeStr\":type_,\n",
        "               \"train_size\":train_size,\n",
        "               \"F1_avg\":F1_avg,\n",
        "               \"F1_var\":F1_var,\n",
        "               \"AUC_PR\":AUC_PR,\n",
        "               \"AUC_ROC\":AUC_ROC,\n",
        "               \"Precision\":Precision,\n",
        "               \"Recall\":Recall,\n",
        "               \"TP\":TP,\n",
        "               \"TN\":TN,\n",
        "               \"FP\":FP,\n",
        "               \"FN\":FN})\n",
        "\n",
        "  def add_ClassVars(self,Terms = None, nTerms=None,PatternOrLemma=None,BERTmodel=None,\n",
        "                    validation_size=None,learning_rate=None,epochs=None,batch_size=None,\n",
        "                    GPTmodel=None,role=None,prompt=None,examples=None,nExamples=None,\n",
        "                    balance_ratio=None):\n",
        "    # Specific vars to a classifier type\n",
        "    wandb.log({\"Terms\":Terms, \"nTerms\":nTerms,\"PatternOrLemma\":PatternOrLemma,\n",
        "               \"BERTmodel\":BERTmodel,\n",
        "               \"validation_size\":validation_size,\n",
        "               \"learning_rate\":learning_rate,\"epochs\":epochs,\n",
        "               \"batch_size\":batch_size,\"GPTmodel\":GPTmodel,\n",
        "               \"role\":role,\"prompt\":prompt,\"examples\":examples,\n",
        "               \"nExamples\":nExamples, \"balance_ratio\":balance_ratio})\n",
        "\n",
        "  def end_run(self):\n",
        "    # Finish wandb session\n",
        "     wandb.finish()\n",
        "\n",
        "def summarise_data(df, name = \"training\"):\n",
        "  print(\"----------------------------------------------\")\n",
        "  n_mis = df.Misunderstanding.sum()\n",
        "  pct_mis = round(n_mis/len(df) * 100)\n",
        "  print(f\"There are {len(df)} sentences in the {name} set.\")\n",
        "  print(f\"There are {n_mis} ({pct_mis}%) misunderstandings in the set.\")\n",
        "  print(\"----------------------------------------------\")\n",
        "\n",
        "class Classifier_Throughput:\n",
        "  \"\"\"\n",
        "  A text classifier that supports rule-based, supervised machine learning,\n",
        "  and few-shot classification approaches.\n",
        "  \"\"\"\n",
        "  def __init__(self,texts,true_scores):\n",
        "\n",
        "    \"\"\"\n",
        "    Initializes the Classifier with texts and their true classification scores.\n",
        "    \"\"\"\n",
        "    self.texts = texts\n",
        "    self.true_scores = true_scores\n",
        "    self.train_size = len(texts)\n",
        "    self.find_learner = False\n",
        "    self.type_ = None\n",
        "    self.patterns = []\n",
        "    self.lemmas = []\n",
        "    self.pred_scores = []\n",
        "    self.LLMScores = []\n",
        "  # _____________________\n",
        "  # Rule-based classifiers\n",
        "\n",
        "  def add_rule_based_terms(self, terms, mode):\n",
        "    \"\"\"\n",
        "    Adds terms for rule-based classification and sets the type of classification based on the mode.\n",
        "    \"\"\"\n",
        "    if mode == \"pattern\":\n",
        "      self.patterns = terms\n",
        "      self.type_ = \"rule-based-1\"\n",
        "    elif mode == \"lemma\":\n",
        "      self.lemmas = terms\n",
        "      self.type_ = \"rule-based-2\"\n",
        "\n",
        "  def classify_with_spacy_pattern(self, nlp):\n",
        "    \"\"\"\n",
        "    Classifies texts using spaCy's pattern matching for the provided patterns.\n",
        "    \"\"\"\n",
        "    matcher = Matcher(nlp.vocab)\n",
        "    for pattern in self.patterns:\n",
        "      matcher.add(pattern[\"label\"], [pattern[\"pattern\"]])\n",
        "\n",
        "    results = []\n",
        "    for text in self.texts:\n",
        "      doc = nlp(text) if text else nlp(\"notext\")\n",
        "      matches = matcher(doc)\n",
        "      results.append(len(matches) > 0)\n",
        "    self.pred_scores = results\n",
        "\n",
        "  def classify_with_spacy_lemma(self, nlp):\n",
        "    \"\"\"\n",
        "    Classifies texts by checking if they contain any of the specified lemmas.\n",
        "    \"\"\"\n",
        "    doc = nlp(\" \".join(self.lemmas))\n",
        "    lemma_set = set(token.lemma_ for token in doc)\n",
        "    results = []\n",
        "    for text in self.texts:\n",
        "        doc = nlp(text.lower()) if text else nlp(\"notext\")\n",
        "        text_lemmas = set(token.lemma_ for token in doc)\n",
        "        results.append(bool(text_lemmas & lemma_set))\n",
        "    self.pred_scores = results\n",
        "  # _____________________\n",
        "  # Supervised machine learning classifier\n",
        "\n",
        "  def add_SML_params(self,find_learner=False, save_model = False,validation_size=0.30, batch_size=16,\n",
        "                     learning_rate=2e-5, epochs=4,BERTmodel=\"bert\",preprocess_mode=\"bert\",\n",
        "                     maxlen=64,max_features = 50000, balance_ratio = 0):\n",
        "    self.type_ = \"supervised\"\n",
        "    self.find_learner=find_learner\n",
        "    self.save_model = save_model\n",
        "    self.validation_size=validation_size\n",
        "    self.batch_size=batch_size\n",
        "    self.learning_rate=learning_rate\n",
        "    self.epochs=epochs\n",
        "    self.BERTmodel=BERTmodel\n",
        "    self.preprocess_mode=preprocess_mode\n",
        "    self.maxlen=maxlen\n",
        "    self.max_features = max_features\n",
        "    self.balance_ratio = balance_ratio # for undersampling majority class\n",
        "\n",
        "  def convert_misBinary(self, return_scores = False):\n",
        "    output = []\n",
        "    for pred in self.pred_scores:\n",
        "      if \"not\" in pred.lower():\n",
        "        output.append(0)\n",
        "      else:\n",
        "        output.append(1)\n",
        "    if not return_scores:\n",
        "      self.pred_scores = output\n",
        "    else:\n",
        "      return output\n",
        "\n",
        "  def classify_with_supervised(self):\n",
        "    # create vectors of texts from loaded dataset\n",
        "    balance_ratio = self.balance_ratio\n",
        "    validation_size = self.validation_size\n",
        "    preprocess_mode = self.preprocess_mode\n",
        "    sentences = self.texts\n",
        "    true_scores = self.true_scores\n",
        "\n",
        "    print(f\"s:{len(sentences)},ts:{len(true_scores)}, s(ts):{sum(true_scores)}\")\n",
        "    # Split dataset\n",
        "    trainText, validText, trainScores, validScores = train_test_split(sentences, true_scores,\n",
        "                                                                      test_size=validation_size,\n",
        "                                                                      random_state=10, stratify=true_scores)\n",
        "\n",
        "    self.MLTrain = pd.DataFrame({\"text\": trainText, \"Misunderstanding\": [int(x) for x in trainScores]})\n",
        "    if balance_ratio > 0:\n",
        "      df_ = self.MLTrain\n",
        "      # select misunderstanding turns\n",
        "      var_df = df_[df_[\"Misunderstanding\"]==1]\n",
        "      # select non-misunderstanding turns; stating the random state ensures reproducibility\n",
        "      notVar_df = df_[df_[\"Misunderstanding\"]==0].sample(balance_ratio*len(var_df), random_state=10)\n",
        "      df_ = pd.concat([var_df,notVar_df])\n",
        "      self.MLTrain = df_\n",
        "    self.MLValid = pd.DataFrame({\"text\": validText, \"Misunderstanding\": [int(x) for x in validScores]})\n",
        "    self.true_scores = self.MLValid[\"Misunderstanding\"].to_list()\n",
        "    self.texts = self.MLValid[\"text\"].to_list()\n",
        "    # Preprocess texts\n",
        "    (x_train,  y_train), (x_validation, y_validation), preproc = text.texts_from_df(train_df = self.MLTrain, text_column = \"text\",\n",
        "                                                                            label_columns = [\"Misunderstanding\"], val_df = self.MLValid,\n",
        "                                                                            preprocess_mode=preprocess_mode, # embeddings to use\n",
        "                                                                            maxlen=self.maxlen, # max number of words for a document\n",
        "                                                                            max_features = self.max_features) # size of the network\n",
        "    # Prime the model\n",
        "    self.preproc = preproc\n",
        "    model = text.text_classifier(self.BERTmodel, train_data=(x_train, y_train), preproc=preproc)\n",
        "    # Create the learner object\n",
        "    learner = ktrain.get_learner(model, train_data=(x_train, y_train), batch_size=self.batch_size)\n",
        "    if self.find_learner:\n",
        "      learner.lr_find()\n",
        "      learner.lr_plot()\n",
        "    else:\n",
        "      learner.fit_onecycle(self.learning_rate, self.epochs)\n",
        "      self.learner = learner\n",
        "      # train the model\n",
        "\n",
        "  def predict_new_texts(self, save_model=False):\n",
        "    texts_ = self.MLValid\n",
        "    texts_ = texts_[\"text\"].to_list()\n",
        "    learner = self.learner\n",
        "    preproc = self.preproc\n",
        "    predictor = ktrain.get_predictor(learner.model, preproc)\n",
        "    preds = predictor.predict(texts_) #,return_proba=True)\n",
        "    self.predictor = predictor\n",
        "    self.pred_scores = preds #np.argmax(preds, axis=1)\n",
        "    self.convert_misBinary()\n",
        "\n",
        "  def save_SMLmodel(self, wd = os.getcwd()):\n",
        "    predictor = self.predictor\n",
        "    predictor.save(wd)\n",
        "\n",
        "  def return_learner(self):\n",
        "    return self.learner, self.preproc\n",
        "\n",
        "  def return_MLValid(self):\n",
        "    return self.MLValid\n",
        "  # _____________________\n",
        "  # Few-shot classifier\n",
        "\n",
        "\n",
        "  def add_prompt_param(self,GPTmodel,role,prompt,suffix,examples=\"\", nExamples=0):\n",
        "    self.GPTmodel = GPTmodel\n",
        "    self.prompt = \"\\n\".join([prompt,examples,suffix])\n",
        "    self.role = role\n",
        "    self.examples = examples\n",
        "    self.nExamples = nExamples\n",
        "    self.type_ = \"few-shot\"\n",
        "    self.cost = 0\n",
        "    self.total_tokens = 0\n",
        "\n",
        "  def gptActualCost(self, response):\n",
        "    '''calculates the gpt cost'''\n",
        "    engine = self.GPTmodel\n",
        "    total_tokens=response.usage.total_tokens\n",
        "    total_tokens_1k_units = total_tokens/1000\n",
        "\n",
        "    if engine=='gpt-3.5-turbo':\n",
        "        cost=total_tokens_1k_units*0.0005\n",
        "    elif engine=='gpt-4-turbo':\n",
        "        cost=total_tokens_1k_units*0.01\n",
        "    elif engine=='gpt-4-32k':\n",
        "        cost=total_tokens_1k_units*0.12\n",
        "    else:\n",
        "        print('getCost error: engine not found')\n",
        "        return\n",
        "    return cost, total_tokens\n",
        "\n",
        "  def get_llm_response(self,messages,temperature=0, max_tokens = 100, max_attempts = 3):\n",
        "    '''\n",
        "    Function that takes messages format for ChatGPT input and returns the response text.\n",
        "    '''\n",
        "    GPTmodel = self.GPTmodel\n",
        "\n",
        "    for attempt in range(0, max_attempts):\n",
        "      try:\n",
        "        #. request timeout ADD IN\n",
        "        response = openai.chat.completions.create(model=GPTmodel, messages = messages, temperature=temperature, max_tokens=max_tokens)\n",
        "        response_text = response.choices[0].message.content\n",
        "        self.LLMScores.append(response_text)\n",
        "        response_cost, token_count = self.gptActualCost(response)\n",
        "        self.cost += response_cost\n",
        "        self.total_tokens += token_count\n",
        "        break  # If analysis was successful, break out of the retry loop\n",
        "      except Exception as e:\n",
        "        print(f\"Error processing text on attempt {attempt+1}: {e}\")\n",
        "        if attempt + 1 == max_attempts:\n",
        "          print(f\"Skipping text after {max_attempts} failed attempts.\")\n",
        "          response_text\n",
        "    return response_text\n",
        "\n",
        "\n",
        "  def define_messages(self, text_to_classify):\n",
        "    '''\n",
        "    Function for creating a basic messages format from a prompt, a role, and a text to classify (all strings)\n",
        "    '''\n",
        "    prompt = self.prompt\n",
        "    role = self.role\n",
        "    prompt = prompt.format(text_to_classify)\n",
        "    messages = [{'role': 'system', 'content': role},\n",
        "                {'role': 'user', 'content' : prompt}]\n",
        "    return messages\n",
        "\n",
        "  def convert_llm_scores_binary(self, return_scores = False):\n",
        "    '''\n",
        "    Function for converting a string \"Yes\" or \"No\" into binary format - used for the clarification requests\n",
        "    '''\n",
        "    llm_scores = self.pred_scores\n",
        "    new_scores = []\n",
        "    for s in llm_scores:\n",
        "      if \"yes\" in s.lower():\n",
        "        new_scores.append(1)\n",
        "      else:\n",
        "        new_scores.append(0)\n",
        "    if not return_scores:\n",
        "      self.pred_scores = new_scores\n",
        "    else:\n",
        "      return new_scores\n",
        "\n",
        "  def classify_with_fewshot(self,  max_tokens = 100, max_attempts = 3, temperature = 0):\n",
        "    '''\n",
        "    Function for running a prompt over a series of texts (expects a list)\n",
        "    '''\n",
        "\n",
        "    prompt = self.prompt\n",
        "    role = self.role\n",
        "    input_texts = self.texts\n",
        "    GPTmodel = self.GPTmodel\n",
        "    scores = []\n",
        "    for txt in tqdm(input_texts):\n",
        "      message = self.define_messages(txt)\n",
        "      try:\n",
        "        response = self.get_llm_response(message,temperature=temperature,\n",
        "                                         max_tokens=max_tokens, max_attempts=max_attempts)\n",
        "      except:\n",
        "        response = \"Error in response\"\n",
        "      scores.append(response)\n",
        "    self.pred_scores = scores\n",
        "    self.convert_llm_scores_binary()\n",
        "\n",
        "\n",
        "  # _____________________\n",
        "  # Functions for running classifiers\n",
        "  def run_classifier(self):\n",
        "    \"\"\"\n",
        "    Determines the type of classification to use and applies it.\n",
        "    \"\"\"\n",
        "    if self.type_ == \"rule-based-1\":\n",
        "      self.classify_with_spacy_pattern(nlp)\n",
        "    elif self.type_ == \"rule-based-2\":\n",
        "      self.classify_with_spacy_lemma(nlp)\n",
        "    elif self.type_ == \"supervised\":\n",
        "      self.classify_with_supervised()\n",
        "      if self.find_learner == False:\n",
        "        self.predict_new_texts()\n",
        "    elif self.type_ == \"few-shot\":\n",
        "      self.classify_with_fewshot()\n",
        "      cost = self.cost\n",
        "      total_tokens = self.total_tokens\n",
        "      avg_tokens = self.total_tokens / self.train_size\n",
        "      print(f\"This run cost {cost:.2f}$ for {total_tokens} tokens. Average tokens: {avg_tokens:.2f}\")\n",
        "    else:\n",
        "      raise ValueError(\"Invalid classifier type specified.\")\n",
        "\n",
        "  def get_model_report(self, display=True):\n",
        "    true_scores = self.true_scores\n",
        "    pred_scores = self.pred_scores\n",
        "    print(f\"true:{len(true_scores)},pred:{len(pred_scores)}\")\n",
        "    cm = confusion_matrix(true_scores, pred_scores)\n",
        "    TP = cm[1, 1]\n",
        "    FN = cm[1, 0]\n",
        "    FP = cm[0, 1]\n",
        "    TN = cm[0, 0]\n",
        "    report = classification_report(true_scores, pred_scores, output_dict=True)\n",
        "    F1_var = report['1']['f1-score']  # F1 score for class '1'\n",
        "    F1_avg = report['weighted avg']['f1-score']  # Weighted average F1 score\n",
        "    Precision = report['1']['precision']\n",
        "    Recall = report['1']['recall']\n",
        "    precision, recall, thresholds = precision_recall_curve(true_scores, pred_scores)\n",
        "    AUC_PR = auc(recall, precision)\n",
        "    AUC_ROC = roc_auc_score(true_scores, pred_scores)\n",
        "    if display:\n",
        "      print(f'AUC-PR: {AUC_PR:.2f}\\n')\n",
        "      print(f'AUC-ROC: {AUC_ROC:.2f}\\n')\n",
        "      print(classification_report(true_scores, pred_scores))\n",
        "    else:\n",
        "      return Precision,Recall,AUC_PR,AUC_ROC,F1_avg,F1_var,TP,TN,FP,FN\n",
        "\n",
        "  def log_model(self, wandb_project):\n",
        "    \"\"\"\n",
        "    Function runs the model and logs the data for wandb.\n",
        "    \"\"\"\n",
        "    if self.find_learner:\n",
        "      return\n",
        "    else:\n",
        "      Precision,Recall,AUC_PR,AUC_ROC,F1_avg,F1_var,TP,TN,FP,FN = self.get_model_report(display=False)\n",
        "      type_ = self.type_\n",
        "      lwb = log_wandb(wandb_project)\n",
        "      lwb.add_KeyVariables(len(self.texts),Precision,Recall,\n",
        "                       AUC_PR,AUC_ROC,F1_avg,F1_var,\n",
        "                       TP,TN,FP,FN,type_)\n",
        "      if type_ in [\"rule-based-1\", \"rule-based-2\"]:\n",
        "        lwb.add_ClassVars(Terms=0, nTerms=0, PatternOrLemma=0)\n",
        "      elif type_ == \"supervised\":\n",
        "        lwb.add_ClassVars(BERTmodel=self.BERTmodel, validation_size=self.validation_size,\n",
        "                          learning_rate=self.learning_rate, epochs=self.epochs,\n",
        "                          batch_size=self.batch_size)\n",
        "\n",
        "      elif type_ == \"few-shot\":\n",
        "        lwb.add_ClassVars(GPTmodel=self.GPTmodel, role=self.role, prompt=self.prompt,\n",
        "                          examples=\"\", nExamples=0)\n",
        "      lwb.end_run()\n",
        "\n",
        "  def return_results(self):\n",
        "    return self.pred_scores\n",
        "\n",
        "  def run_and_log(self, wandb_project, display=True):\n",
        "    self.run_classifier()\n",
        "    if not self.find_learner:\n",
        "      self.get_model_report(display)\n",
        "      self.log_model(wandb_project)\n",
        "    elif self.find_learner == False:\n",
        "      self.get_model_report(display)\n",
        "      self.log_model(wandb_project)\n",
        "\n",
        "  def get_misclassification(self, return_all = False):\n",
        "    df = pd.DataFrame({\"text\":self.texts,\"true\":self.true_scores,\n",
        "                       \"pred\":self.pred_scores})\n",
        "    # Function to classify each row\n",
        "    def classify_row(row):\n",
        "      if row['true'] == 1 and row['pred'] == 1:\n",
        "        return 'TP'\n",
        "      elif row['true'] == 0 and row['pred'] == 1:\n",
        "        return 'FP'\n",
        "      elif row['true'] == 1 and row['pred'] == 0:\n",
        "        return 'FN'\n",
        "      elif row['true'] == 0 and row['pred'] == 0:\n",
        "        return 'TN'\n",
        "    df['Classification'] = df.apply(classify_row, axis=1)\n",
        "    if return_all:\n",
        "      return df\n",
        "    else:\n",
        "      return df[df[\"Classification\"].isin([\"FP\",\"FN\"])]\n",
        "  def preprocess_text(self, text):\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    words = nltk.word_tokenize(text)\n",
        "    cleaned_text = [lemmatizer.lemmatize(word.lower()) for word in words if word.isalnum() and word.lower() not in stop_words]\n",
        "    return ' '.join(cleaned_text)\n",
        "\n",
        "  def plot_misclassifications(self, df, FN_FP=\"FN\"):\n",
        "    df['cleaned_text'] = df['text'].apply(self.preprocess_text)\n",
        "    if FN_FP == \"FN\":\n",
        "      print(\"Word Cloud for False Negatives:\")\n",
        "      texts = \" \".join(df[df['Classification'] == 'FN']['cleaned_text'])\n",
        "    else:\n",
        "      print(\"Word Cloud for False Positives:\")\n",
        "      texts = \" \".join(df[df['Classification'] == 'FP']['cleaned_text'])\n",
        "    wordcloud = WordCloud(width = 800, height = 400, background_color ='white').generate(texts)\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.imshow(wordcloud, interpolation='bilinear')\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "  def return_LLMscores(self):\n",
        "    return self.LLMScores\n",
        "\n",
        "\n",
        "## RULE BASED EXAMPLE USAGE\n",
        "#print(f\"N lemmas (duplicates removed manual): {len(terms)}\")\n",
        "#RB_lemClass = Classifier_(texts=texts,true_scores=true_scores)\n",
        "#RB_lemClass.add_rule_based_terms(lemmas, \"lemma\")\n",
        "#RB_lemClass.add_rule_based_terms(patterns, \"pattern\")\n",
        "#RB_lemClass.run_and_log(wandb_project)\n",
        "\n",
        "## SUPERVISED CLASSIFIER EXAMPLE USAGE\n",
        "## Run classifier\n",
        "#find_learner=False\n",
        "#validation_size=0.05 # 30 20 10\n",
        "#batch_size= 128 # 64,32,16\n",
        "#learning_rate=2e-5# 5e-5, 4e-5, 3e-5, and 2e-5 1e-5\n",
        "#epochs=4\n",
        "#BERTmodel=\"bert\"\n",
        "#preprocess_mode=\"bert\"\n",
        "#maxlen=30\n",
        "#max_features = 50000 # 100000 ; 50000 ; 35000   -> 50000 seemed best\n",
        "#balance_ratio = 0 # rebalances the training data\n",
        "#SML_Class = Classifier_(texts=texts,true_scores=true_scores)\n",
        "#SML_Class.add_SML_params(find_learner=find_learner,validation_size=validation_size,\n",
        "#                         batch_size=batch_size,learning_rate=learning_rate,epochs=epochs,\n",
        "#                         BERTmodel=BERTmodel,preprocess_mode=preprocess_mode,maxlen=maxlen,\n",
        "#                         max_features=max_features,balance_ratio=balance_ratio)\n",
        "#SML_Class.SML_Classifier()\n",
        "#SML_Class.predict_new_texts()\n",
        "#SML_Class.run_and_log(wandb_project)\n",
        "\n"
      ],
      "metadata": {
        "id": "x8fvJsDvf15G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Plotting and summary object\n",
        "\n",
        "This class is used throughout to do various plotting and statistical functions."
      ],
      "metadata": {
        "id": "5Y5mJpC0JtQZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TextDataStats:\n",
        "  def __init__(self, df, text_column=\"text\", binary_column=\"Misunderstanding\",\n",
        "               IRR_columns = [\"Coder1\",\"Coder2\",\"Coder3\",\"Coder4\"],\n",
        "               group_column = \"Round\"):\n",
        "    self.df = df\n",
        "    self.text_column = text_column\n",
        "    self.binary_column = binary_column\n",
        "    self.IRR_columns = IRR_columns\n",
        "    self.group_column = group_column\n",
        "\n",
        "  def preprocess_text(self):\n",
        "    \"\"\"\n",
        "    Extracts words and sentences from the text, counts them and adds to the dataframe.\n",
        "    \"\"\"\n",
        "    self.df['words'] = self.df[self.text_column].apply(lambda x: re.findall(r'\\b\\w+\\b', x.lower()))\n",
        "    self.df['word_count'] = self.df['words'].apply(len)\n",
        "\n",
        "  def basic_stats(self):\n",
        "    \"\"\"\n",
        "    Computes basic statistics for overall and grouped data.\n",
        "    \"\"\"\n",
        "    self.preprocess_text()\n",
        "\n",
        "    # General stats\n",
        "    general_stats = self.df.describe(include=[np.number]).loc[['mean', 'std', 'min', '50%', 'max'], ['word_count']]\n",
        "    general_stats.rename(index={'50%': 'median'}, inplace=True)\n",
        "    # Grouped stats by binary column\n",
        "    grouped_stats = self.df.groupby(self.binary_column).agg({\n",
        "        'word_count': ['mean', 'median', 'std', 'min', 'max'],\n",
        "    })\n",
        "    # Binary column distribution\n",
        "    binary_dist = self.df[self.binary_column].value_counts(normalize=True).to_frame('distribution')\n",
        "    return general_stats.round(2), grouped_stats.round(2), binary_dist.round(2)\n",
        "\n",
        "  def BasicReport(self):\n",
        "    \"\"\"\n",
        "    Generates a report combining all statistics in a readable text format.\n",
        "    \"\"\"\n",
        "    general_stats, grouped_stats, binary_dist = self.basic_stats()\n",
        "\n",
        "    # Creating a structured text report\n",
        "    report = \"Text Data Statistics Report\\n\\n\"\n",
        "    report += \"General Statistics:\\n\"\n",
        "    report += general_stats.to_string() + \"\\n\\n\"\n",
        "\n",
        "    report += \"Statistics by Binary Column:\\n\"\n",
        "    for name, group in self.df.groupby(self.binary_column):\n",
        "        report += f\"\\nGroup: {name}\\n\"\n",
        "        report += grouped_stats.loc[name].to_string() + \"\\n\"\n",
        "    return report\n",
        "\n",
        "\n",
        "  def get_IRR(self, df):\n",
        "    \"\"\"\n",
        "    Fetches the absolute agreement, Krippendorff's Alpha, Gwet's AC1\n",
        "    \"\"\"\n",
        "    df = df[self.IRR_columns]\n",
        "    # Get absolute agreement\n",
        "    df = df.astype(int)\n",
        "    IRR_out = []\n",
        "    for i, row in df.iterrows():\n",
        "      for k in list(df.columns):\n",
        "        IRR_out.append([k, str(i), row[k]])\n",
        "    ratingtask = agreement.AnnotationTask(data=IRR_out)\n",
        "    ags = ratingtask.avg_Ao()\n",
        "    # Get Gwet AC1 and K Alpha\n",
        "    cac= CAC(df)\n",
        "    print(cac)\n",
        "    #print(cac_4raters)\n",
        "    Gwet_obj = cac.gwet()\n",
        "    Alpha_obj = cac.krippendorff()\n",
        "    return ags, Alpha_obj, Gwet_obj\n",
        "  def process_object(self, IRR_obj, sig_level = 0.001):\n",
        "    \"\"\"\n",
        "    This processes the cac output for the IRR into two strings for reporting\n",
        "    \"\"\"\n",
        "    s = IRR_obj[\"est\"][\"coefficient_value\"]\n",
        "    ci1 = IRR_obj[\"est\"][\"confidence_interval\"][0]\n",
        "    ci2 = IRR_obj[\"est\"][\"confidence_interval\"][1]\n",
        "    stat_string = f\"{s:.2f} CI = ({ci1:.2f}, {ci2:.2f})\"\n",
        "    Z = IRR_obj[\"est\"][\"z\"]\n",
        "    pval = IRR_obj[\"est\"][\"p_value\"]\n",
        "    if pval < sig_level:\n",
        "      sig_string = f\"z = {Z:.2f}; p < {sig_level}\"\n",
        "    else:\n",
        "      sig_string = f\"z = {Z:.2f}; p = {pval:.3f}\"\n",
        "\n",
        "    return stat_string, sig_string\n",
        "\n",
        "\n",
        "  def IRRreport(self):\n",
        "    df = self.df.sort_values([self.group_column])\n",
        "    rounds = df[self.group_column].unique()\n",
        "    agreement, alphas_, alpha_sigs_ = [],[],[]\n",
        "    ac1s, ac1s_sigs, ss = [],[],[]\n",
        "    for i in rounds:\n",
        "      tdf = df[df[self.group_column] == i]\n",
        "      ss.append(len(tdf))\n",
        "      ags, alpha_, gwets_ = self.get_IRR(tdf)\n",
        "      agreement.append(ags)\n",
        "      alpha_stat, alpha_sig = self.process_object(alpha_)\n",
        "      alphas_.append(alpha_stat)\n",
        "      alpha_sigs_.append(alpha_sig)\n",
        "\n",
        "      ac1_stat, ac1_sig = self.process_object(gwets_)\n",
        "      ac1s.append(ac1_stat)\n",
        "      ac1s_sigs.append(ac1_sig)\n",
        "\n",
        "    return pd.DataFrame({\"Round\":[\"Round \" + str(i) for i in rounds],\n",
        "                         \"Sample size\":ss, \"Agreement\":agreement,\n",
        "                         \"K's Alpha\":alphas_,\"K's Alpha significance\":alpha_sigs_,\n",
        "                         \"Gwet's AC1\":ac1s,\"Gwet's AC1 significance\":ac1s_sigs,\n",
        "                         })\n",
        "\n",
        "  def get_disagreements(self,n=10, return_df = False):\n",
        "    \"\"\"\n",
        "    Prints n disagreements for the IRR results\n",
        "    \"\"\"\n",
        "    df = self.df\n",
        "    disag = []\n",
        "    for i, row in df.iterrows():\n",
        "      x = 0\n",
        "      for coder in self.IRR_columns:\n",
        "        x += row[coder]\n",
        "      disag.append(x)\n",
        "    df[\"disag\"] = disag\n",
        "    ncoders = len(self.IRR_columns)\n",
        "    df = df[df[\"disag\"] < ncoders]\n",
        "    df = df[df[\"disag\"] > 0]\n",
        "    if return_df:\n",
        "      return df.round(2)\n",
        "    else:\n",
        "      sdf = df.sample(n)\n",
        "      for s in sdf.text:\n",
        "        print(\"----------\")\n",
        "        print(s)\n",
        "\n",
        "  def get_misclassifications(self, n=5, return_all=False):\n",
        "    \"\"\"\n",
        "    Function to report on the misclassifications across all three classifiers.\n",
        "    \"\"\"\n",
        "    df = self.df\n",
        "\n",
        "    def classify(row):\n",
        "      base, fs, sup = int(row[\"Manual\"]), int(row[\"LLM\"]), int(row[\"supervised\"])\n",
        "      if sup == base:\n",
        "        return \"TP (All)\" if base == 1 else \"TN (All)\" if fs == base else \"FP (LLM)\" if base == 0 else \"FN (LLM)\"\n",
        "      else:\n",
        "        return \"FN (supervised)\" if fs == base and base == 1 else \"FP (supervised)\" if fs == base else \"FP (All)\" if base == 1 else \"FN (All)\"\n",
        "\n",
        "    df[\"FN_FP\"] = df.apply(classify, axis=1)\n",
        "\n",
        "    if return_all:\n",
        "      return df\n",
        "\n",
        "    misclassifications = {\n",
        "        \"FP (All)\": df[df.FN_FP == \"FP (All)\"].text.to_list(),\n",
        "        \"FP (supervised)\": df[df.FN_FP == \"FP (supervised)\"].text.to_list(),\n",
        "        \"FP (LLM)\": df[df.FN_FP == \"FP (LLM)\"].text.to_list(),\n",
        "        \"FN (All)\": df[df.FN_FP == \"FN (All)\"].text.to_list(),\n",
        "        \"FN (supervised)\": df[df.FN_FP == \"FN (supervised)\"].text.to_list(),\n",
        "        \"FN (LLM)\": df[df.FN_FP == \"FN (LLM)\"].text.to_list()\n",
        "    }\n",
        "\n",
        "    for key, value in misclassifications.items():\n",
        "      print(f\"--- {key.replace('_', ' ')} count: -- {len(value)}\")\n",
        "\n",
        "    print(f\"\\nPrinting {n} examples of each classifier type.\\n\")\n",
        "\n",
        "    for key, value in misclassifications.items():\n",
        "      print(f\"------ {key.replace('_', ' ').upper()} ------\")\n",
        "      for example in value[:n]:\n",
        "        print(f\"- {example}\")\n",
        "      print(\"--------\")\n",
        "\n",
        "\n",
        "  def RAMP_plot(self, x_col, y_col, group_col,\n",
        "                pastel_colors = ['#77B5FE', '#FF6961', '#B19CD9'],\n",
        "                title=\"\", width=800, height=500, line_width=2, line_opacity=0.5,\n",
        "                font_size=14, tick_size=12):\n",
        "    \"\"\"\n",
        "    Creates a connected scatter plot with customizable font size and tick size\n",
        "    \"\"\"\n",
        "    self.df[group_col] = self.df[group_col].astype('category')\n",
        "\n",
        "    scatter_fig = px.line(self.df, x=x_col, y=y_col, color=group_col,\n",
        "                          title=title, template='plotly_white',\n",
        "                          labels={x_col: x_col, y_col: y_col, group_col: group_col},\n",
        "                          markers=True,\n",
        "                          color_discrete_sequence=pastel_colors)\n",
        "\n",
        "    for group, group_df in self.df.groupby(group_col):\n",
        "        min_x = group_df[x_col].min()\n",
        "        max_x = group_df[x_col].max()\n",
        "        min_y = group_df[group_df[x_col] == min_x][y_col].iloc[0]\n",
        "        max_y = group_df[group_df[x_col] == max_x][y_col].iloc[0]\n",
        "        color_index = group_df[group_col].cat.codes.unique()[0] % len(pastel_colors)\n",
        "        scatter_fig.add_trace(go.Scatter(\n",
        "            x=[min_x, max_x],\n",
        "            y=[min_y, max_y],\n",
        "            mode='lines',\n",
        "            name=f'{group} - Range Line',\n",
        "            line=dict(color=pastel_colors[color_index], width=line_width, dash='dash'),\n",
        "            opacity=line_opacity,\n",
        "            showlegend=False))\n",
        "\n",
        "    # Update layout to include font size and tick size settings\n",
        "    scatter_fig.update_layout(\n",
        "        title=dict(text=title, font=dict(size=font_size)),\n",
        "        xaxis=dict(title=dict(text=x_col, font=dict(size=font_size)),\n",
        "                   tickfont=dict(size=tick_size)),\n",
        "        yaxis=dict(title=dict(text=y_col, font=dict(size=font_size)),\n",
        "                   tickfont=dict(size=tick_size)),\n",
        "        legend=dict(font=dict(size=font_size)),\n",
        "        width=width, height=height\n",
        "    )\n",
        "\n",
        "    scatter_fig.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "aW0xRPcIKELa"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Manual coding\n",
        "\n",
        "The first stage of RAMP is a manual coding stage, where a codebook is developed through the process of training coders and conducting small pilot studies. We use Krippendorff's Alpha ([Krippendorff, 1970](https://journals.sagepub.com/doi/10.1177/001316447003000105)) for quantifying the inter-rater reliability of coders.\n",
        "\n",
        "\n",
        "This section reports the inter-rater reliability of these studies and the final inter-rater reliability on a shared dataset. The shared dataset was coded blind, with coders unaware of which sentences were being shared and which were exclusive to the individual."
      ],
      "metadata": {
        "id": "DMvNGUi-kJSW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1 Input:"
      ],
      "metadata": {
        "id": "iK_gyvGUkLiG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1.1 Data"
      ],
      "metadata": {
        "id": "e6Htv_uykRy-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "The raw dataset contains sentences from online dialogues, sampled from three sources:\n",
        "\n",
        "**Reddit conversations from 27 subreddits**.\n",
        "\n",
        "> This data was downloaded using the Reddit API by the authors.\n",
        "\n",
        "**Twitter Customer Support data**  ([Thought Vector & Axelbrooke, 2017](https://www.kaggle.com/datasets/thoughtvector/customer-support-on-twitter)).\n",
        "\n",
        "> This data was downloaded from (Copyright: CC BY-NC-SA 4.0).\n",
        "\n",
        "**Wikipedia Talk Pages data** ([Danescu-Niculescu-Mizil et al., 2012](https://convokit.cornell.edu/documentation/wiki.html)).\n",
        "\n",
        "> This data was downloaded using Cornell University's [ConvoKit](https://convokit.cornell.edu) Python package (Copyright: CC BY 4.0)\n",
        "\n",
        "**Notes:**\n",
        "\n",
        "> All author names and sentences have been anonymized following ethical guidelines for the study.\n",
        "> As a further precaution, the sentences are shuffled and the source (e.g., Reddit, Twitter) removed from the dataframe."
      ],
      "metadata": {
        "id": "RoxsE1Uc8HFn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Manual coded dataset final size\n",
        "print(f\"Full dataset size: {len(train) + len(validation)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wj9RKsx-YHDC",
        "outputId": "c1be1e3f-8f83-49df-e7c8-56fa60550fbe"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Full dataset size: 21994\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Explanation of shared subsamples manual coding\n",
        "tdf = St1Through\n",
        "prev_rounds = tdf[tdf.Round!=6]\n",
        "IRR_sample = tdf[tdf.Round==6]\n",
        "IRR_texts = IRR_sample.text.to_list()\n",
        "non_IRR_texts = prev_rounds.text.to_list()\n",
        "crossover_texts = [t for t in IRR_texts if t in non_IRR_texts]\n",
        "crossover_df = tdf[tdf.text.isin(crossover_texts)].drop_duplicates()\n",
        "crossover_df.loc[:,\"All_coders\"] = crossover_df.Coder1 + crossover_df.Coder2 + crossover_df.Coder3 + crossover_df.Coder4\n",
        "crossover_df.loc[:,\"All_coders\"] = crossover_df[\"All_coders\"].apply(lambda x: 1 if x > 1 else 0)\n",
        "\n",
        "all_rounds_len = len(tdf)\n",
        "n_crossovers_all = all_rounds_len - len(tdf.text.drop_duplicates())\n",
        "pct_all_cross = round((n_crossovers_all/all_rounds_len)*100,2)\n",
        "IRR_len = len(IRR_sample)\n",
        "n_crossovers = len(crossover_texts)\n",
        "pct_cross= round((n_crossovers/IRR_len)*100,2)\n",
        "n_mis_in_cross = crossover_df.All_coders.sum()\n",
        "pct_mis = round((n_mis_in_cross/n_crossovers)*100,2)\n",
        "print(f\"\"\"\n",
        "There are {all_rounds_len} sentences across all rounds of coding.\n",
        "{n_crossovers_all} ({pct_all_cross}%) sentences were shared across various rounds.\n",
        "\n",
        "The IRR set (Round 6) contains {IRR_len} sentences.\n",
        "Of these sentences, {n_crossovers} ({pct_cross}%) appeared in another round.\n",
        "Of these crossover sentences, {n_mis_in_cross} ({pct_mis}%) were coded for misunderstanding.\n",
        "\"\"\")\n",
        "\n",
        "IRR_df_no_crossovers = IRR_sample[~IRR_sample.text.isin(crossover_texts)]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vnopgto0lPVH",
        "outputId": "457da019-cafb-438f-bb1f-ade80a92b722"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "There are 6099 sentences across all rounds of coding.\n",
            "288 (4.72%) sentences were shared across various rounds.\n",
            "\n",
            "The IRR set (Round 6) contains 1551 sentences.\n",
            "Of these sentences, 135 (8.7%) appeared in another round.\n",
            "Of these crossover sentences, 17 (12.59%) were coded for misunderstanding.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the IRR from the final round (validation)\n",
        "IRR_final = St1Through[St1Through[\"Round\"]==6]\n",
        "IRR_through = St1Through[St1Through[\"Round\"]!=6]"
      ],
      "metadata": {
        "id": "5VoWDNwBRgQt"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2 Throughput"
      ],
      "metadata": {
        "id": "zX-a78DVkbbi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inter rater reliability across four pilot studies coding random samples of sentences:"
      ],
      "metadata": {
        "id": "0B23lDDzWzNk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tds = TextDataStats(IRR_through)\n",
        "tds.IRRreport().round(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "RCQOxLqEDsQr",
        "outputId": "5400f8d8-4a1e-4f93-c1b9-d609dbd3412c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<irrCAC.raw.CAC Subjects: 689, Raters: 4, Categories: [0, 1], Weights: \"identity\">\n",
            "<irrCAC.raw.CAC Subjects: 1178, Raters: 4, Categories: [0, 1], Weights: \"identity\">\n",
            "<irrCAC.raw.CAC Subjects: 1068, Raters: 4, Categories: [0, 1], Weights: \"identity\">\n",
            "<irrCAC.raw.CAC Subjects: 783, Raters: 4, Categories: [0, 1], Weights: \"identity\">\n",
            "<irrCAC.raw.CAC Subjects: 830, Raters: 4, Categories: [0, 1], Weights: \"identity\">\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Round  Sample size  Agreement               K's Alpha  \\\n",
              "0  Round 1          689       0.95  0.57 CI = (0.49, 0.66)   \n",
              "1  Round 2         1178       0.97  0.69 CI = (0.62, 0.77)   \n",
              "2  Round 3         1068       0.97  0.72 CI = (0.66, 0.79)   \n",
              "3  Round 4          783       0.94  0.78 CI = (0.73, 0.82)   \n",
              "4  Round 5          830       0.98  0.75 CI = (0.68, 0.82)   \n",
              "\n",
              "  K's Alpha significance              Gwet's AC1 Gwet's AC1 significance  \n",
              "0   z = 13.47; p < 0.001  0.94 CI = (0.93, 0.96)   z = 129.52; p < 0.001  \n",
              "1   z = 17.45; p < 0.001  0.97 CI = (0.96, 0.98)   z = 251.29; p < 0.001  \n",
              "2   z = 21.62; p < 0.001  0.96 CI = (0.95, 0.97)   z = 199.78; p < 0.001  \n",
              "3   z = 34.19; p < 0.001  0.92 CI = (0.91, 0.94)   z = 100.61; p < 0.001  \n",
              "4   z = 20.70; p < 0.001  0.97 CI = (0.97, 0.98)   z = 230.60; p < 0.001  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e1e1f43f-30fb-41e4-8e15-c48450ca1961\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Round</th>\n",
              "      <th>Sample size</th>\n",
              "      <th>Agreement</th>\n",
              "      <th>K's Alpha</th>\n",
              "      <th>K's Alpha significance</th>\n",
              "      <th>Gwet's AC1</th>\n",
              "      <th>Gwet's AC1 significance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Round 1</td>\n",
              "      <td>689</td>\n",
              "      <td>0.95</td>\n",
              "      <td>0.57 CI = (0.49, 0.66)</td>\n",
              "      <td>z = 13.47; p &lt; 0.001</td>\n",
              "      <td>0.94 CI = (0.93, 0.96)</td>\n",
              "      <td>z = 129.52; p &lt; 0.001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Round 2</td>\n",
              "      <td>1178</td>\n",
              "      <td>0.97</td>\n",
              "      <td>0.69 CI = (0.62, 0.77)</td>\n",
              "      <td>z = 17.45; p &lt; 0.001</td>\n",
              "      <td>0.97 CI = (0.96, 0.98)</td>\n",
              "      <td>z = 251.29; p &lt; 0.001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Round 3</td>\n",
              "      <td>1068</td>\n",
              "      <td>0.97</td>\n",
              "      <td>0.72 CI = (0.66, 0.79)</td>\n",
              "      <td>z = 21.62; p &lt; 0.001</td>\n",
              "      <td>0.96 CI = (0.95, 0.97)</td>\n",
              "      <td>z = 199.78; p &lt; 0.001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Round 4</td>\n",
              "      <td>783</td>\n",
              "      <td>0.94</td>\n",
              "      <td>0.78 CI = (0.73, 0.82)</td>\n",
              "      <td>z = 34.19; p &lt; 0.001</td>\n",
              "      <td>0.92 CI = (0.91, 0.94)</td>\n",
              "      <td>z = 100.61; p &lt; 0.001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Round 5</td>\n",
              "      <td>830</td>\n",
              "      <td>0.98</td>\n",
              "      <td>0.75 CI = (0.68, 0.82)</td>\n",
              "      <td>z = 20.70; p &lt; 0.001</td>\n",
              "      <td>0.97 CI = (0.97, 0.98)</td>\n",
              "      <td>z = 230.60; p &lt; 0.001</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e1e1f43f-30fb-41e4-8e15-c48450ca1961')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e1e1f43f-30fb-41e4-8e15-c48450ca1961 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e1e1f43f-30fb-41e4-8e15-c48450ca1961');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-102858f4-5ff0-4baa-aa02-e93f7b7a3dca\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-102858f4-5ff0-4baa-aa02-e93f7b7a3dca')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-102858f4-5ff0-4baa-aa02-e93f7b7a3dca button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"tds\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Round\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Round 2\",\n          \"Round 5\",\n          \"Round 3\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sample size\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 205,\n        \"min\": 689,\n        \"max\": 1178,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1178,\n          830,\n          1068\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Agreement\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.016431676725154998,\n        \"min\": 0.94,\n        \"max\": 0.98,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.97,\n          0.98,\n          0.95\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"K's Alpha\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"0.69 CI = (0.62, 0.77)\",\n          \"0.75 CI = (0.68, 0.82)\",\n          \"0.72 CI = (0.66, 0.79)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"K's Alpha significance\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"z = 17.45; p < 0.001\",\n          \"z = 20.70; p < 0.001\",\n          \"z = 21.62; p < 0.001\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Gwet's AC1\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"0.97 CI = (0.96, 0.98)\",\n          \"0.97 CI = (0.97, 0.98)\",\n          \"0.96 CI = (0.95, 0.97)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Gwet's AC1 significance\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"z = 251.29; p < 0.001\",\n          \"z = 230.60; p < 0.001\",\n          \"z = 199.78; p < 0.001\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that the Alpha gets progressively better.\n",
        "\n",
        "We can also see the deceptive nature of absolute agreement. For instance, the low alpha of 0.57 in the first round has 95% agreement is because coders were generally good at recognizing *not* misunderstandings but bad at agreeing on what sentences were misunderstandings. The problem is caused by the skewed nature of the dataset (misunderstandings only 8% of data).\n",
        "\n",
        "\n",
        "We ended the training at Round 5, as the agreement diminishes from the previous round."
      ],
      "metadata": {
        "id": "iQJzLFKckjqe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.3 Output"
      ],
      "metadata": {
        "id": "hY6VX1eAkmlv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tds = TextDataStats(IRR_final)\n",
        "tds.IRRreport().round(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        },
        "id": "t8A04avekqPi",
        "outputId": "ee3dbe09-c25b-4164-b9c1-9841c923d80b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<irrCAC.raw.CAC Subjects: 1551, Raters: 4, Categories: [0, 1], Weights: \"identity\">\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Round  Sample size  Agreement               K's Alpha  \\\n",
              "0  Round 6         1551       0.98  0.79 CI = (0.74, 0.84)   \n",
              "\n",
              "  K's Alpha significance              Gwet's AC1 Gwet's AC1 significance  \n",
              "0   z = 29.76; p < 0.001  0.98 CI = (0.97, 0.98)   z = 330.29; p < 0.001  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-497e4573-7d81-4442-810f-0c0dbde9be81\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Round</th>\n",
              "      <th>Sample size</th>\n",
              "      <th>Agreement</th>\n",
              "      <th>K's Alpha</th>\n",
              "      <th>K's Alpha significance</th>\n",
              "      <th>Gwet's AC1</th>\n",
              "      <th>Gwet's AC1 significance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Round 6</td>\n",
              "      <td>1551</td>\n",
              "      <td>0.98</td>\n",
              "      <td>0.79 CI = (0.74, 0.84)</td>\n",
              "      <td>z = 29.76; p &lt; 0.001</td>\n",
              "      <td>0.98 CI = (0.97, 0.98)</td>\n",
              "      <td>z = 330.29; p &lt; 0.001</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-497e4573-7d81-4442-810f-0c0dbde9be81')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-497e4573-7d81-4442-810f-0c0dbde9be81 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-497e4573-7d81-4442-810f-0c0dbde9be81');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"tds\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"Round\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Round 6\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sample size\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 1551,\n        \"max\": 1551,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1551\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Agreement\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.98,\n        \"max\": 0.98,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.98\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"K's Alpha\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"0.79 CI = (0.74, 0.84)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"K's Alpha significance\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"z = 29.76; p < 0.001\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Gwet's AC1\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"0.98 CI = (0.97, 0.98)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Gwet's AC1 significance\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"z = 330.29; p < 0.001\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is very good agreement (98%) with moderate inter-rater reliability (Krippendorff's Alpha  = 0.79).\n"
      ],
      "metadata": {
        "id": "SPSjO8BpXDkU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To sense-check the inter-rater reliability, we can remove all sentences that appeared in the previous rounds, leaving us with only sentences that the coders had yet to score before:"
      ],
      "metadata": {
        "id": "K3TQ6LTplhCN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tds = TextDataStats(IRR_df_no_crossovers)\n",
        "tds.IRRreport().round(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        },
        "id": "Qrf9PpFmlrNE",
        "outputId": "55fcf07a-1778-4da5-8d99-3f25415ed114"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<irrCAC.raw.CAC Subjects: 1416, Raters: 4, Categories: [0, 1], Weights: \"identity\">\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Round  Sample size  Agreement               K's Alpha  \\\n",
              "0  Round 6         1416       0.98  0.78 CI = (0.73, 0.84)   \n",
              "\n",
              "  K's Alpha significance              Gwet's AC1 Gwet's AC1 significance  \n",
              "0   z = 27.16; p < 0.001  0.98 CI = (0.97, 0.98)   z = 314.46; p < 0.001  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-71b2872d-fd30-4e6e-92ca-8964160ad9c9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Round</th>\n",
              "      <th>Sample size</th>\n",
              "      <th>Agreement</th>\n",
              "      <th>K's Alpha</th>\n",
              "      <th>K's Alpha significance</th>\n",
              "      <th>Gwet's AC1</th>\n",
              "      <th>Gwet's AC1 significance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Round 6</td>\n",
              "      <td>1416</td>\n",
              "      <td>0.98</td>\n",
              "      <td>0.78 CI = (0.73, 0.84)</td>\n",
              "      <td>z = 27.16; p &lt; 0.001</td>\n",
              "      <td>0.98 CI = (0.97, 0.98)</td>\n",
              "      <td>z = 314.46; p &lt; 0.001</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-71b2872d-fd30-4e6e-92ca-8964160ad9c9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-71b2872d-fd30-4e6e-92ca-8964160ad9c9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-71b2872d-fd30-4e6e-92ca-8964160ad9c9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"tds\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"Round\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Round 6\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sample size\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 1416,\n        \"max\": 1416,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1416\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Agreement\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.98,\n        \"max\": 0.98,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.98\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"K's Alpha\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"0.78 CI = (0.73, 0.84)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"K's Alpha significance\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"z = 27.16; p < 0.001\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Gwet's AC1\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"0.98 CI = (0.97, 0.98)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Gwet's AC1 significance\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"z = 314.46; p < 0.001\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Computation\n",
        "\n",
        "This stage reports the development of three classifiers and their testing on the validation data. The development stage reports the accuracy statistics across 21 different attempts to improve the classifiers' performance on the training data.\n",
        "\n",
        "The three classifiers are:\n",
        "\n",
        "1. A rule-based dictionary classifier\n",
        "\n",
        "This classifier labels a text as misunderstandings if it identifies any of a pre-defined set of words (the dictionary).\n",
        "\n",
        "We use this for binary classification. However, it can be used for producing a ratio or frequency count of the words. In this case, a ratio is pointless as the short sentences almost never contain two words relating to misunderstandings. The frequency count will mostly be 1 or 0, and therefore a binary classification. Ratios offer more information for longer texts, as these would generate more word counts.  \n",
        "\n",
        "2. A supervised machine learning classifier\n",
        "\n",
        "This classifier fine-tunes a BERT ([Devlin et al., 2019](https://arxiv.org/abs/1810.04805)) model using the ktrain packages. We also plot the increasing accuracy from the development stage as we explored the use of different parameters.\n",
        "\n",
        "3. A large language model (LLM) classifier\n",
        "\n",
        "This classifier sends a prompt to GPT-4o (version May 13, 2024) alongside the text to label. It's response is then processed into a binary classification. This is also known as zero-shot or few-shot classification, named after how many empirical examples are included in the prompt ([Brown et al., 2020](https://arxiv.org/abs/2005.14165)).\n",
        "\n"
      ],
      "metadata": {
        "id": "fivY_6dpkrZ8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1 Input"
      ],
      "metadata": {
        "id": "oYZCmJ-lkv6g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Information on the validation data = binary column is misunderstandings.\n",
        "tds = TextDataStats(validation)\n",
        "print(tds.BasicReport())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1HJN3au5YIyH",
        "outputId": "64041305-f6f0-4040-a29d-0054f7a508ee"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text Data Statistics Report\n",
            "\n",
            "General Statistics:\n",
            "        word_count\n",
            "mean         14.97\n",
            "std          11.71\n",
            "min           0.00\n",
            "median       12.00\n",
            "max         203.00\n",
            "\n",
            "Statistics by Binary Column:\n",
            "\n",
            "Group: 0\n",
            "word_count  mean       14.90\n",
            "            median     12.00\n",
            "            std        11.68\n",
            "            min         0.00\n",
            "            max       203.00\n",
            "\n",
            "Group: 1\n",
            "word_count  mean      15.82\n",
            "            median    12.00\n",
            "            std       12.09\n",
            "            min        2.00\n",
            "            max       80.00\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "These are the spaCy terms for the rule-based classifier:"
      ],
      "metadata": {
        "id": "CUln424LEQSK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "terms = [{\"label\":\"MISUNDERSTANDING\",\"pattern\":[{\"LOWER\":{\"IN\":[\"what\",\"why\"]}},{\"OP\":\"*\",\"POS\":\"AUX\"},{\"POS\":\"VERB\",\"OP\":\"*\"},{\"IS_PUNCT\":True,\"OP\":\"?\"}]},\n",
        "          {\"label\":\"MISUNDERSTANDING\",\"pattern\":[{\"LOWER\":\"what\"},{\"LOWER\":\"do\"},{\"LOWER\":\"you\"},{\"LOWER\":\"mean\"},{\"IS_PUNCT\":True,\"OP\":\"?\"}]},\n",
        "            {\"label\":\"MISUNDERSTANDING\",\"pattern\":[{\"LOWER\":\"could\"},{\"LOWER\":\"you\"},{\"LEMMA\":{\"IN\":[\"elaborate\",\"expand\",\"explain\"]}},{\"OP\":\"?\",\"IS_PUNCT\":True}]},\n",
        "             {\"label\":\"MISUNDERSTANDING\",\"pattern\":[{\"LOWER\":\"i\"},{\"LOWER\":\"don't\"},{\"LEMMA\":\"understand\"}]},\n",
        "              {\"label\":\"MISUNDERSTANDING\",\"pattern\":[{\"LOWER\":{\"IN\":[\"sorry\",\"pardon\",\"excuse\"]}},{\"LOWER\":\"me\"},{\"LOWER\":\"could\"},{\"LOWER\":\"you\"},{\"LOWER\":\"repeat\"},{\"OP\":\"?\",\"IS_PUNCT\":True}]},\n",
        "               {\"label\":\"MISUNDERSTANDING\",\"pattern\":[{\"LOWER\":\"are\"},{\"LOWER\":\"you\"},{\"LOWER\":\"saying\"},{\"IS_ALPHA\":True,\"OP\":\"+\"},{\"OP\":\"?\",\"IS_PUNCT\":True}]},\n",
        "                {\"label\":\"MISUNDERSTANDING\",\"pattern\":[{\"LEMMA\":{\"IN\":[\"misinterpret\",\"misunderstand\",\"misconstrue\"]}},{\"POS\":\"ADP\"},{\"IS_ALPHA\":True,\"OP\":\"+\"}]},\n",
        "                 {\"label\":\"MISUNDERSTANDING\",\"pattern\":[{\"LOWER\":{\"IN\":[\"did\",\"do\",\"does\"]}},{\"LOWER\":\"you\"},{\"LEMMA\":\"mean\"},{\"OP\":\"?\",\"IS_PUNCT\":True}]},\n",
        "                  {\"label\":\"MISUNDERSTANDING\",\"pattern\":[{\"LOWER\":\"let's\"},{\"LOWER\":\"talk\"},{\"LOWER\":\"about\"},{\"IS_ALPHA\":True,\"OP\":\"+\"}]},\n",
        "                   {\"label\":\"MISUNDERSTANDING\",\"pattern\":[{\"LOWER\":\"to\"},{\"LOWER\":\"clarify\"},{\"OP\":\"?\",\"IS_PUNCT\":True}]}]"
      ],
      "metadata": {
        "id": "iFGXqvH9kubG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is the pre-trained BERT model for the supervised classifier (trained on 90% of the training data - the remaining 10% were used to monitor its accuracy)."
      ],
      "metadata": {
        "id": "YHkOiOmKEWBC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictor = ktrain.load_predictor('supervised_model')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JonSwZrcEV2M",
        "outputId": "b522d69d-db75-48ad-cc7f-90bce2ab190c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/initializers/initializers.py:120: UserWarning: The initializer GlorotNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initializer instance more than once.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is the prompt for the LLM classifier:"
      ],
      "metadata": {
        "id": "ZUFUiABGETYf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "role = \"\"\"\n",
        "*Role* You are a research assistant tasked with identifying whether a sentence indicates a misunderstanding.\n",
        "*Misunderstanding definition* A misunderstanding occurs during dialogue when one participant has an incorrect understanding of another’s perspective.\n",
        "\"\"\"\n",
        "prompt = \"\"\"\n",
        "There are two categories of misunderstanding:\n",
        "1. “Direct” misunderstandings. These occur when a participant evidences a misunderstanding of another participant’s point.\n",
        "2. “Felt” misunderstandings. These occur when a participant feels their previous turn was misunderstood by another participant.\n",
        "This is a non-exhaustive list of possible sentences indicating misunderstanding.\n",
        "1. Explicit statement: The sentence explicitly indicates the speaker doesn't understand another’s perspective (e.g., \"I don't get what you're trying to say about the dog\")\n",
        "2. Clarification question: The question seeks to clarify the other’s perspective (e.g., \"What do you mean?\")\n",
        "3. Request for confirmation: A question that seeks confirmation on the other’s understanding of the speaker’s previous turn(e.g., \"You really think that I meant all dogs?\")\n",
        "4. Correction of Other: Correcting another speaker’s misunderstanding of the present speaker’s previous turn(e.g., \"You've misunderstood my point\", “You don’t get it.”)\n",
        "5. Clarification or apology about speaker's intentions: Clarifying the meaning of what the speaker previously said (e.g., \"Sorry, I meant to say X\")\n",
        "6. Misunderstanding due to lack of response (e.g., \"Why did you change the subject?\")\n",
        "7. Editing a message at a later time: This is when a speaker in text-based dialogue comes back to edit their comment after the fact (e.g., \"EDIT\": That's what I said)\n",
        "Here are some examples of sentences indicating misunderstandings:\n",
        "- Jane, that article was what I was talking about.\n",
        "- Why not go further? - Do you think that was ok?\n",
        "- I apologise for saying that, but I meant the other stuff.\n",
        "- @John But when? - @John Please tell me why I've been stuck here for so long.\n",
        "- What drove that thought? - I actually said \"sure thing\".\n",
        "- You serious?\n",
        "- I'm not sure what I could have done differently.\n",
        "TASK:\n",
        "Does the below sentence indicate a possible misunderstanding?\n",
        "Only respond with \"Yes\" or \"No\"\n",
        "Sentence: {}\n",
        "Response:\"\"\""
      ],
      "metadata": {
        "id": "IjUet6QSkz1m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2 Throughput"
      ],
      "metadata": {
        "id": "KBCsSzjWk1EW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "These two plots show the classifier performance according to (1) Matthews Correlation Coefficient (MCC) (2) Weighted F1 for the classifier.\n",
        "\n",
        "Each point indicates a change in the input parameters of the classifier. For the rule-based classifier, this was adding and altering the words. For the supervised classifier, this was altering the hyper-parameters. For the few-shot classifier, this was changing the prompt."
      ],
      "metadata": {
        "id": "vKwY5i75e2Gu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def matthews_correlation_coefficient(tp, tn, fp, fn):\n",
        "    numerator = (tp * tn) - (fp * fn)\n",
        "    denominator = ((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn)) ** 0.5\n",
        "    if denominator == 0:\n",
        "        return 0  # Undefined MCC, return 0 as a safe default\n",
        "    return numerator / denominator"
      ],
      "metadata": {
        "id": "JD6YZv1_vIxr"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_cols = [\"Order\",\"Classifier\",\"F1_avg\",\"F1_var\",\"AUC_PR\", \"AUC_ROC\",\"Precision\",\"Recall\",\"FP\",\"FN\",\"TP\",\"TN\"]\n",
        "ThroughRes = St2Through[target_cols].round(2).sort_values(\"AUC_PR\", ascending = False)\n",
        "ThroughRes[\"Matthews Correlation Coefficient\"] = ThroughRes.apply(lambda row: matthews_correlation_coefficient(row[\"TP\"],row[\"TN\"],row[\"FP\"],row[\"FN\"]), axis=1)\n",
        "ThroughRes = ThroughRes.rename(columns={\"F1_avg\": \"Weighted F1\"})\n",
        "tdf = ThroughRes.sort_values(by=[\"Order\",\"Classifier\"])"
      ],
      "metadata": {
        "id": "F6s6eqmsvw-3"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tdf = tdf.replace({\"few-shot\":\"LLM\"})\n",
        "tds = TextDataStats(tdf)\n",
        "tds.RAMP_plot(\"Order\", \"Matthews Correlation Coefficient\",\"Classifier\", width=1100,height=700, font_size = 20, tick_size=17)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 876
        },
        "id": "VlRkLaBcfABm",
        "outputId": "c7dfc81c-5f7e-43fa-ae59-550b2ccf284b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/plotly/express/_core.py:1971: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
            "  grouped = df.groupby(required_grouper, sort=False)  # skip one_group groupers\n",
            "/usr/local/lib/python3.10/dist-packages/plotly/express/_core.py:1992: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
            "  sf: grouped.get_group(s if len(s) > 1 else s[0])\n",
            "<ipython-input-6-2ea9dbe75de7>:225: FutureWarning:\n",
            "\n",
            "The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"44b83daa-6b69-4e66-9436-e1625f32db39\" class=\"plotly-graph-div\" style=\"height:700px; width:1100px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"44b83daa-6b69-4e66-9436-e1625f32db39\")) {                    Plotly.newPlot(                        \"44b83daa-6b69-4e66-9436-e1625f32db39\",                        [{\"hovertemplate\":\"Classifier=LLM\\u003cbr\\u003eOrder=%{x}\\u003cbr\\u003eMatthews Correlation Coefficient=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"LLM\",\"line\":{\"color\":\"#77B5FE\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"markers+lines\",\"name\":\"LLM\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21],\"xaxis\":\"x\",\"y\":[0.04155057467859536,0.23253419377124737,0.2872648322419155,0.3788620955042638,0.45050226031417195,0.45622944725159137,0.4388519509665063,0.4297266920675937,0.43390417958812666,0.4226985961116316,0.38181025231378946,0.37195016180963997,0.5103408004015701,0.4513002843209721,0.4223994623196093,0.3760396575601762,0.4100377518375483,0.44933985572791046,0.4867082070959006,0.4396002217946111,0.4469235978386974],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":\"Classifier=rule-based\\u003cbr\\u003eOrder=%{x}\\u003cbr\\u003eMatthews Correlation Coefficient=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"rule-based\",\"line\":{\"color\":\"#FF6961\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"markers+lines\",\"name\":\"rule-based\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21],\"xaxis\":\"x\",\"y\":[0.015568081914519931,0.06295492360573066,0.12544249960349563,0.1339989857899664,0.18756566942339511,0.20992750561486523,0.20992750561486523,0.21061803720203995,0.21061803720203995,0.2133748599824115,0.2133748599824115,0.21406274533684738,0.21406274533684738,0.21526051222535336,0.17458096995085534,0.15103669048887527,0.187213025740682,0.13644631346657118,0.1883649275156507,0.17092233631676323,0.1814268484369643],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":\"Classifier=supervised\\u003cbr\\u003eOrder=%{x}\\u003cbr\\u003eMatthews Correlation Coefficient=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"supervised\",\"line\":{\"color\":\"#B19CD9\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"markers+lines\",\"name\":\"supervised\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21],\"xaxis\":\"x\",\"y\":[0.5754351411550477,0.5861444096527617,0.5904565786928206,0.6107896411354067,0.6374342425993592,0.6313637360269997,0.6164541426816715,0.6327040852450997,0.6442486824149336,0.6153172923741053,0.6143894156366835,0.6376964437031357,0.6280373432660777,0.5987459987395344,0.6063771273032497,0.5912067350962279,0.6416549304497944,0.6174259758483488,0.6220384979247013,0.6467041398429002,0.623007382245237],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"line\":{\"color\":\"#77B5FE\",\"dash\":\"dash\",\"width\":2},\"mode\":\"lines\",\"name\":\"LLM - Range Line\",\"opacity\":0.5,\"showlegend\":false,\"x\":[1,21],\"y\":[0.04155057467859536,0.4469235978386974],\"type\":\"scatter\"},{\"line\":{\"color\":\"#FF6961\",\"dash\":\"dash\",\"width\":2},\"mode\":\"lines\",\"name\":\"rule-based - Range Line\",\"opacity\":0.5,\"showlegend\":false,\"x\":[1,21],\"y\":[0.015568081914519931,0.1814268484369643],\"type\":\"scatter\"},{\"line\":{\"color\":\"#B19CD9\",\"dash\":\"dash\",\"width\":2},\"mode\":\"lines\",\"name\":\"supervised - Range Line\",\"opacity\":0.5,\"showlegend\":false,\"x\":[1,21],\"y\":[0.5754351411550477,0.623007382245237],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Order\",\"font\":{\"size\":20}},\"tickfont\":{\"size\":17}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Matthews Correlation Coefficient\",\"font\":{\"size\":20}},\"tickfont\":{\"size\":17}},\"legend\":{\"title\":{\"text\":\"Classifier\"},\"tracegroupgap\":0,\"font\":{\"size\":20}},\"margin\":{\"t\":60},\"title\":{\"font\":{\"size\":20},\"text\":\"\"},\"width\":1100,\"height\":700},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('44b83daa-6b69-4e66-9436-e1625f32db39');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tds.RAMP_plot(\"Order\", \"Weighted F1\",\"Classifier\", width=1100,height=700)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 945
        },
        "id": "TDcsjlrFfDkU",
        "outputId": "018985b7-6520-4fe3-82a4-a1b109f49053"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/plotly/express/_core.py:1971: FutureWarning:\n",
            "\n",
            "The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/plotly/express/_core.py:1992: FutureWarning:\n",
            "\n",
            "When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
            "\n",
            "<ipython-input-6-2ea9dbe75de7>:225: FutureWarning:\n",
            "\n",
            "The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"33c36f15-26b4-483a-98e6-80132337fd4d\" class=\"plotly-graph-div\" style=\"height:700px; width:1100px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"33c36f15-26b4-483a-98e6-80132337fd4d\")) {                    Plotly.newPlot(                        \"33c36f15-26b4-483a-98e6-80132337fd4d\",                        [{\"hovertemplate\":\"Classifier=LLM\\u003cbr\\u003eOrder=%{x}\\u003cbr\\u003eWeighted F1=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"LLM\",\"line\":{\"color\":\"#77B5FE\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"markers+lines\",\"name\":\"LLM\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21],\"xaxis\":\"x\",\"y\":[0.79,0.78,0.86,0.87,0.88,0.91,0.88,0.88,0.87,0.88,0.88,0.86,0.91,0.91,0.88,0.84,0.87,0.9,0.91,0.88,0.9],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":\"Classifier=rule-based\\u003cbr\\u003eOrder=%{x}\\u003cbr\\u003eWeighted F1=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"rule-based\",\"line\":{\"color\":\"#FF6961\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"markers+lines\",\"name\":\"rule-based\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21],\"xaxis\":\"x\",\"y\":[0.85,0.85,0.82,0.81,0.82,0.87,0.87,0.87,0.87,0.87,0.87,0.87,0.87,0.87,0.83,0.79,0.78,0.78,0.76,0.75,0.74],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":\"Classifier=supervised\\u003cbr\\u003eOrder=%{x}\\u003cbr\\u003eWeighted F1=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"supervised\",\"line\":{\"color\":\"#B19CD9\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"markers+lines\",\"name\":\"supervised\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21],\"xaxis\":\"x\",\"y\":[0.93,0.93,0.93,0.93,0.94,0.94,0.93,0.94,0.94,0.93,0.93,0.94,0.93,0.93,0.93,0.93,0.94,0.93,0.93,0.94,0.93],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"line\":{\"color\":\"#77B5FE\",\"dash\":\"dash\",\"width\":2},\"mode\":\"lines\",\"name\":\"LLM - Range Line\",\"opacity\":0.5,\"showlegend\":false,\"x\":[1,21],\"y\":[0.79,0.9],\"type\":\"scatter\"},{\"line\":{\"color\":\"#FF6961\",\"dash\":\"dash\",\"width\":2},\"mode\":\"lines\",\"name\":\"rule-based - Range Line\",\"opacity\":0.5,\"showlegend\":false,\"x\":[1,21],\"y\":[0.85,0.74],\"type\":\"scatter\"},{\"line\":{\"color\":\"#B19CD9\",\"dash\":\"dash\",\"width\":2},\"mode\":\"lines\",\"name\":\"supervised - Range Line\",\"opacity\":0.5,\"showlegend\":false,\"x\":[1,21],\"y\":[0.93,0.93],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Order\",\"font\":{\"size\":14}},\"tickfont\":{\"size\":12}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Weighted F1\",\"font\":{\"size\":14}},\"tickfont\":{\"size\":12}},\"legend\":{\"title\":{\"text\":\"Classifier\"},\"tracegroupgap\":0,\"font\":{\"size\":14}},\"margin\":{\"t\":60},\"title\":{\"font\":{\"size\":14},\"text\":\"\"},\"width\":1100,\"height\":700},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('33c36f15-26b4-483a-98e6-80132337fd4d');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can call up the best classifiers of each type, alongside any relevant input parameters. The rule-based words are the ones defined in Section 2.1."
      ],
      "metadata": {
        "id": "-cB39tKxVoMa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Best supervised classifier and parameters\n",
        "St2Through[\"MCC\"] = St2Through.apply(lambda row: matthews_correlation_coefficient(row[\"TP\"],row[\"TN\"],row[\"FP\"],row[\"FN\"]), axis=1)\n",
        "supdf = St2Through[[\"Order\",\"Classifier\",\"F1_avg\",\"AUC_PR\", \"MCC\",\"Precision\",\"Recall\",\"validation_size\",\"epochs\",\"learning_rate\",\"batch_size\"]]\n",
        "supdf[supdf[\"Classifier\"]==\"supervised\"].sort_values(\"MCC\", ascending = False).head(1).round(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "H7ct4xwOb7JI",
        "outputId": "4b49d203-4836-4b83-9619-0beeaff71133"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Order  Classifier  F1_avg  AUC_PR   MCC  Precision  Recall  \\\n",
              "61     20  supervised    0.94     0.7  0.65       0.74    0.62   \n",
              "\n",
              "    validation_size  epochs  learning_rate  batch_size  \n",
              "61              0.3     4.0            0.0       128.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-64821144-394a-4511-abb3-3b0bd6bd992d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Order</th>\n",
              "      <th>Classifier</th>\n",
              "      <th>F1_avg</th>\n",
              "      <th>AUC_PR</th>\n",
              "      <th>MCC</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>validation_size</th>\n",
              "      <th>epochs</th>\n",
              "      <th>learning_rate</th>\n",
              "      <th>batch_size</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>20</td>\n",
              "      <td>supervised</td>\n",
              "      <td>0.94</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.74</td>\n",
              "      <td>0.62</td>\n",
              "      <td>0.3</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>128.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-64821144-394a-4511-abb3-3b0bd6bd992d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-64821144-394a-4511-abb3-3b0bd6bd992d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-64821144-394a-4511-abb3-3b0bd6bd992d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"supdf[supdf[\\\"Classifier\\\"]==\\\"supervised\\\"]\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"Order\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 20,\n        \"max\": 20,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          20\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Classifier\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"supervised\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1_avg\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.94,\n        \"max\": 0.94,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.94\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AUC_PR\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.7,\n        \"max\": 0.7,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MCC\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.65,\n        \"max\": 0.65,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.65\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.74,\n        \"max\": 0.74,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.74\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.62,\n        \"max\": 0.62,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.62\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"validation_size\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.3,\n        \"max\": 0.3,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"epochs\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 4.0,\n        \"max\": 4.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          4.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"learning_rate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"batch_size\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 128.0,\n        \"max\": 128.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          128.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Best rule-based classifier (using lemma list)\n",
        "rbdf = St2Through[[\"Order\",\"Classifier\",\"F1_avg\",\"AUC_PR\",\"MCC\", \"Precision\",\"Recall\",\"PatternOrLemma\",\"train_size\",\"nTerms\"]]\n",
        "rbdf[rbdf[\"Classifier\"]==\"rule-based\"].sort_values(\"MCC\", ascending = False).head(1).round(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "evTmH1ZWdVRO",
        "outputId": "0d98e950-9c89-44d0-e64e-8b3cd3545b46"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Order  Classifier  F1_avg  AUC_PR   MCC  Precision  Recall PatternOrLemma  \\\n",
              "34     14  rule-based    0.87    0.32  0.22       0.33    0.24        pattern   \n",
              "\n",
              "    train_size  nTerms  \n",
              "34       14728    10.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ba69e434-ec09-42bb-9576-63a544fe14ac\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Order</th>\n",
              "      <th>Classifier</th>\n",
              "      <th>F1_avg</th>\n",
              "      <th>AUC_PR</th>\n",
              "      <th>MCC</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>PatternOrLemma</th>\n",
              "      <th>train_size</th>\n",
              "      <th>nTerms</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>14</td>\n",
              "      <td>rule-based</td>\n",
              "      <td>0.87</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.33</td>\n",
              "      <td>0.24</td>\n",
              "      <td>pattern</td>\n",
              "      <td>14728</td>\n",
              "      <td>10.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ba69e434-ec09-42bb-9576-63a544fe14ac')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ba69e434-ec09-42bb-9576-63a544fe14ac button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ba69e434-ec09-42bb-9576-63a544fe14ac');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"rbdf[rbdf[\\\"Classifier\\\"]==\\\"rule-based\\\"]\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"Order\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 14,\n        \"max\": 14,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          14\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Classifier\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"rule-based\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1_avg\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.87,\n        \"max\": 0.87,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.87\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AUC_PR\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.32,\n        \"max\": 0.32,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.32\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MCC\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.22,\n        \"max\": 0.22,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.22\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.33,\n        \"max\": 0.33,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.33\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.24,\n        \"max\": 0.24,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.24\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"PatternOrLemma\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"pattern\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"train_size\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 14728,\n        \"max\": 14728,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          14728\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"nTerms\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 10.0,\n        \"max\": 10.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          10.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Best LLM classifiers (using prompt)\n",
        "rbdf = St2Through[[\"Order\",\"Classifier\",\"F1_avg\",\"AUC_PR\", \"MCC\",\"Precision\",\"Recall\", \"train_size\",\"GPTmodel\"]]\n",
        "rbdf[rbdf[\"Classifier\"]==\"few-shot\"].sort_values(\"MCC\", ascending = False).head(1).round(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "q34Rv6ofehT9",
        "outputId": "96c38409-379e-489f-c09b-efb0ebd0bd1a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Order Classifier  F1_avg  AUC_PR   MCC  Precision  Recall  train_size  \\\n",
              "12     13   few-shot    0.91    0.58  0.51       0.54    0.59        1000   \n",
              "\n",
              "       GPTmodel  \n",
              "12  gpt-4-turbo  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9205df4f-9a89-4f00-a06b-c1fbb2ccbc2f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Order</th>\n",
              "      <th>Classifier</th>\n",
              "      <th>F1_avg</th>\n",
              "      <th>AUC_PR</th>\n",
              "      <th>MCC</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>train_size</th>\n",
              "      <th>GPTmodel</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>13</td>\n",
              "      <td>few-shot</td>\n",
              "      <td>0.91</td>\n",
              "      <td>0.58</td>\n",
              "      <td>0.51</td>\n",
              "      <td>0.54</td>\n",
              "      <td>0.59</td>\n",
              "      <td>1000</td>\n",
              "      <td>gpt-4-turbo</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9205df4f-9a89-4f00-a06b-c1fbb2ccbc2f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9205df4f-9a89-4f00-a06b-c1fbb2ccbc2f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9205df4f-9a89-4f00-a06b-c1fbb2ccbc2f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"rbdf[rbdf[\\\"Classifier\\\"]==\\\"few-shot\\\"]\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"Order\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 13,\n        \"max\": 13,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          13\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Classifier\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"few-shot\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1_avg\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.91,\n        \"max\": 0.91,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.91\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AUC_PR\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.58,\n        \"max\": 0.58,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.58\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MCC\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.51,\n        \"max\": 0.51,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.51\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.54,\n        \"max\": 0.54,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.54\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.59,\n        \"max\": 0.59,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.59\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"train_size\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 1000,\n        \"max\": 1000,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1000\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"GPTmodel\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"gpt-4-turbo\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.3 Output"
      ],
      "metadata": {
        "id": "jivZGllok5VD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3.1 Classification reports\n",
        "\n",
        "The below prints the classification reports from our final classifiers on the validation dataset."
      ],
      "metadata": {
        "id": "kSU0RKIlm_9L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texts = out.text.to_list()\n",
        "true_scores = out.Misunderstanding.to_list()\n",
        "pred_scores = out[\"rule-based\"].to_list()\n",
        "rbClassifier = Classifier(texts, true_scores)\n",
        "rbClassifier.add_pred_scores(pred_scores)\n",
        "rbClassifier.get_model_report()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHW4dkLfs2Ff",
        "outputId": "d895b92a-d2d5-46a6-f4f7-dce96288a289"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC-PR: 0.31\n",
            "\n",
            "AUC-ROC: 0.61\n",
            "\n",
            "MCC: 0.22\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.94      0.94      5909\n",
            "           1       0.29      0.27      0.28       511\n",
            "\n",
            "    accuracy                           0.89      6420\n",
            "   macro avg       0.62      0.61      0.61      6420\n",
            "weighted avg       0.89      0.89      0.89      6420\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Rule-based classifier - unhash to replicate the analysis\n",
        "#out = validation.copy()\n",
        "#texts = out.text.to_list()\n",
        "#true_scores = out.Misunderstanding.to_list()\n",
        "#rbClassifier = Classifier(texts, true_scores)\n",
        "#rbClassifier.add_rule_based_terms(terms, 'pattern')\n",
        "#rbClassifier.run_classifier()\n",
        "#rbClassifier.get_model_report()"
      ],
      "metadata": {
        "id": "AdfORjN8k9aW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "true_scores = out.Misunderstanding.to_list()\n",
        "pred_scores = out[\"supervised\"].to_list()\n",
        "smlClassifier = Classifier(texts, true_scores)\n",
        "smlClassifier.add_pred_scores(pred_scores)\n",
        "smlClassifier.get_model_report()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9VamfnintTnd",
        "outputId": "426fccf7-fac5-418e-c88d-45877098eb09"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC-PR: 0.73\n",
            "\n",
            "AUC-ROC: 0.88\n",
            "\n",
            "MCC: 0.69\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.96      0.97      5909\n",
            "           1       0.65      0.79      0.71       511\n",
            "\n",
            "    accuracy                           0.95      6420\n",
            "   macro avg       0.81      0.88      0.84      6420\n",
            "weighted avg       0.95      0.95      0.95      6420\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For supervised machine learning classifier\n",
        "#smlClassifier = Classifier(texts, true_scores)\n",
        "#smlClassifier.add_SML_classifier(predictor)\n",
        "#smlClassifier.run_classifier()\n",
        "#smlClassifier.get_model_report()"
      ],
      "metadata": {
        "id": "thvSe0cmt4yY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "true_scores = out.Misunderstanding.to_list()\n",
        "pred_scores = out[\"few-shot\"].to_list()\n",
        "fsClassifier = Classifier(texts, true_scores)\n",
        "fsClassifier.add_pred_scores(pred_scores)\n",
        "fsClassifier.get_model_report()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MOraUzYyte_y",
        "outputId": "0a7ec3c1-7339-4d48-e105-e624f576fcfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/spacy/util.py:1740: UserWarning: [W111] Jupyter notebook detected: if using `prefer_gpu()` or `require_gpu()`, include it in the same cell right before `spacy.load()` to ensure that the model is loaded on the correct device. More information: http://spacy.io/usage/v3#jupyter-notebook-gpu\n",
            "  warnings.warn(Warnings.W111)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC-PR: 0.56\n",
            "\n",
            "AUC-ROC: 0.80\n",
            "\n",
            "MCC: 0.47\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.91      0.94      5909\n",
            "           1       0.39      0.69      0.50       511\n",
            "\n",
            "    accuracy                           0.89      6420\n",
            "   macro avg       0.68      0.80      0.72      6420\n",
            "weighted avg       0.93      0.89      0.90      6420\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LLM classifier\n",
        "#gpt_model = \"gpt-4o\"\n",
        "#fsClassifier = Classifier(texts, true_scores)\n",
        "#fsClassifier.add_few_shot_classifier(gpt_model, prompt, role)\n",
        "#fsClassifier.run_classifier()\n",
        "#fsClassifier.get_model_report()"
      ],
      "metadata": {
        "id": "9OWU-c9Xt9aw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#out[\"rule-based\"] = rbClassifier.pred_scores\n",
        "#out[\"supervised\"] = smlClassifier.pred_scores\n",
        "#out[\"few-shot\"] = fsClassifier.pred_scores\n",
        "#out.to_csv(\"RAMP_Stage2Output_v2.csv\",index=False)"
      ],
      "metadata": {
        "id": "iv3FQ3-snIdm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Evaluation\n",
        "\n",
        "This section looks at disagreements and misclassifications in order to inform the final stage of RAMP. These are used to infer surprising findings from which to identify potential problems of construct and concept validity.\n",
        "\n",
        "This analysis is qualitative and is informed by the below disagreements and misclassifications"
      ],
      "metadata": {
        "id": "5QvklA8-nEJT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1 Disagreements evaluation"
      ],
      "metadata": {
        "id": "j4wwlA44mblb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get sample of disagreements\n",
        "tds = TextDataStats(IRR_final)\n",
        "tds.get_disagreements(25)"
      ],
      "metadata": {
        "id": "TKmaQbQ8mgYh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7458db7-d719-434a-c525-6c982d3a4c2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------\n",
            "In any case, everyone has different things they find satisfying to do on Wikipedia; why don't you spend time on things that give you pleasure?\n",
            "----------\n",
            "@Ask_Spectrum I've gave your company enough of my patience ive had enough, you just lost a customer!.\n",
            "----------\n",
            "Update: as a few have pointed out, the term racist was a poor choice of words.\n",
            "----------\n",
            "this is amc, but i feel you\n",
            "----------\n",
            "Well, I'm not talking about Western Sahara specifically.\n",
            "----------\n",
            "We wouldn't be able to comment further than what was discussed yesterday, until Omniserve come back.\n",
            "----------\n",
            "The rest not so rightÔ£ø√º√≤√ë thanks for correcting me!\n",
            "----------\n",
            "The article is actually a lot better and resourceful than it originally appeared but I believe my edits have improved it, even if I picked up a few horses in Jutland rather than Jutland horse and probably needed minor copyedits.\n",
            "----------\n",
            "Why go from zero to 100 today?\n",
            "----------\n",
            "I mean is there proof for that third one?\n",
            "----------\n",
            "You seem to have misread the guidelines.\n",
            "----------\n",
            "Are you suggesting otherwise?\n",
            "----------\n",
            "I forgot that we are on earth and that there are forces applied on objects that arent present in space lol.\n",
            "----------\n",
            "Now it's clear to me.\n",
            "----------\n",
            "The discrepancy between the UK self-esteem and the view the rest of the world has.\n",
            "----------\n",
            "Rather, the point I'm making is that you're applying an overly-simplified lens to this.\n",
            "----------\n",
            "If part of your point relates to the idea that religion makes it so you don't question the belief system and also divides people up into different groups by virtue of being a different religion then that could be true but even post religious societies have that aspect such as nationalism.\n",
            "----------\n",
            "Why now?\n",
            "----------\n",
            "So the service is worse than usual but its more expensive to travel?\n",
            "----------\n",
            "I understand that, but we don't need twenty plus pages to solve that problem.\n",
            "----------\n",
            "However on looking at the relevant AN\\/I section, discussion on it appears to have dried up, and given the topic of the dispute and its sheer irrelevance to anything remotely related to making Barack Obama an encyclopaedic article, and given some editors' (on both sides) single-minded obsession with the one article and the debates in and around it, I don't feel any great regrets about the action taken.\n",
            "----------\n",
            "What do you know?\n",
            "----------\n",
            "Now refusing to send elsewhere?\n",
            "----------\n",
            "So the article [[Jackal]] is wrong then?\n",
            "----------\n",
            "@361567 Hi, not to worry it will not be charged.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2 Misclassifications evaluation"
      ],
      "metadata": {
        "id": "Ym2-GFNumkRr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "out = out.rename(columns={\"Misunderstanding\":\"Manual\", \"few-shot\":\"LLM\"})"
      ],
      "metadata": {
        "id": "NRF8EStoCdmG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tds = TextDataStats(out)\n",
        "misdf = tds.get_misclassifications(return_all = True)"
      ],
      "metadata": {
        "id": "1e47fC2YZ1Gs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For printing rule-based misclassifications - these are fairly arbitrary\n",
        "for i in misdf[misdf[\"Manual\"]==1][misdf[\"rule-based\"]==0].sample(10).text.values:\n",
        "  print(i)"
      ],
      "metadata": {
        "id": "mhrPActSaBn0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3d434ab-2bf5-42ba-fab6-e83810cd2f24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "btw I'm not Ronald!\n",
            "hehe, whoops!\n",
            "No news is good news?\n",
            "@Company_Handle For the type of issue reported I thought I may have at least been contacted for some information.\n",
            "Do you steal from seniors too or just kids?\n",
            "Am I missing something?\n",
            "Isn't this to show pics we've taken??\n",
            "We don't think it is.\n",
            "Like John hasn't exhibited a consistent attitude conducive to collaboration?\n",
            "Oh, I see.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-3b1cc0282d4c>:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
            "  for i in misdf[misdf[\"Manual\"]==1][misdf[\"rule-based\"]==0].sample(10).text.values:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For supervised and few shot classifiers\n",
        "tds = TextDataStats(out)\n",
        "tds.get_misclassifications(n=25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7Fvi5Aenrj-",
        "outputId": "a5a72773-f585-4cbd-bc76-f8458dedefcf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- FP (All) count: -- 53\n",
            "--- FP (supervised) count: -- 111\n",
            "--- FP (LLM) count: -- 436\n",
            "--- FN (All) count: -- 111\n",
            "--- FN (supervised) count: -- 53\n",
            "--- FN (LLM) count: -- 0\n",
            "\n",
            "Printing 25 examples of each classifier type.\n",
            "\n",
            "------ FP (ALL) ------\n",
            "- Sure, do you want me to?\n",
            "- This is completely unacceptable and to worsen it is that you lot do not respond quick enough.\n",
            "- I am very patient as to what-will-happen-next, although I don't seem to manage it with spur-of-the-moment replies (oops).\n",
            "- I'm not really committed to extensive rewriting as it's only wiki and can be edited anyway.\n",
            "- I take that back.\n",
            "- hahahahaha my apologies\n",
            "- How can you fame a Wikipedian?\n",
            "- @Company_Handle @Company_Handle What type of ticket have you bought?\n",
            "- Again, Industry Canada is a reliable source, even if not the preferred one, and those numbers are much better than no numbers at all.\n",
            "- Anything you can do to make him believe that I mean no ill will would be very helpful.\n",
            "- For one i didn't even know the person \\\"personally\\\".\n",
            "- I thought it was a clear-cut case of \\\"notability not proven\\\" the way it stood, but if he can improve it, it's no problem as far as I'm concerned.\n",
            "- Hrafn's a constructive editor who is on my watchlist. . .\n",
            "- What's going on with the import script?\n",
            "- I want to know the cause of this delay.\n",
            "- I am the person that added all the attendances(at least most of it), I have no reason to fabricate attendances.\n",
            "- Thank you for explaining why, I withdraw my complaint.\n",
            "- Remember, I was just helping Michael with the ''Origin'', but ''Orchids'' was mostly me with a great deal of help from both of you.\n",
            "- I get there's no real answer but which option has more support?\n",
            "- No put stickers on things that changed the perception of them Like he would put a woodchuck sticker on the hand operated pencil sharpener and stickers that read, \"Lies?\" on the globe because despite being a science teacher he was a flat earther.\n",
            "- @Company_Handle Oh, okay.\n",
            "- I already have and he has done it multiple times.\n",
            "- It's not specific enough, I need something that doesn't require ps plus or Nintendo online\n",
            "- I don't really think it's necessary; I wouldn't have added the tag if I were editing the article by hand.\n",
            "- It was mostly the \\\"community\\\" name and the unprofessional look of the webpage that caused me to remove it, plus I was in \\\"mass-delete\\\" mode as I went through dozens of vehicle articles looking for links that obviously violated the guideline.\n",
            "--------\n",
            "------ FP (SUPERVISED) ------\n",
            "- A google time-stamped prophecy is neither an opinion, experience nor is it an argument, so I can't see how it is original research.\n",
            "- I also have to admit that running into you has made this avocation less than enjoyable as I seek to begin to respond to the grain and chaff issue I referred to in a previous edit.\n",
            "- This proves my point too.\n",
            "- Indonesian organisations with english names as title of article and the indonesian name as the aka please?\n",
            "- Which will be better??\n",
            "- Are you having this issue with any other channels?\n",
            "- I don't care about martyrdom, etc., or any dramas.\n",
            "- If you can't, it's no problem; I just thought I'd ask.\n",
            "- @Company_Handle I did not hear back from you yet.\n",
            "- Now you're just being uncivil and insulting.\n",
            "- I wanted to talk to them, but didn't know where to start.\n",
            "- I understand your frustration at seeing a lot of what you've created slowly whittled away, but [http:\\/\\/en.wikipedia.org\\/w\\/index.php?title=Suzi_Suzuki&curid=4775796&diff=437390137&oldid=437364401 this] is 100% pure [[WP:POINT]].\n",
            "- &#x200B; It is true that they are wrong, but how should they know?\n",
            "- It's me, again.\n",
            "- Like you, I wrote on what I know, so it was easy.\n",
            "- Oh no!!\n",
            "- I thought not.\n",
            "- But yes obviously that Facebook whatever stuff is actually wrong i just wanted to point out that an actual number for the death rate exists and has actually existed for many months\n",
            "- My phone been on 1x for 2 fucking days wtf is 1x?\n",
            "- Yes, please do that, if you change it to non consensus then it stops people quoting it as if it was decided by the review when it wasn't.- \n",
            "- Do you think its function could be impoved?\n",
            "- :-) On an unrelated note, I've obviously read your user page -- is your daughter killing you the same way ours is killing us?\n",
            "- No, he didn't.\n",
            "- Add it to the category pages?\n",
            "- Oh yeah!\n",
            "--------\n",
            "------ FP (LLM) ------\n",
            "- @Company_Handle We apologize for any confusion, it looks like this item sold out quickly!\n",
            "- And I am not some crazed guy out to mock and disrupt his life, regardless of what he says ot thinks.\n",
            "- But I do not think he really supports the semiprotection, neither does Sidaway or some other respected editors.\n",
            "- Where do you see the blog is sponsored by Parade Magazine.\n",
            "- Any clues as to how I can fix?\n",
            "- I have never once seen anyone on here mention anything about purchasing silver.\n",
            "- Thanks for the article, which does not in fact discuss ''how'' to distinguish empty matrices, although it does mention their distinctiveness.\n",
            "- @Company_Handle That's not okay.\n",
            "- They fought for you to be able to, not to require you to This phrase mostly comes up when you decide not to care about something someone else feels strongly about\n",
            "- Cant tell if that's the pilot or the undercarriage that gets fired out the front.\n",
            "- I was thinking the Piney Woods school article itself needed more additions, but you already did that too.\n",
            "- Just stop thinking your above others be you only listen to a few of biggie and Christopher's songs when you don't give anything else a try.\n",
            "- Don't fool yourself, that's what's going on.\n",
            "- If my words are not clear, please point out the parts which need further explaining.\n",
            "- @Company_Handle It say's I'm verified been when I click the user detail this is the next page.\n",
            "- So I continually request a discount that I'm entitled to with &amp; they don't give info.\n",
            "- @Company_Handle looks like am not only one having this issue!\n",
            "- There are bigger issues at hand - like maybe the fact that the masks are fake, not that the wearers are upset the masks are fake\n",
            "- I fail to see the danger.\n",
            "- (My memory might be wrong, but I'm sure I would not have allowed that photo to be used in the article without double-checking that it was okay.)\n",
            "- Hello, I have sent 2 coppies of my unblock request to arbcom, one in march, and one in early April, but no response, so I am seaking advice, what else is there for me to do, I'm totaly out of ideas and I have lost faith in wikipedia.\n",
            "- I don't recall EVER seeing how people also abandon their own parents when they're old.\n",
            "- @Company_Handle be nice though if the whole range was available esp in an Xtra store, I currently have to drive 10km to James for more choice.. @Company_Handle hi im interested in the new ones the peppercorn and \"goats\" cheese I already know where the existing Free From cheezes can.be got.\n",
            "- Please, could someone tell me what next?\n",
            "- As for your comment about Lisa Millerton people\\\", Wikipedia policy is that content is based on reliable sources, not what is insulting to any group of people (for example, we refer to that landlocked country north of East Michael as Harperport, even though that term seems to be offensive to many Greeks).\n",
            "--------\n",
            "------ FN (ALL) ------\n",
            "- Its happened a few times now.Is it supposed to be like that?\n",
            "- @Company_Handle That's so strange - clicked on the link and it isn't showing that late :( \n",
            "- So what about everyone else?\n",
            "- But why is that ideology so attractive?\n",
            "- @Company_Handle Will I still be getting a Scorpio editon?\n",
            "- I hope you didn't think it was serious.\n",
            "- I can't answer to all your questions since I don't think to have been involved in all the edits you talk about.\n",
            "- As for \\\"taking recentism to new heights\\\", I stand by that attack on the edit.\n",
            "- Was it still showing as downloading for you?\n",
            "- Belatedly, I've added the material I mentioned earlier concerning individual reactions to Laurie's books upon their publication.\n",
            "- Two flights in a row????\n",
            "- Does this mean that articles such as [[Duality (Song)]] and [[Mirrorcle World]] are invalid, as well as all of [[The Gazette]]'s other singles?\n",
            "- To customer CARE?\n",
            "- Is that right?\n",
            "- @Company_Handle ?\n",
            "- That's why I needed to double-check.\n",
            "- I was wondering this too, or if it's something you intentionally do to trick your brain?\n",
            "- > Okay, when I wrote this, I was a little too focused on deliberate acts of self expression rather than things people are born with.\n",
            "- I'm not saying don't thrift shop.\n",
            "- EDIT - wow, I can't spell apparently....\"known for being he Cofounder\" whoops.\n",
            "- why the elderly man refused hot coffee ?\n",
            "- @Company_Handle can you tell me why I was promised a manager call me in 1 hour &amp; they haven't?\n",
            "- @Company_Handle I haven't order anything from you guys!\n",
            "- Why is that?\n",
            "- Wtf was that ending?\n",
            "--------\n",
            "------ FN (SUPERVISED) ------\n",
            "- Not sure what that is\n",
            "- But... they do.\n",
            "- To the user whose page this is, examine the situation as you will, but I thought I'd leave my two cents when the person above is trying to portray me as someone out to ruin the article.\n",
            "- Mark, the experience you are describing is something we'd never do.\n",
            "- What am I doing?\n",
            "- How is this photo relevant to Rachel's life?\n",
            "- How does it make it make Wikipedia more user friendly to alter [[Natasha]] to [[Kelly of England|Henry VIII]]?\n",
            "- FA work is fine and I'm sure WMC could assist in non CC related article improvement but once a bulls eye get painted on anyone of this high a profile on this project, someone is always going to be the ready to play smackdown if such an editor so much as twitches \\\"incorrectly\\\"...my understanding as it was clarified to me was that user talkpages, even your own user talkpage are taboo for issues related to the topic ban.--\n",
            "- @Company_Handle I provided you all with the info 5 hours ago\n",
            "- @Company_Handle We are not the bots you are looking for.\n",
            "- That may be (one can never be sure), but the editors don't seem to understand the serious problems with the page.\n",
            "- Hold up.\n",
            "- Can you elaborate the implications of your argument?\n",
            "- @Company_Handle this is the enough apologies you have sent, it's enough to last me a life time .. clean up your mess \n",
            "- Might I ask you to check out my responses to the issues you raised, specifically the questions I asked about images?\n",
            "- The rest not so right thanks for correcting me!\n",
            "- Could you confirm If you have contacted the support team through link provided earlier?\n",
            "- Edit: this is for areas that don't normally get freezing temperatures, where houses aren't designed for those temperatures.\n",
            "- I guess you think more highly of userboxes than myself.\n",
            "- @Company_Handle What number are you dialing?\n",
            "- @Company_Handle This is the same trip.\n",
            "- so, if the national cancer... has cancer, what's the problem\n",
            "- I understand that, but we don't need twenty plus pages to solve that problem.\n",
            "- However, at the [[Talk:List of Farscape episodes#Upcoming Merge & Redirect per Wikipedia Guidelines & Notability Standards|''Farscape'' talk page]], you stated that I was ''Anthony\"'' with these same policies.\n",
            "- And what's wrong with reading through five+ paragraphs?\n",
            "--------\n",
            "------ FN (LLM) ------\n",
            "--------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2.1 Using LIME to explore BERT classifier"
      ],
      "metadata": {
        "id": "C6djwU6rmv6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For assessing the supervised classifier FN and FP\n",
        "predictor.explain(\"It's me, again\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "id": "IxRV_yhTa7J9",
        "outputId": "417a389d-0e44-4625-a068-84e5a3a8ccec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <style>\n",
              "    table.eli5-weights tr:hover {\n",
              "        filter: brightness(85%);\n",
              "    }\n",
              "</style>\n",
              "\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "        \n",
              "\n",
              "    \n",
              "\n",
              "        \n",
              "\n",
              "        \n",
              "    \n",
              "        \n",
              "        \n",
              "    \n",
              "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
              "            <b>\n",
              "    \n",
              "        y=Misunderstanding\n",
              "    \n",
              "</b>\n",
              "\n",
              "    \n",
              "    (probability <b>0.799</b>, score <b>1.378</b>)\n",
              "\n",
              "top features\n",
              "        </p>\n",
              "    \n",
              "    <table class=\"eli5-weights\"\n",
              "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
              "        <thead>\n",
              "        <tr style=\"border: none;\">\n",
              "            \n",
              "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
              "                    Contribution<sup>?</sup>\n",
              "                </th>\n",
              "            \n",
              "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
              "            \n",
              "        </tr>\n",
              "        </thead>\n",
              "        <tbody>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +2.777\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        Highlighted in text (sum)\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "        \n",
              "\n",
              "        \n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 87.63%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -1.399\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        &lt;BIAS&gt;\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "\n",
              "        </tbody>\n",
              "    </table>\n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n",
              "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
              "        <span style=\"background-color: hsl(120, 100.00%, 74.54%); opacity: 0.90\" title=\"1.709\">it</span><span style=\"opacity: 0.80\">&#x27;</span><span style=\"background-color: hsl(0, 100.00%, 92.22%); opacity: 0.82\" title=\"-0.314\">s</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 87.68%); opacity: 0.84\" title=\"0.606\">me</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(120, 100.00%, 60.00%); opacity: 1.00\" title=\"3.259\">again</span>\n",
              "    </p>\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictor.explain(\"Mark, the experience you are describing is something we'd never do.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "id": "-FSv-aABefP8",
        "outputId": "25634fc7-81f2-4613-f5bd-70a469c8c583"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <style>\n",
              "    table.eli5-weights tr:hover {\n",
              "        filter: brightness(85%);\n",
              "    }\n",
              "</style>\n",
              "\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "        \n",
              "\n",
              "    \n",
              "\n",
              "        \n",
              "\n",
              "        \n",
              "    \n",
              "        \n",
              "        \n",
              "    \n",
              "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
              "            <b>\n",
              "    \n",
              "        y=not_Misunderstanding\n",
              "    \n",
              "</b>\n",
              "\n",
              "    \n",
              "    (probability <b>0.701</b>, score <b>-0.850</b>)\n",
              "\n",
              "top features\n",
              "        </p>\n",
              "    \n",
              "    <table class=\"eli5-weights\"\n",
              "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
              "        <thead>\n",
              "        <tr style=\"border: none;\">\n",
              "            \n",
              "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
              "                    Contribution<sup>?</sup>\n",
              "                </th>\n",
              "            \n",
              "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
              "            \n",
              "        </tr>\n",
              "        </thead>\n",
              "        <tbody>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +1.272\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        &lt;BIAS&gt;\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "        \n",
              "\n",
              "        \n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 90.76%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -0.422\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        Highlighted in text (sum)\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "\n",
              "        </tbody>\n",
              "    </table>\n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n",
              "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
              "        <span style=\"background-color: hsl(0, 100.00%, 91.80%); opacity: 0.82\" title=\"-0.289\">mark</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(0, 100.00%, 87.58%); opacity: 0.84\" title=\"-0.523\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 84.45%); opacity: 0.85\" title=\"0.721\">experience</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 65.61%); opacity: 0.96\" title=\"-2.240\">you</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.54%); opacity: 0.82\" title=\"-0.252\">are</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 60.00%); opacity: 1.00\" title=\"-2.780\">describing</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 87.81%); opacity: 0.84\" title=\"-0.509\">is</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.96%); opacity: 0.81\" title=\"-0.144\">something</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 71.82%); opacity: 0.92\" title=\"-1.685\">we</span><span style=\"opacity: 0.80\">&#x27;</span><span style=\"background-color: hsl(120, 100.00%, 77.01%); opacity: 0.89\" title=\"1.260\">d</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 70.08%); opacity: 0.93\" title=\"-1.836\">never</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.63%); opacity: 0.81\" title=\"0.118\">do</span><span style=\"opacity: 0.80\">.</span>\n",
              "    </p>\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For assessing the supervised classifier FN and FP\n",
        "predictor.explain(\"Not sure what that is\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "id": "CmZKiXyCbTMC",
        "outputId": "bf9a779d-be21-45e5-9202-adbcf1ee0978"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <style>\n",
              "    table.eli5-weights tr:hover {\n",
              "        filter: brightness(85%);\n",
              "    }\n",
              "</style>\n",
              "\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "        \n",
              "\n",
              "    \n",
              "\n",
              "        \n",
              "\n",
              "        \n",
              "    \n",
              "        \n",
              "        \n",
              "    \n",
              "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
              "            <b>\n",
              "    \n",
              "        y=not_Misunderstanding\n",
              "    \n",
              "</b>\n",
              "\n",
              "    \n",
              "    (probability <b>0.432</b>, score <b>0.275</b>)\n",
              "\n",
              "top features\n",
              "        </p>\n",
              "    \n",
              "    <table class=\"eli5-weights\"\n",
              "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
              "        <thead>\n",
              "        <tr style=\"border: none;\">\n",
              "            \n",
              "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
              "                    Contribution<sup>?</sup>\n",
              "                </th>\n",
              "            \n",
              "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
              "            \n",
              "        </tr>\n",
              "        </thead>\n",
              "        <tbody>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 83.32%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +0.929\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        &lt;BIAS&gt;\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "        \n",
              "\n",
              "        \n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 80.00%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -1.204\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        Highlighted in text (sum)\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "\n",
              "        </tbody>\n",
              "    </table>\n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n",
              "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
              "        <span style=\"background-color: hsl(120, 100.00%, 81.83%); opacity: 0.86\" title=\"0.456\">not</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 71.37%); opacity: 0.92\" title=\"0.873\">sure</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 67.48%); opacity: 0.95\" title=\"-1.047\">what</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 60.00%); opacity: 1.00\" title=\"-1.407\">that</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 64.52%); opacity: 0.97\" title=\"-1.186\">is</span>\n",
              "    </p>\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For assessing the supervised classifier FN and FP\n",
        "predictor.explain(\"But... They do.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "id": "dWDBjWMGzCFk",
        "outputId": "2caca445-afc6-458c-c38e-067d452478d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <style>\n",
              "    table.eli5-weights tr:hover {\n",
              "        filter: brightness(85%);\n",
              "    }\n",
              "</style>\n",
              "\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "        \n",
              "\n",
              "    \n",
              "\n",
              "        \n",
              "\n",
              "        \n",
              "    \n",
              "        \n",
              "        \n",
              "    \n",
              "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
              "            <b>\n",
              "    \n",
              "        y=not_Misunderstanding\n",
              "    \n",
              "</b>\n",
              "\n",
              "    \n",
              "    (probability <b>0.997</b>, score <b>-5.930</b>)\n",
              "\n",
              "top features\n",
              "        </p>\n",
              "    \n",
              "    <table class=\"eli5-weights\"\n",
              "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
              "        <thead>\n",
              "        <tr style=\"border: none;\">\n",
              "            \n",
              "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
              "                    Contribution<sup>?</sup>\n",
              "                </th>\n",
              "            \n",
              "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
              "            \n",
              "        </tr>\n",
              "        </thead>\n",
              "        <tbody>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +5.248\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        Highlighted in text (sum)\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 95.21%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +0.682\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        &lt;BIAS&gt;\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "        \n",
              "\n",
              "        \n",
              "        \n",
              "\n",
              "        </tbody>\n",
              "    </table>\n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n",
              "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
              "        <span style=\"background-color: hsl(120, 100.00%, 84.97%); opacity: 0.85\" title=\"0.600\">but</span><span style=\"opacity: 0.80\">... </span><span style=\"background-color: hsl(120, 100.00%, 72.94%); opacity: 0.91\" title=\"1.390\">they</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 60.00%); opacity: 1.00\" title=\"2.429\">do</span><span style=\"opacity: 0.80\">.</span>\n",
              "    </p>\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Conclusions\n",
        "\n",
        "In the manual coding stage, we had acceptable inter-rater reliability (Krippendorff's Alpha = 0.79) following 5 training rounds.\n",
        "In the computational classification stage, we created three different text classifiers, one rule-based, one supervised, and one LLM. Overall, the supervised machine learning classifier – a fine-tuned BERT model – is much better than both the LLM and rule-based classifiers. The classifier's performance is acceptable (MCC = 0.69) with room for improvement.\n",
        "\n",
        " When troubleshooting the results, we can see that the false negatiives are missing some key clarification questions (e.g., \"So what about everyone else?\"). We can also see that the classifiers are picking up on \"new information\" questions, not directed at another's perspeective (e.g., \"Are you having this issue with any other channels?\"). The misclassifications indicate that the classifier is generally struggling with edge cases more than standard cases."
      ],
      "metadata": {
        "id": "VbMaI0IKk_0H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. References\n",
        "\n",
        "\n",
        "> Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J. D., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A., Agarwal, S., Herbert-Voss, A., Krueger, G., Henighan, T., Child, R., Ramesh, A., Ziegler, D., Wu, J., Winter, C., … Amodei, D. (2020). Language models are few-shot learners. Advances in Neural Information Processing Systems, 33, 1877–1901. https://proceedings.neurips.cc/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html\n",
        "\n",
        "> Danescu-Niculescu-Mizil, C., Lee, L., Pang, B., & Kleinberg, J. (2012). Echoes of power: Language effects and power differences in social interaction. Proceedings of the 21st International Conference on World Wide Web, 699–708. https://doi.org/10.1145/2187836.2187931\n",
        "\n",
        "> Devlin, J., Chang, M.-W., Lee, K., & Toutanova, K. (2019). BERT: Pre-training of deep bidirectional transformers for language understanding. Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), 4171–4186. https://doi.org/10.18653/v1/N19-1423\n",
        "\n",
        "> Honnibal, M., Montani, I., Van Landeghem, S., & Boyd, A. (2022). SpaCy: Industrial-Strength Natural Language Processing in Python. Explosion.\n",
        "\n",
        "> Korobov, M. (Presenter). (2017). Explaining behavior of Machine Learning models with eli5 library. EuroPython.\n",
        "\n",
        "> Korobov, M., & Lopuhin, K. (2024). eli5: Debug machine learning classifiers and explain their predictions (0.13.0) [Python; OS Independent]. https://github.com/eli5-org/eli5\n",
        "\n",
        "> Krippendorff, K. (1970). Estimating the reliability, systematic error and random error of interval data. Educational and Psychological Measurement, 30(1), 61–70. https://doi.org/10.1177/001316447003000105\n",
        "\n",
        "> Maiya, A. S. (2022). ktrain: A low-code library for augmented machine learning (arXiv:2004.10703). arXiv. https://doi.org/10.48550/arXiv.2004.10703\n",
        "\n",
        "> OpenAI, Achiam, J., Adler, S., Agarwal, S., Ahmad, L., Akkaya, I., Aleman, F. L., Almeida, D., Altenschmidt, J., Altman, S., Anadkat, S., Avila, R., Babuschkin, I., Balaji, S., Balcom, V., Baltescu, P., Bao, H., Bavarian, M., Belgum, J., … Zoph, B. (2024). GPT-4 Technical Report (arXiv:2303.08774). arXiv. https://doi.org/10.48550/arXiv.2303.08774\n",
        "\n",
        "> Pennebaker, J. W., Francis, M. E., & Booth, R. J. (2001). Linguistic Inquiry and Word Count: LIWC. Mahway: Lawrence Erlbaum Associates, 71(2001).\n",
        "\n",
        "> Ribeiro, M. T., Singh, S., & Guestrin, C. (2016). ‘Why should I trust you?’: Explaining the predictions of any classifier (arXiv:1602.04938). arXiv. https://doi.org/10.48550/arXiv.1602.04938\n",
        "\n",
        "> Shivan, B., & Chaitanya, A. (2024). textstat: Calculate statistical features from text (0.7.3) [Python]. https://github.com/shivam5992/textstat\n",
        "\n"
      ],
      "metadata": {
        "id": "bulsXEAaP83Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Export notebook:"
      ],
      "metadata": {
        "id": "RW6oyH4WK7U3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary packages\n",
        "!sudo apt-get install texlive-xetex texlive-fonts-recommended texlive-plain-generic"
      ],
      "metadata": {
        "id": "M15jQ7qrK5j5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# First MANUALLY download locally to the working directory\n",
        "# Convert the downloaded file to an HTML file\n",
        "!jupyter nbconvert --to PDF \"RAMP_CaseStudy_12May2024_v31.ipynb\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7mKMhSOIIv7f",
        "outputId": "72e7663b-8772-4065-e540-df37aa329174"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NbConvertApp] Converting notebook RAMP_CaseStudy_12May2024_v31.ipynb to PDF\n",
            "/usr/local/lib/python3.10/dist-packages/nbconvert/filters/datatypefilter.py:41: UserWarning: Your element with mimetype(s) dict_keys(['text/html']) is not able to be represented.\n",
            "  warn(\n",
            "[NbConvertApp] Writing 178109 bytes to notebook.tex\n",
            "[NbConvertApp] Building PDF\n",
            "[NbConvertApp] Running xelatex 3 times: ['xelatex', 'notebook.tex', '-quiet']\n",
            "[NbConvertApp] Running bibtex 1 time: ['bibtex', 'notebook']\n",
            "[NbConvertApp] WARNING | bibtex had problems, most likely because there were no citations\n",
            "[NbConvertApp] PDF successfully created\n",
            "[NbConvertApp] Writing 163015 bytes to RAMP_CaseStudy_12May2024_v31.pdf\n"
          ]
        }
      ]
    }
  ]
}