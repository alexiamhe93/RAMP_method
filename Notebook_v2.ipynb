{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "authorship_tag": "ABX9TyPVIcY6gCE6+N5NIbRJxzH2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alexiamhe93/RAMP_method/blob/main/Notebook_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Recursive Adjustment of Measurement Protocols (RAMP) Case Study Python Notebook\n",
        "\n",
        "This Python notebook is used to replicate the results of the paper titled:\n",
        "\n",
        "\"Recursive Adjustment of Measurement Protocols (RAMP) method for developing and validating text classifiers\"\n",
        "\n",
        "The RAMP method has three stages:\n",
        "1. A manual classification stage: Used to generate a coded dataset for a target construct.\n",
        "2. A computational classification stage: Uses the coded dataset to develop a text classifier.\n",
        "3. An evaluation stage: Identify and evaluate surprises and outliers in classifier development, with the goal of identifying construct and content validity issues\n",
        "\n",
        "Each stage has an *input*, *throughput*, and *output* phase.\n",
        "\n",
        "Manual stage:\n",
        "1. Input: *write initial codebook*, *gather data*\n",
        "2. Throughput: repeat on training data - *Train coders*, *code sample data*, *inter-rater reliability on sample*, *troubleshoot misclassifications*, *adjust codebook*\n",
        "3. Output: *finalize notebook*, *code full dataset*, *inter-rater reliability on shared subset*\n",
        "\n",
        "Computational stage:\n",
        "1. Input: *define protocol parameters*, *split dataset into training and validation*\n",
        "2. Throughput: Repeat on training data - *run model on sample data*, *troubleshoot misclassifications*, *change protocol parameters*\n",
        "3. Output: *Finalize protocol*, *Run on validation data*\n",
        "\n",
        "Evaluation stage:\n",
        "1. Input: *identify disagreements from manual stage*, *identify misclassifications from computational stage*,\n",
        "2. Throughput: *evaluate disagreements*, *evaluate misclassifications*\n",
        "3. Output: *Discuss problems of content and construct validity*\n",
        "\n",
        "\n",
        "The notebook applies RAMP to a case study on measuring misunderstandings in online dialogue data.\n",
        "\n",
        "The notebook is structured in terms of the RAMP stages, with an additional first section for initializing all the relevant functions and objects.\n",
        "\n",
        "The notebook was designed using Google Colab on an Nvidia T4 GPU (free with log-in). The code works locally but all dependencies from the \"Load packages\" will have to be installed."
      ],
      "metadata": {
        "id": "Ht0MhYw8ggZq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0. Initiate notebook"
      ],
      "metadata": {
        "id": "0NK-mCzVj-K0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0.1 Install and load packages"
      ],
      "metadata": {
        "id": "l1uWzkOxkBaG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3xHt9VHlgZMO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "177866fe-f73d-4ce9-ef39-70386a289a52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ktrain\n",
            "  Downloading ktrain-0.41.3.tar.gz (25.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25.3/25.3 MB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from ktrain) (1.2.2)\n",
            "Requirement already satisfied: matplotlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from ktrain) (3.7.1)\n",
            "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from ktrain) (2.0.3)\n",
            "Requirement already satisfied: fastprogress>=0.1.21 in /usr/local/lib/python3.10/dist-packages (from ktrain) (1.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from ktrain) (2.31.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from ktrain) (1.4.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from ktrain) (24.0)\n",
            "Collecting langdetect (from ktrain)\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m51.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: jieba in /usr/local/lib/python3.10/dist-packages (from ktrain) (0.42.1)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.10/dist-packages (from ktrain) (3.3.2)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from ktrain) (5.2.0)\n",
            "Collecting syntok>1.3.3 (from ktrain)\n",
            "  Downloading syntok-1.4.4-py3-none-any.whl (24 kB)\n",
            "Collecting tika (from ktrain)\n",
            "  Downloading tika-2.6.0.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from ktrain) (4.41.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from ktrain) (0.1.99)\n",
            "Collecting keras_bert>=0.86.0 (from ktrain)\n",
            "  Downloading keras-bert-0.89.0.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting whoosh (from ktrain)\n",
            "  Downloading Whoosh-2.7.4-py2.py3-none-any.whl (468 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.8/468.8 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras_bert>=0.86.0->ktrain) (1.25.2)\n",
            "Collecting keras-transformer==0.40.0 (from keras_bert>=0.86.0->ktrain)\n",
            "  Downloading keras-transformer-0.40.0.tar.gz (9.7 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting keras-pos-embd==0.13.0 (from keras-transformer==0.40.0->keras_bert>=0.86.0->ktrain)\n",
            "  Downloading keras-pos-embd-0.13.0.tar.gz (5.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting keras-multi-head==0.29.0 (from keras-transformer==0.40.0->keras_bert>=0.86.0->ktrain)\n",
            "  Downloading keras-multi-head-0.29.0.tar.gz (13 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting keras-layer-normalization==0.16.0 (from keras-transformer==0.40.0->keras_bert>=0.86.0->ktrain)\n",
            "  Downloading keras-layer-normalization-0.16.0.tar.gz (3.9 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting keras-position-wise-feed-forward==0.8.0 (from keras-transformer==0.40.0->keras_bert>=0.86.0->ktrain)\n",
            "  Downloading keras-position-wise-feed-forward-0.8.0.tar.gz (4.1 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting keras-embed-sim==0.10.0 (from keras-transformer==0.40.0->keras_bert>=0.86.0->ktrain)\n",
            "  Downloading keras-embed-sim-0.10.0.tar.gz (3.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting keras-self-attention==0.51.0 (from keras-multi-head==0.29.0->keras-transformer==0.40.0->keras_bert>=0.86.0->ktrain)\n",
            "  Downloading keras-self-attention-0.51.0.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->ktrain) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->ktrain) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->ktrain) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->ktrain) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->ktrain) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->ktrain) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->ktrain) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->ktrain) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->ktrain) (2024.1)\n",
            "Requirement already satisfied: regex>2016 in /usr/local/lib/python3.10/dist-packages (from syntok>1.3.3->ktrain) (2023.12.25)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from langdetect->ktrain) (1.16.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->ktrain) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->ktrain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->ktrain) (2024.2.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->ktrain) (1.11.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->ktrain) (3.5.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tika->ktrain) (67.7.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers->ktrain) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers->ktrain) (0.23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers->ktrain) (6.0.1)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers->ktrain) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers->ktrain) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers->ktrain) (4.66.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers->ktrain) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers->ktrain) (4.11.0)\n",
            "Building wheels for collected packages: ktrain, keras_bert, keras-transformer, keras-embed-sim, keras-layer-normalization, keras-multi-head, keras-pos-embd, keras-position-wise-feed-forward, keras-self-attention, langdetect, tika\n",
            "  Building wheel for ktrain (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ktrain: filename=ktrain-0.41.3-py3-none-any.whl size=25316960 sha256=ce563d65b34f2ae8cbd5fb577b1f3b729769c1fff187e4b54d0787a1fec51de8\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/76/11/5b953090eebf531f660948a30cd26e70260619f6480f186a5a\n",
            "  Building wheel for keras_bert (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras_bert: filename=keras_bert-0.89.0-py3-none-any.whl size=33500 sha256=41e5725397bd058c0e3dcc340f06a8f671a293576957f24322af38293eab1641\n",
            "  Stored in directory: /root/.cache/pip/wheels/89/0c/04/646b6fdf6375911b42c8d540a8a3fda8d5d77634e5dcbe7b26\n",
            "  Building wheel for keras-transformer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-transformer: filename=keras_transformer-0.40.0-py3-none-any.whl size=12286 sha256=e807e1eb7fa86e3b1b8abc632dbf4d71bb8ad73815fc1adfed946f272f4a1834\n",
            "  Stored in directory: /root/.cache/pip/wheels/f2/cb/22/75a0ad376129177f7c95c0d91331a18f5368fd657f4035ba7c\n",
            "  Building wheel for keras-embed-sim (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-embed-sim: filename=keras_embed_sim-0.10.0-py3-none-any.whl size=3944 sha256=165442b2a711e4f4a24ea499a5dbfbe197eaf39bbc76044989a3b34a3251efb2\n",
            "  Stored in directory: /root/.cache/pip/wheels/82/32/c7/fd35d0d1b840a6c7cbd4343f808d10d0f7b87d271a4dbe796f\n",
            "  Building wheel for keras-layer-normalization (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-layer-normalization: filename=keras_layer_normalization-0.16.0-py3-none-any.whl size=4654 sha256=42d23a1a1ff5780c147804e1731161b90d7dcfe8a783524d959cc264fcf7d363\n",
            "  Stored in directory: /root/.cache/pip/wheels/ed/3a/4b/21db23c0cc56c4b219616e181f258eb7c57d36cc5d056fae9a\n",
            "  Building wheel for keras-multi-head (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-multi-head: filename=keras_multi_head-0.29.0-py3-none-any.whl size=14976 sha256=a31bda352d7c067eb4f48c3b0451b47cf94e0c8e47f0547faa51fb265005976b\n",
            "  Stored in directory: /root/.cache/pip/wheels/cb/23/4b/06d7ae21714f70fcc25b48f972cc8e5e7f4b6b764a038b509d\n",
            "  Building wheel for keras-pos-embd (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-pos-embd: filename=keras_pos_embd-0.13.0-py3-none-any.whl size=6945 sha256=0e7d4adf3ef88766b96f6a5a95a7876358cd8ec63f84f1138ca6c7929a578547\n",
            "  Stored in directory: /root/.cache/pip/wheels/78/07/1b/b1ca47b6ac338554b75c8f52c54e6a2bfbe1b07d79579979a4\n",
            "  Building wheel for keras-position-wise-feed-forward (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-position-wise-feed-forward: filename=keras_position_wise_feed_forward-0.8.0-py3-none-any.whl size=4969 sha256=8491da0eb6a64740571a0e6a8f204a5f49b8a2e7820ae6c31da47eb9d47d9bb7\n",
            "  Stored in directory: /root/.cache/pip/wheels/c1/6a/04/d1706a53b23b2cb5f9a0a76269bf87925daa1bca09eac01b21\n",
            "  Building wheel for keras-self-attention (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-self-attention: filename=keras_self_attention-0.51.0-py3-none-any.whl size=18894 sha256=2bb966766bc1f43dbf7f94af0a02b4bcb03e36d3ba4ae129838bb1519475ae79\n",
            "  Stored in directory: /root/.cache/pip/wheels/b8/f7/24/607b483144fb9c47b4ba2c5fba6b68e54aeee2d5bf6c05302e\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993227 sha256=4817b4955f3b8c63433013477398c18f2c5841f0db2cbbd026d9ca0016665414\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/03/7d/59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\n",
            "  Building wheel for tika (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tika: filename=tika-2.6.0-py3-none-any.whl size=32621 sha256=6d81eb5ec9ff185cbe6c3154541971b9d859e4ff5480e6f33d1b1e14bd6193cb\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/71/c7/b757709531121b1700cffda5b6b0d4aad095fb507ec84316d0\n",
            "Successfully built ktrain keras_bert keras-transformer keras-embed-sim keras-layer-normalization keras-multi-head keras-pos-embd keras-position-wise-feed-forward keras-self-attention langdetect tika\n",
            "Installing collected packages: whoosh, syntok, langdetect, keras-self-attention, keras-position-wise-feed-forward, keras-pos-embd, keras-layer-normalization, keras-embed-sim, tika, keras-multi-head, keras-transformer, keras_bert, ktrain\n",
            "Successfully installed keras-embed-sim-0.10.0 keras-layer-normalization-0.16.0 keras-multi-head-0.29.0 keras-pos-embd-0.13.0 keras-position-wise-feed-forward-0.8.0 keras-self-attention-0.51.0 keras-transformer-0.40.0 keras_bert-0.89.0 ktrain-0.41.3 langdetect-1.0.9 syntok-1.4.4 tika-2.6.0 whoosh-2.7.4\n",
            "Collecting https://github.com/amaiya/eli5-tf/archive/refs/heads/master.zip\n",
            "  Downloading https://github.com/amaiya/eli5-tf/archive/refs/heads/master.zip\n",
            "\u001b[2K     \u001b[32m|\u001b[0m \u001b[32m6.9 MB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: attrs>17.1.0 in /usr/local/lib/python3.10/dist-packages (from eli5==0.13.0) (23.2.0)\n",
            "Requirement already satisfied: jinja2>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from eli5==0.13.0) (3.1.4)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from eli5==0.13.0) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from eli5==0.13.0) (1.11.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from eli5==0.13.0) (1.16.0)\n",
            "Requirement already satisfied: scikit-learn>=0.20 in /usr/local/lib/python3.10/dist-packages (from eli5==0.13.0) (1.2.2)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from eli5==0.13.0) (0.20.3)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from eli5==0.13.0) (0.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=3.0.0->eli5==0.13.0) (2.1.5)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20->eli5==0.13.0) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20->eli5==0.13.0) (3.5.0)\n",
            "Building wheels for collected packages: eli5\n",
            "  Building wheel for eli5 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for eli5: filename=eli5-0.13.0-py2.py3-none-any.whl size=108158 sha256=291bfebc95c15816880e164c93a3a54ac8f9fa46c1beecead1b053d0f717d82e\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-6d9nrjgx/wheels/0b/14/54/23c07f7254b733dc3daac99ba1fda60e30f1b2991b3b8ee0bf\n",
            "Successfully built eli5\n",
            "Installing collected packages: eli5\n",
            "Successfully installed eli5-0.13.0\n",
            "Collecting openai\n",
            "  Downloading openai-1.30.3-py3-none-any.whl (320 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.6/320.6 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.2)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.30.3\n",
            "Collecting textstat\n",
            "  Downloading textstat-0.7.3-py3-none-any.whl (105 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.1/105.1 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyphen (from textstat)\n",
            "  Downloading pyphen-0.15.0-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyphen, textstat\n",
            "Successfully installed pyphen-0.15.0 textstat-0.7.3\n"
          ]
        }
      ],
      "source": [
        "# For Supervised classifier\n",
        "!pip install ktrain\n",
        "# For revealing under the classifier black box\n",
        "!pip install https://github.com/amaiya/eli5-tf/archive/refs/heads/master.zip\n",
        "# For LLM classifier\n",
        "!pip install openai\n",
        "# For summary statistics\n",
        "!pip install textstat"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# General use packages\n",
        "import requests, zipfile, io, os, psutil, random, time\n",
        "import torch\n",
        "import pandas as pd\n",
        "# This deactivates a warning from Pandas that frequently prints\n",
        "pd.options.mode.chained_assignment = None  # default='warn'\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "from tqdm import tqdm\n",
        "# For descriptive statistics\n",
        "from textstat.textstat import textstatistics\n",
        "import re\n",
        "# Performance evaluations for binary classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_recall_curve,roc_auc_score,classification_report,auc,confusion_matrix\n",
        "# for rule-based classification\n",
        "import spacy\n",
        "from spacy.matcher import Matcher\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "# for supervised classification\n",
        "import ktrain\n",
        "from ktrain import text\n",
        "# for LLM classification\n",
        "import openai\n",
        "\n",
        "#for troubleshooting\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from wordcloud import WordCloud\n",
        "from nltk import agreement\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "# Plotting\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams['figure.dpi'] = 120\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KJGGvaNX8hPy",
        "outputId": "fc366e6f-49ed-4e31-91e0-a396a5e84337"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check system GPU (recommended if possible)\n",
        "# CPU cores\n",
        "num_cpu_cores = os.cpu_count()\n",
        "print(f\"Number of CPU cores: {num_cpu_cores}\")\n",
        "# GPU details\n",
        "if torch.cuda.is_available():\n",
        "    gpu_name = torch.cuda.get_device_name(0)\n",
        "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / (1024 ** 3)  # in GB\n",
        "    print(f\"GPU Name: {gpu_name}\")\n",
        "    print(f\"GPU Memory: {gpu_memory:.2f} GB\")\n",
        "else:\n",
        "    print(\"No GPU available.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mT0gjhlD8lsl",
        "outputId": "1d61578d-29d6-4e2f-8e4b-c76839fc0725"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of CPU cores: 2\n",
            "GPU Name: Tesla T4\n",
            "GPU Memory: 14.75 GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load in openai keys for producing topic model names\n",
        "oai_k = \"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\"\n",
        "openai.organization = \"org-7Q7DY9cZcPr6mbXa67jDCNbS\"\n",
        "openai.api_key = oai_k\n",
        "os.environ['OPENAI_API_KEY'] = oai_k"
      ],
      "metadata": {
        "id": "ifDAz7zT9Co3"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0.2 Download data and pre-trained BERT model\n",
        "\n",
        "All the data for replication (<50mb) is accessed through a GitHub link and the pre-trained BERT model (1.03GB) from dropbox"
      ],
      "metadata": {
        "id": "9NbRD_KokEAA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download data from GitHub"
      ],
      "metadata": {
        "id": "fUH0ETcp-P6p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download empirical data\n",
        "r = requests.get( 'https://github.com/alexiamhe93/RAMP_method/blob/main/Dataset/data.zip?raw=true')\n",
        "z = zipfile.ZipFile(io.BytesIO(r.content))\n",
        "z.extractall()\n",
        "\n",
        "# Load train (70%) and test (30%)\n",
        "try:\n",
        "  train = pd.read_csv(\"data/Train.csv\")\n",
        "  validation = pd.read_csv(\"data/Validation.csv\")\n",
        "  St1Through = pd.read_csv(\"data/RAMP_Stage1.csv\")\n",
        "  St2Through = pd.read_csv(\"data/RAMP_Stage2.csv\")\n",
        "  out = pd.read_csv(\"data/RAMP_Stage3.csv\")\n",
        "except:\n",
        "  train = pd.read_csv(\"Train.csv\")\n",
        "  validation = pd.read_csv(\"Validation.csv\")\n",
        "  St1Through = pd.read_csv(\"RAMP_Stage1.csv\")\n",
        "  St2Through = pd.read_csv(\"RAMP_Stage2.csv\")\n",
        "  out = pd.read_csv(\"RAMP_Stage3.csv\")"
      ],
      "metadata": {
        "id": "nTn-uqu8kIS4"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Validation n before cleaning: {len(validation)} texts\")\n",
        "# Delete any duplicates\n",
        "validation = validation.dropna(subset=[\"text\"])\n",
        "validation = validation.drop_duplicates(subset=\"text\")\n",
        "print(f\"Validation n after cleaning: {len(validation)} texts\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--VnA5j2IhmM",
        "outputId": "110a54e3-54a5-44b2-8985-45651dc934a0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation n before cleaning: 6599 texts\n",
            "Validation n after cleaning: 6420 texts\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We removed 179 sentences that are duplicates or empty values."
      ],
      "metadata": {
        "id": "wWk0GcaOJP7I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download model from Dropbox (can take some time if internet is slow - aprox 1.1GB - downloads weights and pre-processing)"
      ],
      "metadata": {
        "id": "3GFOZlP3-Eg-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O supervised_model.zip https://www.dropbox.com/scl/fi/5wtuor1ag1gktg6eukqwr/supervised_model.zip?rlkey=nfwxyataobjzt708m3gf27o3s&st=cz5r9lq0&dl=0 --quiet\n",
        "!unzip supervised_model.zip"
      ],
      "metadata": {
        "id": "i6URMHD9-GOY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00d0e33b-b184-4d7d-c6ec-3c0d3e1298be"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: --quiet: command not found\n",
            "--2024-05-26 14:21:03--  https://www.dropbox.com/scl/fi/5wtuor1ag1gktg6eukqwr/supervised_model.zip?rlkey=nfwxyataobjzt708m3gf27o3s\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.1.18, 2620:100:6016:18::a27d:112\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.1.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc2af33b24bb1d2cb20ca81d1f3c.dl.dropboxusercontent.com/cd/0/inline/CTrQiMZ_EfXhJ04KXi_Dw8DSqBPygmTBqIkjiIvQlnvfYGbL4qDlaKRDof5v7Rt66JMtnWhGDH0y_UISFlrr7BdaLFN-JN1ljYGDYuc5FR64IsksFKLOFGZUyQWBezk4jnLWIMiimPmSLJvkUsSqN0uk/file# [following]\n",
            "--2024-05-26 14:21:04--  https://uc2af33b24bb1d2cb20ca81d1f3c.dl.dropboxusercontent.com/cd/0/inline/CTrQiMZ_EfXhJ04KXi_Dw8DSqBPygmTBqIkjiIvQlnvfYGbL4qDlaKRDof5v7Rt66JMtnWhGDH0y_UISFlrr7BdaLFN-JN1ljYGDYuc5FR64IsksFKLOFGZUyQWBezk4jnLWIMiimPmSLJvkUsSqN0uk/file\n",
            "Resolving uc2af33b24bb1d2cb20ca81d1f3c.dl.dropboxusercontent.com (uc2af33b24bb1d2cb20ca81d1f3c.dl.dropboxusercontent.com)... 162.125.1.15, 2620:100:6016:15::a27d:10f\n",
            "Connecting to uc2af33b24bb1d2cb20ca81d1f3c.dl.dropboxusercontent.com (uc2af33b24bb1d2cb20ca81d1f3c.dl.dropboxusercontent.com)|162.125.1.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /cd/0/inline2/CTo2TwZbz-9fumJKGFlzU0QX4vhAJBKiBouL_IR4TqQL1HbnzQNeh19o78A6QtT5Nu-YOEEwFm5iVSiMHYeMPgwcx97-P_Q_VSHEsw9l9BOAD1DI0ogKSxzGfd0DgZIK96Uma0d_jqYGjpAOABUADCsh1CC3Y8XGAjm_Q2t72hqWc-cItv6hNXAtHuDBtOO65zoycFaag8-P2nMs7Ow_HyJlYkzHb9JNXLLn84TN7PZudEO3h8i8qT3z_NL-NGtJnqkwRU2knvDTCaDMZGI0tEDllyYXrECqjwNaA__7YdZDrKhl9T-_tXOynFGC7cxQcFvpAu95-T-wkB930BHtAEQq2dJvq99MUTv8PUCdzrssQevhJDNshsGKeryxe3bkuOI/file [following]\n",
            "--2024-05-26 14:21:05--  https://uc2af33b24bb1d2cb20ca81d1f3c.dl.dropboxusercontent.com/cd/0/inline2/CTo2TwZbz-9fumJKGFlzU0QX4vhAJBKiBouL_IR4TqQL1HbnzQNeh19o78A6QtT5Nu-YOEEwFm5iVSiMHYeMPgwcx97-P_Q_VSHEsw9l9BOAD1DI0ogKSxzGfd0DgZIK96Uma0d_jqYGjpAOABUADCsh1CC3Y8XGAjm_Q2t72hqWc-cItv6hNXAtHuDBtOO65zoycFaag8-P2nMs7Ow_HyJlYkzHb9JNXLLn84TN7PZudEO3h8i8qT3z_NL-NGtJnqkwRU2knvDTCaDMZGI0tEDllyYXrECqjwNaA__7YdZDrKhl9T-_tXOynFGC7cxQcFvpAu95-T-wkB930BHtAEQq2dJvq99MUTv8PUCdzrssQevhJDNshsGKeryxe3bkuOI/file\n",
            "Reusing existing connection to uc2af33b24bb1d2cb20ca81d1f3c.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1107245706 (1.0G) [application/zip]\n",
            "Saving to: ‘supervised_model.zip’\n",
            "\n",
            "supervised_model.zi 100%[===================>]   1.03G   121MB/s    in 10s     \n",
            "\n",
            "2024-05-26 14:21:16 (101 MB/s) - ‘supervised_model.zip’ saved [1107245706/1107245706]\n",
            "\n",
            "Archive:  supervised_model.zip\n",
            "   creating: supervised_model/\n",
            "  inflating: __MACOSX/._supervised_model  \n",
            "  inflating: supervised_model/tf_model.preproc  \n",
            "  inflating: __MACOSX/supervised_model/._tf_model.preproc  \n",
            "  inflating: supervised_model/tf_model.h5  \n",
            "  inflating: __MACOSX/supervised_model/._tf_model.h5  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0.3 Load classes and functios\n",
        "\n",
        "The notebook uses two class objects for performing most of the operations across the three stages of RAMP. The classifier object is used to calculate inter-rater reliability (manual stage); run a dictionary word classifier (computational stage), a supervised classifier (computational stage) and an LLM classifier (computational stage); calculate accuracy metrics (computational stage); access disagreements and misclassifications (evaluation stage)."
      ],
      "metadata": {
        "id": "BHYCi1z_kFl3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Classifier object and functions\n",
        "\n",
        "This class does the heavy lifting for the notebook. It integrates the three types of classifier (rule-based, supervised, LLM) into one function so that there is a common language across the examples.\n",
        "\n",
        "The classifier produces a development report, including the following variables:\n",
        "\n",
        "1. `TP`,`TN`,`FP`,`FN`: number of true positives, true negatives, false positives, and false negatives\n",
        "2. `Precision`: TP/TP+FP - ratio of true positives to all predicted positive class. Reported for positive class only.\n",
        "3. `Recall`: TP/TP+FN – ratio of true positives to all true positive class.Reported for positive class only.\n",
        "4. `F1_avg`: Weighted harmonic mean of precision and recall (all classes - this F1 is not the precision and recall reported).\n",
        "5. `F1_var`: Weighted harmonic mean of precision and recall for positive class.\n",
        "6. `AUC_ROC`: Area under the receiving operating characteristic (ROC) curve\n",
        "7. `AUC_PR`: Area under the precision and recall curve.\n",
        "\n",
        "Each metric highlights a different aspect of the classifier's performance. For instance, the weighted F1 (`F1_avg`) is sensitive to imbalanced classes. For misunderstandings, the class is imbalanced (8% of turns are misunderstandings) so the area under the precision recall curve (`AUC_PR`) is more appropriate."
      ],
      "metadata": {
        "id": "Os-aIAYQDBZq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Classifier:\n",
        "  def __init__(self, texts, true_scores):\n",
        "    \"\"\"\n",
        "    Initialize the Classifier class with texts and true scores.\n",
        "    \"\"\"\n",
        "    self.texts = texts\n",
        "    self.true_scores = true_scores\n",
        "    self.train_size = len(texts)\n",
        "    self.type_ = None\n",
        "    self.pred_scores = []\n",
        "    self.nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "  def add_rule_based_terms(self, terms, pattern_type):\n",
        "    \"\"\"\n",
        "    Configure terms and pattern matching type for rule-based classifiers.\n",
        "    \"\"\"\n",
        "    self.terms = terms\n",
        "    if pattern_type == \"pattern\":\n",
        "        self.type_ = \"rule-based-1\"\n",
        "    elif pattern_type == \"lemma\":\n",
        "        self.type_ = \"rule-based-2\"\n",
        "    else:\n",
        "        raise ValueError(\"Invalid pattern type specified.\")\n",
        "  def classify_with_spacy_pattern(self):\n",
        "    \"\"\"\n",
        "    Classify texts using SpaCy's pattern matcher based on predefined terms.\n",
        "    \"\"\"\n",
        "    matcher = Matcher(self.nlp.vocab)\n",
        "    for term in self.terms:\n",
        "        matcher.add(term[\"label\"], [term[\"pattern\"]])\n",
        "    self.pred_scores = [bool(matcher(self.nlp(text))) for text in self.texts]\n",
        "  def classify_with_spacy_lemma(self):\n",
        "    \"\"\"\n",
        "    Classify texts by checking if any lemmas from the terms are in the texts.\n",
        "    \"\"\"\n",
        "    lemma_doc = self.nlp(\" \".join(self.terms))\n",
        "    lemma_set = set(token.lemma_ for token in lemma_doc)\n",
        "    self.pred_scores = [bool(set(token.lemma_ for token in self.nlp(text.lower())) & lemma_set) for text in self.texts]\n",
        "  def add_SML_classifier(self, predictor, **kwargs):\n",
        "    \"\"\"\n",
        "    Configure the supervised machine learning classifier with a predictor and training parameters.\n",
        "    \"\"\"\n",
        "    self.type_ = \"supervised\"\n",
        "    self.predictor = predictor\n",
        "    self.sml_params = kwargs\n",
        "    print(\"Supervised ML classifier configured with parameters:\", kwargs)\n",
        "  def classify_with_SML(self):\n",
        "    \"\"\"\n",
        "    Perform classification using the configured supervised machine learning predictor.\n",
        "    \"\"\"\n",
        "    preds = self.predictor.predict(self.texts)\n",
        "    self.pred_scores = [0 if \"not\" in pred.lower() else 1 for pred in preds]\n",
        "\n",
        "  def add_few_shot_classifier(self, GPTmodel, prompt, role):\n",
        "    \"\"\"\n",
        "    Configure the few-shot classifier with a GPT model, prompt template, and user/system roles.\n",
        "    \"\"\"\n",
        "    self.type_ = \"LLM\"\n",
        "    self.GPTmodel = GPTmodel\n",
        "    self.prompt = prompt\n",
        "    self.role = role\n",
        "    self.cost = 0\n",
        "    self.total_tokens = 0\n",
        "    self.LLMScores = []\n",
        "\n",
        "  def gptActualCost(self, response):\n",
        "    \"\"\"\n",
        "    Calculates the GPT cost for different models\n",
        "    \"\"\"\n",
        "    engine = self.GPTmodel\n",
        "    total_tokens=response.usage.total_tokens\n",
        "    total_tokens_1k_units = total_tokens/1000\n",
        "\n",
        "    if engine=='gpt-3.5-turbo':\n",
        "        cost=total_tokens_1k_units*0.0005\n",
        "    elif engine=='gpt-4-turbo':\n",
        "        cost=total_tokens_1k_units*0.01\n",
        "    elif engine=='gpt-4-32k':\n",
        "        cost=total_tokens_1k_units*0.12\n",
        "    else:\n",
        "        print('getCost error: engine not found')\n",
        "        return\n",
        "    return cost, total_tokens\n",
        "\n",
        "  def get_llm_response(self,messages,temperature=0, max_tokens = 100, max_attempts = 3):\n",
        "    '''\n",
        "    Function that takes messages format for ChatGPT input and returns the response text.\n",
        "    '''\n",
        "    GPTmodel = self.GPTmodel\n",
        "    for attempt in range(0, max_attempts):\n",
        "      try:\n",
        "        #. request timeout ADD IN\n",
        "        response = openai.chat.completions.create(model=GPTmodel, messages = messages, temperature=temperature, max_tokens=max_tokens)\n",
        "        response_text = response.choices[0].message.content\n",
        "        self.LLMScores.append(response_text)\n",
        "        response_cost, token_count = self.gptActualCost(response)\n",
        "        self.cost += response_cost\n",
        "        self.total_tokens += token_count\n",
        "        break  # If analysis was successful, break out of the retry loop\n",
        "      except Exception as e:\n",
        "        print(f\"Error processing text on attempt {attempt+1}: {e}\")\n",
        "        if attempt + 1 == max_attempts:\n",
        "          print(f\"Skipping text after {max_attempts} failed attempts.\")\n",
        "          response_text\n",
        "    return response_text\n",
        "  def define_messages(self, text_to_classify):\n",
        "    '''\n",
        "    Function for creating a basic messages format from a prompt, a role, and a text to classify (all strings)\n",
        "    '''\n",
        "    prompt = self.prompt\n",
        "    role = self.role\n",
        "    prompt = prompt.format(text_to_classify)\n",
        "    messages = [{'role': 'system', 'content': role},\n",
        "                {'role': 'user', 'content' : prompt}]\n",
        "    return messages\n",
        "  def convert_llm_scores_binary(self, return_scores = False):\n",
        "    '''\n",
        "    Function for converting a string \"Yes\" or \"No\" into binary format - used for the clarification requests\n",
        "    '''\n",
        "    llm_scores = self.pred_scores\n",
        "    new_scores = []\n",
        "    for s in llm_scores:\n",
        "      if \"yes\" in s.lower():\n",
        "        new_scores.append(1)\n",
        "      else:\n",
        "        new_scores.append(0)\n",
        "    if not return_scores:\n",
        "      self.pred_scores = new_scores\n",
        "    else:\n",
        "      return new_scores\n",
        "\n",
        "  def classify_with_fewshot(self,  max_tokens = 100, max_attempts = 3, temperature = 0):\n",
        "    '''\n",
        "    Function for running a prompt over a series of texts (expects a list)\n",
        "    '''\n",
        "    prompt = self.prompt\n",
        "    role = self.role\n",
        "    input_texts = self.texts\n",
        "    GPTmodel = self.GPTmodel\n",
        "    scores = []\n",
        "    for txt in tqdm(input_texts):\n",
        "      message = self.define_messages(txt)\n",
        "      try:\n",
        "        response = self.get_llm_response(message,temperature=temperature,\n",
        "                                        max_tokens=max_tokens, max_attempts=max_attempts)\n",
        "      except:\n",
        "        response = \"Error in response\"\n",
        "      scores.append(response)\n",
        "    self.pred_scores = scores\n",
        "    self.convert_llm_scores_binary()\n",
        "\n",
        "  def run_classifier(self):\n",
        "    \"\"\"\n",
        "    Execute the classifier based on the configured type.\n",
        "    \"\"\"\n",
        "    if self.type_ == \"rule-based-1\":\n",
        "        self.classify_with_spacy_pattern()\n",
        "    elif self.type_ == \"rule-based-2\":\n",
        "        self.classify_with_spacy_lemma()\n",
        "    elif self.type_ == \"supervised\":\n",
        "        self.classify_with_SML()\n",
        "    elif self.type_ == \"LLM\":\n",
        "        self.classify_with_fewshot()\n",
        "        cost = self.cost\n",
        "        total_tokens = self.total_tokens\n",
        "        avg_tokens = self.total_tokens / self.train_size\n",
        "        print(f\"This run cost {cost:.2f}$ for {total_tokens} tokens. Average tokens: {avg_tokens:.2f}\")\n",
        "    else:\n",
        "        raise ValueError(\"Classifier type is not configured.\")\n",
        "\n",
        "  def get_model_report(self, display=True):\n",
        "    \"\"\"\n",
        "    Generate and display or return the classification report and metrics.\n",
        "    \"\"\"\n",
        "    cm = confusion_matrix(self.true_scores, self.pred_scores)\n",
        "    report = classification_report(self.true_scores, self.pred_scores, output_dict=True)\n",
        "    precision, recall, thresholds = precision_recall_curve(self.true_scores, self.pred_scores)\n",
        "    auc_pr = auc(recall, precision)\n",
        "    auc_roc = roc_auc_score(self.true_scores, self.pred_scores)\n",
        "\n",
        "    if display:\n",
        "        print(f'AUC-PR: {auc_pr:.2f}\\n')\n",
        "        print(f'AUC-ROC: {auc_roc:.2f}\\n')\n",
        "        print(classification_report(self.true_scores, self.pred_scores, output_dict=False))\n",
        "    else:\n",
        "        return {\n",
        "            \"precision\": report['1']['precision'],\n",
        "            \"recall\": report['1']['recall'],\n",
        "            \"auc_pr\": auc_pr,\n",
        "            \"auc_roc\": auc_roc,\n",
        "            \"f1_avg\": report['weighted avg']['f1-score'],\n",
        "            \"f1_var\": report['1']['f1-score']\n",
        "        }\n",
        "  def get_misclassification(self, return_all = False):\n",
        "    \"\"\"\n",
        "    Function to fetch misclassifications\n",
        "    \"\"\"\n",
        "    df = pd.DataFrame({\"text\":self.texts,\"true\":self.true_scores,\n",
        "                       \"pred\":self.pred_scores})\n",
        "    # Function to classify each row\n",
        "    def classify_row(row):\n",
        "      if row['true'] == 1 and row['pred'] == 1:\n",
        "        return 'TP'\n",
        "      elif row['true'] == 0 and row['pred'] == 1:\n",
        "        return 'FP'\n",
        "      elif row['true'] == 1 and row['pred'] == 0:\n",
        "        return 'FN'\n",
        "      elif row['true'] == 0 and row['pred'] == 0:\n",
        "        return 'TN'\n",
        "    df['Classification'] = df.apply(classify_row, axis=1)\n",
        "    if return_all:\n",
        "      return df\n",
        "    else:\n",
        "      return df[df[\"Classification\"].isin([\"FP\",\"FN\"])]\n",
        "\n",
        "  def preprocess_text(self, text):\n",
        "    \"\"\"\n",
        "    Function to process the texts.\n",
        "    \"\"\"\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    words = nltk.word_tokenize(text)\n",
        "    cleaned_text = [lemmatizer.lemmatize(word.lower()) for word in words if word.isalnum() and word.lower() not in stop_words]\n",
        "    return ' '.join(cleaned_text)\n",
        "\n",
        "  def plot_misclassifications(self, df, FN_FP=\"FN\"):\n",
        "    \"\"\"\n",
        "    Function to generate a wordcloud\n",
        "    \"\"\"\n",
        "    df['cleaned_text'] = df['text'].apply(self.preprocess_text)\n",
        "    if FN_FP == \"FN\":\n",
        "      print(\"Word Cloud for False Negatives:\")\n",
        "      texts = \" \".join(df[df['Classification'] == 'FN']['cleaned_text'])\n",
        "    else:\n",
        "      print(\"Word Cloud for False Positives:\")\n",
        "      texts = \" \".join(df[df['Classification'] == 'FP']['cleaned_text'])\n",
        "    wordcloud = WordCloud(width = 800, height = 400, background_color ='white').generate(texts)\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.imshow(wordcloud, interpolation='bilinear')\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "7_s_-YmtkItR"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Plotting and summary object\n",
        "\n",
        "This class is used throughout to do various plotting and statistical functions."
      ],
      "metadata": {
        "id": "5Y5mJpC0JtQZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TextDataStats:\n",
        "  def __init__(self, df, text_column=\"text\", binary_column=\"Misunderstanding\",\n",
        "               IRR_columns = [\"Coder1\",\"Coder2\",\"Coder3\",\"Coder4\"],\n",
        "               group_column = \"Round\"):\n",
        "    self.df = df\n",
        "    self.text_column = text_column\n",
        "    self.binary_column = binary_column\n",
        "    self.IRR_columns = IRR_columns\n",
        "    self.group_column = group_column\n",
        "\n",
        "  def preprocess_text(self):\n",
        "    \"\"\"\n",
        "    Extracts words and sentences from the text, counts them and adds to the dataframe.\n",
        "    \"\"\"\n",
        "    self.df['words'] = self.df[self.text_column].apply(lambda x: re.findall(r'\\b\\w+\\b', x.lower()))\n",
        "    self.df['word_count'] = self.df['words'].apply(len)\n",
        "\n",
        "  def basic_stats(self):\n",
        "    \"\"\"\n",
        "    Computes basic statistics for overall and grouped data.\n",
        "    \"\"\"\n",
        "    self.preprocess_text()\n",
        "\n",
        "    # General stats\n",
        "    general_stats = self.df.describe(include=[np.number]).loc[['mean', 'std', 'min', '50%', 'max'], ['word_count']]\n",
        "    general_stats.rename(index={'50%': 'median'}, inplace=True)\n",
        "    # Grouped stats by binary column\n",
        "    grouped_stats = self.df.groupby(self.binary_column).agg({\n",
        "        'word_count': ['mean', 'median', 'std', 'min', 'max'],\n",
        "    })\n",
        "    # Binary column distribution\n",
        "    binary_dist = self.df[self.binary_column].value_counts(normalize=True).to_frame('distribution')\n",
        "    return general_stats.round(2), grouped_stats.round(2), binary_dist.round(2)\n",
        "\n",
        "  def BasicReport(self):\n",
        "    \"\"\"\n",
        "    Generates a report combining all statistics in a readable text format.\n",
        "    \"\"\"\n",
        "    general_stats, grouped_stats, binary_dist = self.basic_stats()\n",
        "\n",
        "    # Creating a structured text report\n",
        "    report = \"Text Data Statistics Report\\n\\n\"\n",
        "    report += \"General Statistics:\\n\"\n",
        "    report += general_stats.to_string() + \"\\n\\n\"\n",
        "\n",
        "    report += \"Statistics by Binary Column:\\n\"\n",
        "    for name, group in self.df.groupby(self.binary_column):\n",
        "        report += f\"\\nGroup: {name}\\n\"\n",
        "        report += grouped_stats.loc[name].to_string() + \"\\n\"\n",
        "    return report\n",
        "\n",
        "  def get_IRR(self,df):\n",
        "    \"\"\"\n",
        "    Calculates Krippendorff's Alpha and overall agreement\n",
        "    \"\"\"\n",
        "    df = df[self.IRR_columns]\n",
        "    df = df.astype(int)\n",
        "    IRR_out = []\n",
        "    for i, row in df.iterrows():\n",
        "      for k in list(df.columns):\n",
        "        IRR_out.append([k, str(i), row[k]])\n",
        "    ratingtask = agreement.AnnotationTask(data=IRR_out)\n",
        "    ags = ratingtask.avg_Ao()\n",
        "    krip_alpha = ratingtask.alpha()\n",
        "    return ags, krip_alpha\n",
        "\n",
        "  def IRRreport(self):\n",
        "    \"\"\"\n",
        "    Prints Krippendorff's Alpha and the overall agreement for each round of coding\n",
        "    \"\"\"\n",
        "    df = self.df.sort_values([self.group_column])\n",
        "    rounds = df[self.group_column].unique()\n",
        "    agr = []\n",
        "    alp = []\n",
        "    ss = []\n",
        "    for i in rounds:\n",
        "      tdf = df[df[self.group_column] == i]\n",
        "      ss.append(len(tdf))\n",
        "      agr_,alp_ = self.get_IRR(tdf)\n",
        "      agr.append(agr_)\n",
        "      alp.append(alp_)\n",
        "    return pd.DataFrame({\"Round\":[\"Round\" + str(i) for i in rounds],\n",
        "                         \"Sample size\":ss,\n",
        "                         \"Agreement\":agr,\"Krippendorff's Alpha\":alp})\n",
        "\n",
        "  def get_disagreements(self,n=10, return_df = False):\n",
        "    \"\"\"\n",
        "    Prints n disagreements for the IRR results\n",
        "    \"\"\"\n",
        "    df = self.df\n",
        "    disag = []\n",
        "    for i, row in df.iterrows():\n",
        "      x = 0\n",
        "      for coder in self.IRR_columns:\n",
        "        x += row[coder]\n",
        "      disag.append(x)\n",
        "    df[\"disag\"] = disag\n",
        "    ncoders = len(self.IRR_columns)\n",
        "    df = df[df[\"disag\"] < ncoders]\n",
        "    df = df[df[\"disag\"] > 0]\n",
        "    if return_df:\n",
        "      return df.round(2)\n",
        "    else:\n",
        "      sdf = df.sample(n)\n",
        "      for s in sdf.text:\n",
        "        print(\"----------\")\n",
        "        print(s)\n",
        "\n",
        "  def get_misclassifications(self, n=5,return_all = False):\n",
        "    \"\"\"\n",
        "    Functiin to report on the misclassifications across all three classifiers\n",
        "    \"\"\"\n",
        "    df = self.df\n",
        "    FN_FP = []\n",
        "    for i,row in df.iterrows():\n",
        "      base = int(row[\"Manual\"])\n",
        "      fs = int(row[\"LLM\"])\n",
        "      sup = int(row[\"supervised\"])\n",
        "      if sup == base:\n",
        "        if fs == base:\n",
        "          if base == 1:\n",
        "            FN_FP.append(\"TP (All)\")\n",
        "          else:\n",
        "            FN_FP.append(\"TN (All)\")\n",
        "        else:\n",
        "          if base == 1:\n",
        "            FN_FP.append(\"FN (LLM)\")\n",
        "          else:\n",
        "            FN_FP.append(\"FP (LLM)\")\n",
        "      else:\n",
        "        if fs == base:\n",
        "          if base == 1:\n",
        "            FN_FP.append(\"FN (supervised)\")\n",
        "          else:\n",
        "            FN_FP.append(\"FP (supervised)\")\n",
        "        else:\n",
        "          if base == 1:\n",
        "            FN_FP.append(\"FP (ALL\")\n",
        "          else:\n",
        "            FN_FP.append(\"FN (All)\")\n",
        "    df[\"FN_FP\"] = FN_FP\n",
        "    if return_all:\n",
        "      return df\n",
        "    FP_all = df[df.FN_FP == \"FP (All)\"].text.to_list()\n",
        "    FP_sup = df[df.FN_FP == \"FP (supervised)\"].text.to_list()\n",
        "    FP_fs = df[df.FN_FP == \"FP (LLM)\"].text.to_list()\n",
        "\n",
        "    FN_all = df[df.FN_FP == \"FN (All)\"].text.to_list()\n",
        "    FN_sup = df[df.FN_FP == \"FN (supervised)\"].text.to_list()\n",
        "    FN_fs = df[df.FN_FP == \"FN (LLM)\"].text.to_list()\n",
        "    print(f\"--- False positives count: --\")\n",
        "    print(f\"Both = {len(FP_all)}, Supervised = {len(FP_sup)}, LLM = {len(FP_fs)}\")\n",
        "    print(\"\\n--- False negatives count: --\")\n",
        "    print(f\"Both = {len(FN_all)}, Supervised = {len(FN_sup)}, LLM = {len(FN_fs)}\")\n",
        "    print(f\"\\nPrinting {n} examples of each classifier type.\\n\")\n",
        "    print(\"------ FALSE POSITIVES ------\")\n",
        "    print(\"# LLM & supervised false positives\")\n",
        "    for i in FP_all[0:n]:\n",
        "      print(\"- \" + i)\n",
        "    print(\"--------\")\n",
        "    print(\"# Supervised false positives\")\n",
        "    for i in FP_sup[0:n]:\n",
        "      print(\"- \" + i)\n",
        "    print(\"--------\")\n",
        "    print(\"# LLM false positives\")\n",
        "    for i in FP_fs[0:n]:\n",
        "      print(\"- \" + i)\n",
        "    print(\"--------\")\n",
        "    print(\"------ FALSE NEGATIVES ------\")\n",
        "    print(\"# LLM & supervised false negatives\")\n",
        "    for i in FN_all[0:n]:\n",
        "      print(\"- \" + i)\n",
        "    print(\"--------\")\n",
        "    print(\"# Supervised false negatives\")\n",
        "    for i in FN_sup[0:n]:\n",
        "      print(\"- \" + i)\n",
        "    print(\"--------\")\n",
        "    print(\"# LLM false negatives\")\n",
        "    for i in FN_fs[0:n]:\n",
        "      print(\"- \" + i)\n",
        "\n",
        "\n",
        "  def RAMP_plot(self, x_col, y_col, group_col,\n",
        "                pastel_colors = ['#77B5FE', '#FF6961', '#B19CD9'],\n",
        "                title=\"\", width=800, height=500, line_width=2, line_opacity=0.5):\n",
        "    \"\"\"\n",
        "    Creates a connected scatter plot\n",
        "    \"\"\"\n",
        "    # Ensure the group column is categorized\n",
        "    self.df[group_col] = self.df[group_col].astype('category')\n",
        "\n",
        "    # Create the connected scatter plot using Plotly Express with lines\n",
        "    scatter_fig = px.line(self.df, x=x_col, y=y_col, color=group_col,\n",
        "                          title=title, template='plotly_white',\n",
        "                          labels={x_col: x_col, y_col: y_col, group_col: group_col},\n",
        "                          markers=True,  # Include markers at data points\n",
        "                          color_discrete_sequence=pastel_colors)  # Apply the pastel color palette\n",
        "\n",
        "    # Iterate through each group to add dashed lines connecting min and max x values\n",
        "    for group, group_df in self.df.groupby(group_col):\n",
        "        # Get minimum and maximum x values and their corresponding y values\n",
        "        min_x = group_df[x_col].min()\n",
        "        max_x = group_df[x_col].max()\n",
        "        min_y = group_df[group_df[x_col] == min_x][y_col].iloc[0]\n",
        "        max_y = group_df[group_df[x_col] == max_x][y_col].iloc[0]\n",
        "\n",
        "        # Find the index of the group's color in the palette\n",
        "        color_index = group_df[group_col].cat.codes.unique()[0] % len(pastel_colors)\n",
        "\n",
        "        # Add a dashed line to the scatter plot\n",
        "        scatter_fig.add_trace(go.Scatter(\n",
        "            x=[min_x, max_x],\n",
        "            y=[min_y, max_y],\n",
        "            mode='lines',\n",
        "            name=f'{group} - Range Line',\n",
        "            line=dict(color=pastel_colors[color_index], width=line_width, dash='dash'),\n",
        "            opacity=line_opacity,\n",
        "            showlegend=False))  # Hide this line from the legend\n",
        "\n",
        "    # Update layout and display the figure\n",
        "    scatter_fig.update_layout(title=title, width=width, height=height)\n",
        "    scatter_fig.show()\n"
      ],
      "metadata": {
        "id": "aW0xRPcIKELa"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Manual classification stage\n",
        "\n",
        "The first stage of RAMP is a manual coding stage, where a codebook is developed through the process of training coders and conducting small pilot inter-rater reliability studies. This section reports the inter-rater reliability of the throughput stage and the final inter-rater reliability on a shared dataset. The shared dataset was coded blind, with coders unaware of which sentences were being shared and which were exclusive to the individual."
      ],
      "metadata": {
        "id": "DMvNGUi-kJSW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1 Input:"
      ],
      "metadata": {
        "id": "iK_gyvGUkLiG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1.1 Data"
      ],
      "metadata": {
        "id": "e6Htv_uykRy-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "The raw dataset contains sentences from online dialogues, sampled from three sources:\n",
        "\n",
        "**Reddit conversations from 27 subreddits**.\n",
        "\n",
        "> This data was downloaded using the Reddit API by the authors.\n",
        "\n",
        "**Twitter Customer Support data** (Thought Vector & Axelbrooke, 2017).\n",
        "\n",
        "> This data was downloaded from: https://www.kaggle.com/datasets/thoughtvector/customer-support-on-twitter (Copyright: CC BY-NC-SA 4.0).\n",
        "\n",
        "**Wikipedia Talk Pages data**(Danescu-Niculescu-Mizil et al., 2012).\n",
        "\n",
        "> This data was downloaded using Cornell University's ConvoKit Python package (see: https://convokit.cornell.edu/documentation/wiki.html) (Copyright: CC BY 4.0)\n",
        "\n",
        "**Notes:**\n",
        "\n",
        "> All author names and sentences have been anonymized following the guidance of the [Anonymized University] ethics committee (Ref = XXXXX).\n",
        "> As a further precaution, the sentences are shuffled and the source (e.g., Reddit, Twitter) removed from the dataframe."
      ],
      "metadata": {
        "id": "RoxsE1Uc8HFn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Manual coded dataset final size\n",
        "print(f\"Full dataset size: {len(train) + len(validation)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wj9RKsx-YHDC",
        "outputId": "6271754d-436e-437f-fdc4-296b395b0ae1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Full dataset size: 21815\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the IRR from the final round (validation)\n",
        "IRR_final = St1Through[St1Through[\"Round\"]==6]\n",
        "IRR_through = St1Through[St1Through[\"Round\"]!=6]"
      ],
      "metadata": {
        "id": "5VoWDNwBRgQt"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2 Throughput"
      ],
      "metadata": {
        "id": "zX-a78DVkbbi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inter rater reliability across rour rounds of coder training:"
      ],
      "metadata": {
        "id": "0B23lDDzWzNk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tds = TextDataStats(IRR_through)\n",
        "tds.IRRreport().round(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "RCQOxLqEDsQr",
        "outputId": "f288bd6a-3f9f-4bd4-c531-181510ef73dd"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Round  Sample size  Agreement  Krippendorff's Alpha\n",
              "0  Round1          713       0.95                  0.57\n",
              "1  Round2         1228       0.97                  0.71\n",
              "2  Round3         1101       0.97                  0.72\n",
              "3  Round4          808       0.94                  0.78\n",
              "4  Round5          862       0.98                  0.76"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d1f46486-fd02-440a-a3e9-1c9780911e4d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Round</th>\n",
              "      <th>Sample size</th>\n",
              "      <th>Agreement</th>\n",
              "      <th>Krippendorff's Alpha</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Round1</td>\n",
              "      <td>713</td>\n",
              "      <td>0.95</td>\n",
              "      <td>0.57</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Round2</td>\n",
              "      <td>1228</td>\n",
              "      <td>0.97</td>\n",
              "      <td>0.71</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Round3</td>\n",
              "      <td>1101</td>\n",
              "      <td>0.97</td>\n",
              "      <td>0.72</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Round4</td>\n",
              "      <td>808</td>\n",
              "      <td>0.94</td>\n",
              "      <td>0.78</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Round5</td>\n",
              "      <td>862</td>\n",
              "      <td>0.98</td>\n",
              "      <td>0.76</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d1f46486-fd02-440a-a3e9-1c9780911e4d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d1f46486-fd02-440a-a3e9-1c9780911e4d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d1f46486-fd02-440a-a3e9-1c9780911e4d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-18499566-9689-45a1-a801-9c1597d52cc8\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-18499566-9689-45a1-a801-9c1597d52cc8')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-18499566-9689-45a1-a801-9c1597d52cc8 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"tds\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Round\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Round2\",\n          \"Round5\",\n          \"Round3\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sample size\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 214,\n        \"min\": 713,\n        \"max\": 1228,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1228,\n          862,\n          1101\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Agreement\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.016431676725154998,\n        \"min\": 0.94,\n        \"max\": 0.98,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.97,\n          0.98,\n          0.95\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Krippendorff's Alpha\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.08228000972289687,\n        \"min\": 0.57,\n        \"max\": 0.78,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.71,\n          0.76,\n          0.72\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that the Alpha gets progressively better. We ended the training and Round5 as the agreement diminishes from the previous round."
      ],
      "metadata": {
        "id": "iQJzLFKckjqe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.3 Output"
      ],
      "metadata": {
        "id": "hY6VX1eAkmlv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tds = TextDataStats(IRR_final)\n",
        "tds.IRRreport().round(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "t8A04avekqPi",
        "outputId": "85779f2c-ef94-4f0a-8b75-9959350c2329"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Round  Sample size  Agreement  Krippendorff's Alpha\n",
              "0  Round6         1610       0.98                  0.79"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-98eaa41b-fa4d-4615-806b-fefc86ea569f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Round</th>\n",
              "      <th>Sample size</th>\n",
              "      <th>Agreement</th>\n",
              "      <th>Krippendorff's Alpha</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Round6</td>\n",
              "      <td>1610</td>\n",
              "      <td>0.98</td>\n",
              "      <td>0.79</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-98eaa41b-fa4d-4615-806b-fefc86ea569f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-98eaa41b-fa4d-4615-806b-fefc86ea569f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-98eaa41b-fa4d-4615-806b-fefc86ea569f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"tds\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"Round\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Round6\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sample size\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 1610,\n        \"max\": 1610,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1610\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Agreement\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.98,\n        \"max\": 0.98,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.98\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Krippendorff's Alpha\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.79,\n        \"max\": 0.79,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.79\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is very good agreement (98%) with decent reliability (Krippendorff's Alpha  = 0.79). The high agreement is down to misunderstandings being very uncommon (8%). This means they are overrepresented by a pure agreement score.\n"
      ],
      "metadata": {
        "id": "SPSjO8BpXDkU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Computational stage"
      ],
      "metadata": {
        "id": "fivY_6dpkrZ8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1 Input"
      ],
      "metadata": {
        "id": "oYZCmJ-lkv6g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Information on the validation data = binary column is misunderstandings.\n",
        "tds = TextDataStats(validation)\n",
        "print(tds.BasicReport())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1HJN3au5YIyH",
        "outputId": "f1f01c4b-6478-4715-f410-7f686cad9e33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text Data Statistics Report\n",
            "\n",
            "General Statistics:\n",
            "        word_count\n",
            "mean         14.97\n",
            "std          11.71\n",
            "min           0.00\n",
            "median       12.00\n",
            "max         203.00\n",
            "\n",
            "Statistics by Binary Column:\n",
            "\n",
            "Group: 0\n",
            "word_count  mean       14.90\n",
            "            median     12.00\n",
            "            std        11.68\n",
            "            min         0.00\n",
            "            max       203.00\n",
            "\n",
            "Group: 1\n",
            "word_count  mean      15.82\n",
            "            median    12.00\n",
            "            std       12.09\n",
            "            min        2.00\n",
            "            max       80.00\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "These are the words for the misunderstanding dictionary rule-based classifier:"
      ],
      "metadata": {
        "id": "CUln424LEQSK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "terms = ['accord', 'acknowledge', 'actually', 'adjust', 'already', 'ambiguity',\n",
        "          'ambivalence', 'amend', 'angle', 'anomaly', 'apologize', 'approach',\n",
        "          'ask', 'assume', 'assumption', 'aware', 'awareness', 'baffle', 'befuddled',\n",
        "          'bewilderment', 'blunder', 'challenge', 'chat', 'cite',\n",
        "          'clarify', 'comprehend',  'concur', 'confirm', 'conflict',\n",
        "          'confuse', 'consensus', 'contradict', 'controversy', 'conversation',\n",
        "          'correct', 'debate', 'deceptive', 'deliberate', 'delusion', 'demonstrate',\n",
        "          'denial', 'detail', 'dialogue', 'disagree', 'disbelief', 'discombobulated',\n",
        "          'discord', 'discrepancy', 'discussion', 'disorientation', 'dispute',\n",
        "          'dissent', 'distortion', 'distrust', 'disturbance', 'doubt', 'edit',\n",
        "          'elaborate', 'elucidation', 'enlightened', 'equivocation', 'erroneous', 'error',\n",
        "          'examine', 'expand', 'explain', 'explication', 'exposition',\n",
        "          'expound', 'fallacy', 'false', 'fault', 'feedback', 'flaw', 'flummoxed',\n",
        "          'follow', 'gap', 'grasp', 'hear', 'highlight', 'how', 'hypothesis',\n",
        "          'ignorance', 'illusion', 'illustrate', 'imbalance', 'inaccuracy',\n",
        "          'incomprehension', 'incongruence', 'incorrect',\n",
        "          'informed', 'input', 'inquire', 'insight', 'interpret',\n",
        "          'interpretation', 'interrogate', 'investigate', 'justification',\n",
        "          'listen', 'mean', 'misacknowledge', 'misadvise',\n",
        "          'misalign', 'misaligned', 'misapply', 'misapprehend', 'misattribute',\n",
        "          'miscalculate', 'miscalibration', 'mischaracterize', 'misclassify',\n",
        "          'miscommunication', 'miscomprehend', 'misconceive', 'misconception',\n",
        "          'misconclude', 'misconstruction', 'misconstrue', 'misconstrued',\n",
        "          'miscontextualize', 'misconvey', 'misdiagnose', 'misdirect',\n",
        "          'misestimate', 'misfathom', 'misgauge', 'misgiving', 'mishandle',\n",
        "          'mishear', 'misinform', 'misinterpret',\n",
        "          'misjudge', 'misjudgment', 'mislead', 'mismanage', 'mismatch', 'misperceive',\n",
        "          'misplace', 'misportray', 'misread', 'misreport', 'misrepresentation',\n",
        "          'misstate', 'misstep', 'mistake', 'mistranslate','misunderstand', 'modify',\n",
        "          'muddle', 'nonconformity', 'nonplussed', 'objection', 'obscure', 'overlook',\n",
        "          'oversight','reinterpret', 'oversimplification', 'perceive',\n",
        "          'perplexity', 'perspective', 'presumption', 'probe', 'puzzle', 'puzzlement',\n",
        "          'query', 'question', 'quote', 'rationale', 'readdress', 'realize',\n",
        "          'reanalyze', 'reasoning', 'reassess', 'recognize', 'reconfirm', 'recontextualize',\n",
        "          'rectify', 'redress', 'reevaluate', 'reference', 'reiterate', 'rejection',\n",
        "          'rejoinder', 'reply', 'response', 'restate', 'rethink', 'retort', 'revise',\n",
        "          'said', 'saying', 'scrutinize', 'skepticism', 'slip', 'sorry', 'specify',\n",
        "          'speculation', 'standpoint', 'stumped', 'supposition', 'suspicion', 'unawareness',\n",
        "          'uncertainty', 'understand', 'unease', 'unpack', 'validate',\n",
        "          'verify', 'viewpoint', 'what', 'when', 'where', 'which', 'who', 'why',\n",
        "          \"wtf\", \"reflection\", \"delineate\", \"rebuttal\", \"synopsis\", \"evaluation\",\n",
        "          \"reconsider\", \"diverge\", \"introspection\", \"articulate\", \"review\", \"discern\",\n",
        "          \"analyze\", \"contravene\"]"
      ],
      "metadata": {
        "id": "iFGXqvH9kubG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is the pre-trained BERT model for the supervised classifier:"
      ],
      "metadata": {
        "id": "YHkOiOmKEWBC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictor = ktrain.load_predictor('supervised_model')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JonSwZrcEV2M",
        "outputId": "55875407-a2d6-47dd-bec2-a41c7b2b4726"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/initializers/initializers.py:120: UserWarning: The initializer GlorotNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initializer instance more than once.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is the prompt for the LLM classifier:"
      ],
      "metadata": {
        "id": "ZUFUiABGETYf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "role = \"\"\"\n",
        "*Role* You are a research assistant tasked with identifying whether a sentence indicates a misunderstanding.\n",
        "*Misunderstanding definition* A misunderstanding occurs during dialogue when one participant has an incorrect understanding of another’s perspective.\n",
        "\"\"\"\n",
        "prompt = \"\"\"\n",
        "There are two categories of misunderstanding:\n",
        "1. “Direct” misunderstandings. These occur when a participant evidences a misunderstanding of another participant’s point.\n",
        "2. “Felt” misunderstandings. These occur when a participant feels their previous turn was misunderstood by another participant.\n",
        "This is a non-exhaustive list of possible sentences indicating misunderstanding.\n",
        "1. Explicit statement: The sentence explicitly indicates the speaker doesn't understand another’s perspective (e.g., \"I don't get what you're trying to say about the dog\")\n",
        "2. Clarification question: The question seeks to clarify the other’s perspective (e.g., \"What do you mean?\")\n",
        "3. Request for confirmation: A question that seeks confirmation on the other’s understanding of the speaker’s previous turn(e.g., \"You really think that I meant all dogs?\")\n",
        "4. Correction of Other: Correcting another speaker’s misunderstanding of the present speaker’s previous turn(e.g., \"You've misunderstood my point\", “You don’t get it.”)\n",
        "5. Clarification or apology about speaker's intentions: Clarifying the meaning of what the speaker previously said (e.g., \"Sorry, I meant to say X\")\n",
        "6. Misunderstanding due to lack of response (e.g., \"Why did you change the subject?\")\n",
        "7. Editing a message at a later time: This is when a speaker in text-based dialogue comes back to edit their comment after the fact (e.g., \"EDIT\": That's what I said)\n",
        "Here are some examples of sentences indicating misunderstandings:\n",
        "- Jane, that article was what I was talking about.\n",
        "- Why not go further? - Do you think that was ok?\n",
        "- I apologise for saying that, but I meant the other stuff.\n",
        "- @John But when? - @John Please tell me why I've been stuck here for so long.\n",
        "- What drove that thought? - I actually said \"sure thing\".\n",
        "- You serious?\n",
        "- I'm not sure what I could have done differently.\n",
        "TASK:\n",
        "Does the below sentence indicate a possible misunderstanding?\n",
        "Only respond with \"Yes\" or \"No\"\n",
        "Sentence: {}\n",
        "Response:\"\"\""
      ],
      "metadata": {
        "id": "IjUet6QSkz1m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2 Throughput"
      ],
      "metadata": {
        "id": "KBCsSzjWk1EW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "These two plots show the classifier performance according to (1) Weighted F1 for the classifier and (2) Area Under the Precision Recall Curve"
      ],
      "metadata": {
        "id": "vKwY5i75e2Gu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "target_cols = [\"Order\",\"Classifier\",\"F1_avg\",\"F1_var\",\"AUC_PR\", \"AUC_ROC\",\"Precision\",\"Recall\",\"FP\",\"FN\",\"TP\",\"TN\"]\n",
        "ThroughRes = St2Through[target_cols].round(2).sort_values(\"AUC_PR\", ascending = False)\n",
        "ThroughRes = ThroughRes.rename(columns={\"F1_avg\": \"Weighted F1\", \"AUC_PR\":\"Area Under the Presicion-Recall Curve\"})\n",
        "tdf = ThroughRes.sort_values(by=[\"Order\",\"Classifier\"])\n",
        "tdf = tdf.replace({\"few-shot\":\"LLM\"})\n",
        "tds = TextDataStats(tdf)\n",
        "tds.RAMP_plot(\"Order\", \"Weighted F1\",\"Classifier\",width=800,height=500)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        },
        "id": "VlRkLaBcfABm",
        "outputId": "f9ad551d-109e-4bad-d989-b2fa48698045"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"e7572cbc-e6e0-4091-9ada-051bfef218ba\" class=\"plotly-graph-div\" style=\"height:500px; width:800px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"e7572cbc-e6e0-4091-9ada-051bfef218ba\")) {                    Plotly.newPlot(                        \"e7572cbc-e6e0-4091-9ada-051bfef218ba\",                        [{\"hovertemplate\":\"Classifier=LLM\\u003cbr\\u003eOrder=%{x}\\u003cbr\\u003eWeighted F1=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"LLM\",\"line\":{\"color\":\"#77B5FE\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines+markers\",\"name\":\"LLM\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21],\"xaxis\":\"x\",\"y\":[0.79,0.78,0.86,0.87,0.88,0.91,0.88,0.88,0.87,0.88,0.88,0.86,0.91,0.91,0.88,0.84,0.87,0.9,0.91,0.88,0.9],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":\"Classifier=rule-based\\u003cbr\\u003eOrder=%{x}\\u003cbr\\u003eWeighted F1=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"rule-based\",\"line\":{\"color\":\"#FF6961\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines+markers\",\"name\":\"rule-based\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21],\"xaxis\":\"x\",\"y\":[0.85,0.85,0.82,0.81,0.82,0.87,0.87,0.87,0.87,0.87,0.87,0.87,0.87,0.87,0.83,0.79,0.78,0.78,0.76,0.75,0.74],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":\"Classifier=supervised\\u003cbr\\u003eOrder=%{x}\\u003cbr\\u003eWeighted F1=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"supervised\",\"line\":{\"color\":\"#B19CD9\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines+markers\",\"name\":\"supervised\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21],\"xaxis\":\"x\",\"y\":[0.93,0.93,0.93,0.93,0.94,0.94,0.93,0.94,0.94,0.93,0.93,0.94,0.93,0.93,0.93,0.93,0.94,0.93,0.93,0.94,0.93],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"line\":{\"color\":\"#77B5FE\",\"dash\":\"dash\",\"width\":2},\"mode\":\"lines\",\"name\":\"LLM - Range Line\",\"opacity\":0.5,\"showlegend\":false,\"x\":[1,21],\"y\":[0.79,0.9],\"type\":\"scatter\"},{\"line\":{\"color\":\"#FF6961\",\"dash\":\"dash\",\"width\":2},\"mode\":\"lines\",\"name\":\"rule-based - Range Line\",\"opacity\":0.5,\"showlegend\":false,\"x\":[1,21],\"y\":[0.85,0.74],\"type\":\"scatter\"},{\"line\":{\"color\":\"#B19CD9\",\"dash\":\"dash\",\"width\":2},\"mode\":\"lines\",\"name\":\"supervised - Range Line\",\"opacity\":0.5,\"showlegend\":false,\"x\":[1,21],\"y\":[0.93,0.93],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Order\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Weighted F1\"}},\"legend\":{\"title\":{\"text\":\"Classifier\"},\"tracegroupgap\":0},\"margin\":{\"t\":60},\"title\":{\"text\":\"\"},\"width\":800,\"height\":500},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('e7572cbc-e6e0-4091-9ada-051bfef218ba');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tds.RAMP_plot(\"Order\", \"Area Under the Presicion-Recall Curve\",\"Classifier\", width=800,height=500)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        },
        "id": "TDcsjlrFfDkU",
        "outputId": "bf8eec0b-2c58-48fb-d78c-94a141ef0b14"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"22e39ac6-4ce4-4370-91b4-733326526b11\" class=\"plotly-graph-div\" style=\"height:500px; width:800px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"22e39ac6-4ce4-4370-91b4-733326526b11\")) {                    Plotly.newPlot(                        \"22e39ac6-4ce4-4370-91b4-733326526b11\",                        [{\"hovertemplate\":\"Classifier=LLM\\u003cbr\\u003eOrder=%{x}\\u003cbr\\u003eArea Under the Presicion-Recall Curve=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"LLM\",\"line\":{\"color\":\"#77B5FE\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines+markers\",\"name\":\"LLM\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21],\"xaxis\":\"x\",\"y\":[0.22,0.43,0.41,0.49,0.56,0.53,0.54,0.53,0.55,0.52,0.48,0.49,0.58,0.56,0.52,0.52,0.52,0.53,0.56,0.55,0.53],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":\"Classifier=rule-based\\u003cbr\\u003eOrder=%{x}\\u003cbr\\u003eArea Under the Presicion-Recall Curve=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"rule-based\",\"line\":{\"color\":\"#FF6961\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines+markers\",\"name\":\"rule-based\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21],\"xaxis\":\"x\",\"y\":[0.15,0.18,0.28,0.3,0.34,0.32,0.32,0.32,0.32,0.32,0.32,0.32,0.32,0.32,0.32,0.33,0.38,0.33,0.4,0.39,0.41],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":\"Classifier=supervised\\u003cbr\\u003eOrder=%{x}\\u003cbr\\u003eArea Under the Presicion-Recall Curve=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"supervised\",\"line\":{\"color\":\"#B19CD9\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines+markers\",\"name\":\"supervised\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21],\"xaxis\":\"x\",\"y\":[0.64,0.66,0.65,0.67,0.69,0.69,0.67,0.69,0.7,0.67,0.67,0.69,0.68,0.68,0.66,0.66,0.69,0.67,0.68,0.7,0.68],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"line\":{\"color\":\"#77B5FE\",\"dash\":\"dash\",\"width\":2},\"mode\":\"lines\",\"name\":\"LLM - Range Line\",\"opacity\":0.5,\"showlegend\":false,\"x\":[1,21],\"y\":[0.22,0.53],\"type\":\"scatter\"},{\"line\":{\"color\":\"#FF6961\",\"dash\":\"dash\",\"width\":2},\"mode\":\"lines\",\"name\":\"rule-based - Range Line\",\"opacity\":0.5,\"showlegend\":false,\"x\":[1,21],\"y\":[0.15,0.41],\"type\":\"scatter\"},{\"line\":{\"color\":\"#B19CD9\",\"dash\":\"dash\",\"width\":2},\"mode\":\"lines\",\"name\":\"supervised - Range Line\",\"opacity\":0.5,\"showlegend\":false,\"x\":[1,21],\"y\":[0.64,0.68],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Order\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Area Under the Presicion-Recall Curve\"}},\"legend\":{\"title\":{\"text\":\"Classifier\"},\"tracegroupgap\":0},\"margin\":{\"t\":60},\"title\":{\"text\":\"\"},\"width\":800,\"height\":500},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('22e39ac6-4ce4-4370-91b4-733326526b11');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Best supervised classifier and parameters\n",
        "supdf = St2Through[[\"Order\",\"Classifier\",\"F1_avg\",\"AUC_PR\",\"Precision\",\"Recall\",\"validation_size\",\"epochs\",\"learning_rate\",\"batch_size\"]]\n",
        "supdf[supdf[\"Classifier\"]==\"supervised\"].sort_values(\"AUC_PR\", ascending = False).head(1).round(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "H7ct4xwOb7JI",
        "outputId": "0ceec030-00d2-4fdd-b744-ce94b18de121"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Order  Classifier  F1_avg  AUC_PR  Precision  Recall  validation_size  \\\n",
              "61     20  supervised    0.94     0.7       0.74    0.62              0.3   \n",
              "\n",
              "    epochs  learning_rate  batch_size  \n",
              "61     4.0            0.0        64.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7760ff16-ed99-4b4a-9f28-fe6d3ec3d232\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Order</th>\n",
              "      <th>Classifier</th>\n",
              "      <th>F1_avg</th>\n",
              "      <th>AUC_PR</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>validation_size</th>\n",
              "      <th>epochs</th>\n",
              "      <th>learning_rate</th>\n",
              "      <th>batch_size</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>20</td>\n",
              "      <td>supervised</td>\n",
              "      <td>0.94</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.74</td>\n",
              "      <td>0.62</td>\n",
              "      <td>0.3</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>64.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7760ff16-ed99-4b4a-9f28-fe6d3ec3d232')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7760ff16-ed99-4b4a-9f28-fe6d3ec3d232 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7760ff16-ed99-4b4a-9f28-fe6d3ec3d232');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"supdf[supdf[\\\"Classifier\\\"]==\\\"supervised\\\"]\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"Order\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 20,\n        \"max\": 20,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          20\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Classifier\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"supervised\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1_avg\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.94,\n        \"max\": 0.94,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.94\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AUC_PR\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.7,\n        \"max\": 0.7,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.74,\n        \"max\": 0.74,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.74\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.62,\n        \"max\": 0.62,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.62\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"validation_size\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.3,\n        \"max\": 0.3,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"epochs\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 4.0,\n        \"max\": 4.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          4.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"learning_rate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"batch_size\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 64.0,\n        \"max\": 64.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          64.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Best rule-based classifier (using lemma list)\n",
        "rbdf = St2Through[[\"Order\",\"Classifier\",\"F1_avg\",\"AUC_PR\",\"Precision\",\"Recall\",\"PatternOrLemma\",\"train_size\",\"nTerms\"]]\n",
        "rbdf[rbdf[\"Classifier\"]==\"rule-based\"].sort_values(\"AUC_PR\", ascending = False).head(1).round(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "evTmH1ZWdVRO",
        "outputId": "72dc24a4-ccaa-4bf0-d426-bf4f109c500b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Order  Classifier  F1_avg  AUC_PR  Precision  Recall PatternOrLemma  \\\n",
              "41     21  rule-based    0.74    0.41       0.17    0.61          lemma   \n",
              "\n",
              "    train_size  nTerms  \n",
              "41       14728   230.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ae4129af-679b-411a-a137-73f9b45ef6ca\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Order</th>\n",
              "      <th>Classifier</th>\n",
              "      <th>F1_avg</th>\n",
              "      <th>AUC_PR</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>PatternOrLemma</th>\n",
              "      <th>train_size</th>\n",
              "      <th>nTerms</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>21</td>\n",
              "      <td>rule-based</td>\n",
              "      <td>0.74</td>\n",
              "      <td>0.41</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.61</td>\n",
              "      <td>lemma</td>\n",
              "      <td>14728</td>\n",
              "      <td>230.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ae4129af-679b-411a-a137-73f9b45ef6ca')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ae4129af-679b-411a-a137-73f9b45ef6ca button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ae4129af-679b-411a-a137-73f9b45ef6ca');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"rbdf[rbdf[\\\"Classifier\\\"]==\\\"rule-based\\\"]\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"Order\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 21,\n        \"max\": 21,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          21\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Classifier\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"rule-based\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1_avg\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.74,\n        \"max\": 0.74,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.74\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AUC_PR\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.41,\n        \"max\": 0.41,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.41\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.17,\n        \"max\": 0.17,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.17\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.61,\n        \"max\": 0.61,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.61\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"PatternOrLemma\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"lemma\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"train_size\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 14728,\n        \"max\": 14728,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          14728\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"nTerms\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 230.0,\n        \"max\": 230.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          230.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Best LLM classifiers (using prompt)\n",
        "rbdf = St2Through[[\"Order\",\"Classifier\",\"F1_avg\",\"AUC_PR\",\"Precision\",\"Recall\", \"train_size\",\"GPTmodel\"]]\n",
        "rbdf[rbdf[\"Classifier\"]==\"LLM\"].sort_values(\"AUC_PR\", ascending = False).head(1).round(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "q34Rv6ofehT9",
        "outputId": "8926c57f-a888-4bcf-a644-31f941737484"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Order Classifier  F1_avg  AUC_PR  Precision  Recall  train_size  \\\n",
              "12     13   few-shot    0.91    0.58       0.54    0.59        1000   \n",
              "\n",
              "       GPTmodel  \n",
              "12  gpt-4-turbo  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a27b1dd7-50c2-40e4-a567-6a006f06e163\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Order</th>\n",
              "      <th>Classifier</th>\n",
              "      <th>F1_avg</th>\n",
              "      <th>AUC_PR</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>train_size</th>\n",
              "      <th>GPTmodel</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>13</td>\n",
              "      <td>few-shot</td>\n",
              "      <td>0.91</td>\n",
              "      <td>0.58</td>\n",
              "      <td>0.54</td>\n",
              "      <td>0.59</td>\n",
              "      <td>1000</td>\n",
              "      <td>gpt-4-turbo</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a27b1dd7-50c2-40e4-a567-6a006f06e163')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a27b1dd7-50c2-40e4-a567-6a006f06e163 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a27b1dd7-50c2-40e4-a567-6a006f06e163');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"rbdf[rbdf[\\\"Classifier\\\"]==\\\"few-shot\\\"]\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"Order\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 13,\n        \"max\": 13,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          13\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Classifier\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"few-shot\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1_avg\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.91,\n        \"max\": 0.91,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.91\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AUC_PR\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.58,\n        \"max\": 0.58,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.58\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.54,\n        \"max\": 0.54,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.54\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.59,\n        \"max\": 0.59,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.59\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"train_size\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 1000,\n        \"max\": 1000,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1000\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"GPTmodel\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"gpt-4-turbo\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.3 Output"
      ],
      "metadata": {
        "id": "jivZGllok5VD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3.1 Classification reports"
      ],
      "metadata": {
        "id": "kSU0RKIlm_9L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "out = validation.copy()\n",
        "texts = out.text.to_list()\n",
        "true_scores = out.Misunderstanding.to_list()"
      ],
      "metadata": {
        "id": "S9BJA7wlE4yp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Rule-based classifier\n",
        "rbClassifier = Classifier(texts, true_scores)\n",
        "rbClassifier.add_rule_based_terms(terms, 'lemma')\n",
        "rbClassifier.run_classifier()\n",
        "rbClassifier.get_model_report()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AdfORjN8k9aW",
        "outputId": "31090e17-49b9-426b-93ee-b62065294cb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/spacy/util.py:1740: UserWarning:\n",
            "\n",
            "[W111] Jupyter notebook detected: if using `prefer_gpu()` or `require_gpu()`, include it in the same cell right before `spacy.load()` to ensure that the model is loaded on the correct device. More information: http://spacy.io/usage/v3#jupyter-notebook-gpu\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC-PR: 0.40\n",
            "\n",
            "AUC-ROC: 0.65\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.68      0.79      5909\n",
            "           1       0.14      0.63      0.24       511\n",
            "\n",
            "    accuracy                           0.67      6420\n",
            "   macro avg       0.55      0.65      0.51      6420\n",
            "weighted avg       0.89      0.67      0.75      6420\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For supervised machine learning classifier\n",
        "smlClassifier = Classifier(texts, true_scores)\n",
        "smlClassifier.add_SML_classifier(predictor)\n",
        "smlClassifier.run_classifier()\n",
        "smlClassifier.get_model_report()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_dFRe4RExfV",
        "outputId": "c0e854e7-b805-4a90-b048-e8d2b5c99d5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/spacy/util.py:1740: UserWarning:\n",
            "\n",
            "[W111] Jupyter notebook detected: if using `prefer_gpu()` or `require_gpu()`, include it in the same cell right before `spacy.load()` to ensure that the model is loaded on the correct device. More information: http://spacy.io/usage/v3#jupyter-notebook-gpu\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Supervised ML classifier configured with parameters: {}\n",
            "AUC-PR: 0.73\n",
            "\n",
            "AUC-ROC: 0.88\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.96      0.97      5909\n",
            "           1       0.65      0.79      0.71       511\n",
            "\n",
            "    accuracy                           0.95      6420\n",
            "   macro avg       0.81      0.88      0.84      6420\n",
            "weighted avg       0.95      0.95      0.95      6420\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LLM classifier\n",
        "gpt_model = \"gpt-4-turbo\"\n",
        "fsClassifier = Classifier(texts, true_scores)\n",
        "fsClassifier.add_few_shot_classifier(gpt_model, prompt, role)\n",
        "fsClassifier.run_classifier()\n",
        "fsClassifier.get_model_report()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DN8TjOTjEy7N",
        "outputId": "37e17295-6bd7-48df-fa9d-d75b31da5931"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/spacy/util.py:1740: UserWarning:\n",
            "\n",
            "[W111] Jupyter notebook detected: if using `prefer_gpu()` or `require_gpu()`, include it in the same cell right before `spacy.load()` to ensure that the model is loaded on the correct device. More information: http://spacy.io/usage/v3#jupyter-notebook-gpu\n",
            "\n",
            "100%|██████████| 6420/6420 [1:29:32<00:00,  1.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This run cost 33.76$ for 3376337 tokens. Average tokens: 525.91\n",
            "AUC-PR: 0.54\n",
            "\n",
            "AUC-ROC: 0.78\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.92      0.94      5909\n",
            "           1       0.41      0.64      0.50       511\n",
            "\n",
            "    accuracy                           0.90      6420\n",
            "   macro avg       0.69      0.78      0.72      6420\n",
            "weighted avg       0.92      0.90      0.91      6420\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#out[\"rule-based\"] = rbClassifier.pred_scores\n",
        "#out[\"supervised\"] = smlClassifier.pred_scores\n",
        "#out[\"few-shot\"] = fsClassifier.pred_scores\n",
        "#out.to_csv(\"RAMP_Stage3.csv\",index=False)"
      ],
      "metadata": {
        "id": "iv3FQ3-snIdm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Evaluation stage\n",
        "\n",
        "This section looks at disagreements and misclassifications in order to inform the final stage of RAMP. These are used to infer surprising findings from which to identify potential problems of construct and concept validity."
      ],
      "metadata": {
        "id": "5QvklA8-nEJT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1 Disagreements evaluation"
      ],
      "metadata": {
        "id": "j4wwlA44mblb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get sample of disagreements\n",
        "tds = TextDataStats(IRR_final)\n",
        "tds.get_disagreements(n=25)"
      ],
      "metadata": {
        "id": "TKmaQbQ8mgYh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2 Misclassifications evaluation"
      ],
      "metadata": {
        "id": "Ym2-GFNumkRr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "out = out.rename(columns={\"Misunderstanding\":\"Manual\", \"few-shot\":\"LLM\"})"
      ],
      "metadata": {
        "id": "NRF8EStoCdmG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tds = TextDataStats(out)\n",
        "misdf = tds.get_misclassifications(return_all = True)"
      ],
      "metadata": {
        "id": "1e47fC2YZ1Gs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For printing rule-based misclassifications - these are fairly arbitrary\n",
        "for i in misdf[misdf[\"Manual\"]==1][misdf[\"rule-based\"]==0].sample(10).text.values:\n",
        "  print(i)"
      ],
      "metadata": {
        "id": "mhrPActSaBn0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f8332fe-1a53-476b-ad05-2ee7fd040d99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Incredible, n'est pas?\n",
            "So orders can't be partially filled?\n",
            "I don't think anyone's point here was that you won't make more if you put more time into the same job, but that hard work does not equal success, but rather is likely just a component of it.\n",
            "As I mention there, I think it's broadly within criteria but I want nothing more to do with the personalities involved and its best if someone else closed it.\n",
            "My focus is on Chinese version of wikipedia, not the English version.\n",
            "I shouldn't have dragged you along if I did.\n",
            "Stealing hubcaps?\n",
            "No put stickers on things that changed the perception of them Like he would put a woodchuck sticker on the hand operated pencil sharpener and stickers that read, \"Lies?\" on the globe because despite being a science teacher he was a flat earther.\n",
            "It's fine.\n",
            "Are you complaining about the content of the statement or just about the way it was expressed?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-3b1cc0282d4c>:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
            "  for i in misdf[misdf[\"Manual\"]==1][misdf[\"rule-based\"]==0].sample(10).text.values:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For supervised and few shot classifiers\n",
        "tds = TextDataStats(out)\n",
        "tds.get_misclassifications(n=20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7Fvi5Aenrj-",
        "outputId": "306db155-388b-4f60-c2bb-35ab704150c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- False positives count: --\n",
            "Both = 0, Supervised = 118, Few-shot = 372\n",
            "\n",
            "--- False negatives count: --\n",
            "Both = 104, Supervised = 46, Few-shot = 124\n",
            "\n",
            "Printing 20 examples of each classifier type.\n",
            "\n",
            "------ FALSE POSITIVES ------\n",
            "# Few-shot & supervised false positives\n",
            "--------\n",
            "# Supervised false positives\n",
            "- A google time-stamped prophecy is neither an opinion, experience nor is it an argument, so I can't see how it is original research.\n",
            "- I also have to admit that running into you has made this avocation less than enjoyable as I seek to begin to respond to the grain and chaff issue I referred to in a previous edit.\n",
            "- This proves my point too.\n",
            "- Indonesian organisations with english names as title of article and the indonesian name as the aka please?\n",
            "- Are you having this issue with any other channels?\n",
            "- I don't care about martyrdom, etc., or any dramas.\n",
            "- But why is that ideology so attractive?\n",
            "- If you can't, it's no problem; I just thought I'd ask.\n",
            "- @Company_Handle I did not hear back from you yet.\n",
            "- Now you're just being uncivil and insulting.\n",
            "- I wanted to talk to them, but didn't know where to start.\n",
            "- I understand your frustration at seeing a lot of what you've created slowly whittled away, but [http:\\/\\/en.wikipedia.org\\/w\\/index.php?title=Suzi_Suzuki&curid=4775796&diff=437390137&oldid=437364401 this] is 100% pure [[WP:POINT]].\n",
            "- As for \\\"taking recentism to new heights\\\", I stand by that attack on the edit.\n",
            "- Belatedly, I've added the material I mentioned earlier concerning individual reactions to Laurie's books upon their publication.\n",
            "- It's me, again.\n",
            "- Like you, I wrote on what I know, so it was easy.\n",
            "- Oh no!!\n",
            "- @Company_Handle ?\n",
            "- I thought not.\n",
            "- My phone been on 1x for 2 fucking days wtf is 1x?\n",
            "--------\n",
            "# Few-shot false positives\n",
            "- And I am not some crazed guy out to mock and disrupt his life, regardless of what he says ot thinks.\n",
            "- Where do you see the blog is sponsored by Parade Magazine.\n",
            "- Any clues as to how I can fix?\n",
            "- Thanks for the article, which does not in fact discuss ''how'' to distinguish empty matrices, although it does mention their distinctiveness.\n",
            "- this is amc, but i feel you\n",
            "- They fought for you to be able to, not to require you to This phrase mostly comes up when you decide not to care about something someone else feels strongly about\n",
            "- Cant tell if that's the pilot or the undercarriage that gets fired out the front.\n",
            "- Just stop thinking your above others be you only listen to a few of biggie and Christopher's songs when you don't give anything else a try.\n",
            "- Don't fool yourself, that's what's going on.\n",
            "- If my words are not clear, please point out the parts which need further explaining.\n",
            "- Do you have a source for your reversion on [[:Template:Infobox Family Guy Season 7]]?\n",
            "- @Company_Handle It say's I'm verified been when I click the user detail this is the next page.\n",
            "- So I continually request a discount that I'm entitled to with &amp; they don't give info.\n",
            "- Good Day - Sotcr Excuse my English (\n",
            "- I would appreciate if you will take other look and give your opinion.\n",
            "- Your warnings weren't placed amongst the accumulation at [[User_talk:82.111.23.171|Reading Borough Council]].\n",
            "- And I agree, it can be helpful to get an outside perspective to make sure that all readers can understand the subject, too \\u2013 myself being one that really doesn't know anything about the sport of [[drag racing]].\n",
            "- Hello, I have sent 2 coppies of my unblock request to arbcom, one in march, and one in early April, but no response, so I am seaking advice, what else is there for me to do, I'm totaly out of ideas and I have lost faith in wikipedia.\n",
            "- @Company_Handle be nice though if the whole range was available esp in an Xtra store, I currently have to drive 10km to James for more choice.. @Company_Handle hi im interested in the new ones the peppercorn and \"goats\" cheese I already know where the existing Free From cheezes can.be got.\n",
            "- Please, could someone tell me what next?\n",
            "--------\n",
            "------ FALSE NEGATIVES ------\n",
            "# Few-shot & supervised false negatives\n",
            "- Its happened a few times now.Is it supposed to be like that?\n",
            "- @Company_Handle That's so strange - clicked on the link and it isn't showing that late :( \n",
            "- Which will be better??\n",
            "- So what about everyone else?\n",
            "- @Company_Handle Will I still be getting a Scorpio editon?\n",
            "- I hope you didn't think it was serious.\n",
            "- I can't answer to all your questions since I don't think to have been involved in all the edits you talk about.\n",
            "- Was it still showing as downloading for you?\n",
            "- Two flights in a row????\n",
            "- &#x200B; It is true that they are wrong, but how should they know?\n",
            "- Does this mean that articles such as [[Duality (Song)]] and [[Mirrorcle World]] are invalid, as well as all of [[The Gazette]]'s other singles?\n",
            "- To customer CARE?\n",
            "- Is that right?\n",
            "- That's why I needed to double-check.\n",
            "- But yes obviously that Facebook whatever stuff is actually wrong i just wanted to point out that an actual number for the death rate exists and has actually existed for many months\n",
            "- I was wondering this too, or if it's something you intentionally do to trick your brain?\n",
            "- Yes, please do that, if you change it to non consensus then it stops people quoting it as if it was decided by the review when it wasn't.- \n",
            "- > Okay, when I wrote this, I was a little too focused on deliberate acts of self expression rather than things people are born with.\n",
            "- :-) On an unrelated note, I've obviously read your user page -- is your daughter killing you the same way ours is killing us?\n",
            "- No, he didn't.\n",
            "--------\n",
            "# Supervised false negatives\n",
            "- Not sure what that is\n",
            "- But... they do.\n",
            "- To the user whose page this is, examine the situation as you will, but I thought I'd leave my two cents when the person above is trying to portray me as someone out to ruin the article.\n",
            "- Mark, the experience you are describing is something we'd never do.\n",
            "- What am I doing?\n",
            "- I take that back.\n",
            "- How can you fame a Wikipedian?\n",
            "- For one i didn't even know the person \\\"personally\\\".\n",
            "- How is this photo relevant to Rachel's life?\n",
            "- How does it make it make Wikipedia more user friendly to alter [[Natasha]] to [[Kelly of England|Henry VIII]]?\n",
            "- FA work is fine and I'm sure WMC could assist in non CC related article improvement but once a bulls eye get painted on anyone of this high a profile on this project, someone is always going to be the ready to play smackdown if such an editor so much as twitches \\\"incorrectly\\\"...my understanding as it was clarified to me was that user talkpages, even your own user talkpage are taboo for issues related to the topic ban.--\n",
            "- That may be (one can never be sure), but the editors don't seem to understand the serious problems with the page.\n",
            "- Can you elaborate the implications of your argument?\n",
            "- @Company_Handle this is the enough apologies you have sent, it's enough to last me a life time .. clean up your mess \n",
            "- Might I ask you to check out my responses to the issues you raised, specifically the questions I asked about images?\n",
            "- The rest not so right thanks for correcting me!\n",
            "- Could you confirm If you have contacted the support team through link provided earlier?\n",
            "- Edit: this is for areas that don't normally get freezing temperatures, where houses aren't designed for those temperatures.\n",
            "- I guess you think more highly of userboxes than myself.\n",
            "- @Company_Handle What number are you dialing?\n",
            "--------\n",
            "# Few-shot false negatives\n",
            "- How would we know if it was true or not if someone credible hasn't verified it?\n",
            "- For the reasons stated above, I'm not sure what the right venue is.\n",
            "- If it is it.\n",
            "- @Company_Handle Hmm...you've stumped us, Jeffrey!\n",
            "- Simple Kelli, I'm sorry I wasn't able to take up the suggestion, I'm just a little busy in that pesky real world at the moment (to the extent I'll be working on the weekend, something that's unheard of for me!)\n",
            "- I said it before and say it again: the idea of mentors who are selected because \\\"they have tangled with this person before and will drop the hammer\\\" is moonbats at best, and sneaky\\/vindictive at worst.\n",
            "- My focus is on Chinese version of wikipedia, not the English version.\n",
            "- With me, you're largely preaching to the choir, although I didn't know much in the way of specifics.\n",
            "- I read [[User:SchmuckyTheCat\\/Mainland_China]] before I take action against your editing.\n",
            "- I'm not edit warring.\n",
            "- I forgot that we are on earth and that there are forces applied on objects that arent present in space lol.\n",
            "- I'm just sending everyone who's been involved with it the same generic message so I'm not seeming biased and so that I get everyone involved who has a desire to be involved :)\n",
            "- Please see my post to the article's talk page\n",
            "- Fair enough - I suppose I let some of this stuff get to me too much, which is why I felt it best to just take that contentious page off my watchlist.\n",
            "- I mean the argument is that were not a meritocracy because one not all jobs pay the same, and two we have different starting circumstances.\n",
            "- I didn't read the whole mv section.\n",
            "- Woops, no I can't, sorry.\n",
            "- Again, we can only reiterate our sincere apologies.\n",
            "- As I mention there, I think it's broadly within criteria but I want nothing more to do with the personalities involved and its best if someone else closed it.\n",
            "- I mean your proposal in bold (also bold proposal) about FSA's.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2.1 Using LIME to explore BERT classifier"
      ],
      "metadata": {
        "id": "C6djwU6rmv6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For assessing the supervised classifier FN and FP\n",
        "predictor.explain(\"It's me, again\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "id": "IxRV_yhTa7J9",
        "outputId": "417a389d-0e44-4625-a068-84e5a3a8ccec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <style>\n",
              "    table.eli5-weights tr:hover {\n",
              "        filter: brightness(85%);\n",
              "    }\n",
              "</style>\n",
              "\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "        \n",
              "\n",
              "    \n",
              "\n",
              "        \n",
              "\n",
              "        \n",
              "    \n",
              "        \n",
              "        \n",
              "    \n",
              "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
              "            <b>\n",
              "    \n",
              "        y=Misunderstanding\n",
              "    \n",
              "</b>\n",
              "\n",
              "    \n",
              "    (probability <b>0.799</b>, score <b>1.378</b>)\n",
              "\n",
              "top features\n",
              "        </p>\n",
              "    \n",
              "    <table class=\"eli5-weights\"\n",
              "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
              "        <thead>\n",
              "        <tr style=\"border: none;\">\n",
              "            \n",
              "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
              "                    Contribution<sup>?</sup>\n",
              "                </th>\n",
              "            \n",
              "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
              "            \n",
              "        </tr>\n",
              "        </thead>\n",
              "        <tbody>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +2.777\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        Highlighted in text (sum)\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "        \n",
              "\n",
              "        \n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 87.63%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -1.399\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        &lt;BIAS&gt;\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "\n",
              "        </tbody>\n",
              "    </table>\n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n",
              "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
              "        <span style=\"background-color: hsl(120, 100.00%, 74.54%); opacity: 0.90\" title=\"1.709\">it</span><span style=\"opacity: 0.80\">&#x27;</span><span style=\"background-color: hsl(0, 100.00%, 92.22%); opacity: 0.82\" title=\"-0.314\">s</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 87.68%); opacity: 0.84\" title=\"0.606\">me</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(120, 100.00%, 60.00%); opacity: 1.00\" title=\"3.259\">again</span>\n",
              "    </p>\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictor.explain(\"Mark, the experience you are describing is something we'd never do.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "id": "-FSv-aABefP8",
        "outputId": "25634fc7-81f2-4613-f5bd-70a469c8c583"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <style>\n",
              "    table.eli5-weights tr:hover {\n",
              "        filter: brightness(85%);\n",
              "    }\n",
              "</style>\n",
              "\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "        \n",
              "\n",
              "    \n",
              "\n",
              "        \n",
              "\n",
              "        \n",
              "    \n",
              "        \n",
              "        \n",
              "    \n",
              "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
              "            <b>\n",
              "    \n",
              "        y=not_Misunderstanding\n",
              "    \n",
              "</b>\n",
              "\n",
              "    \n",
              "    (probability <b>0.701</b>, score <b>-0.850</b>)\n",
              "\n",
              "top features\n",
              "        </p>\n",
              "    \n",
              "    <table class=\"eli5-weights\"\n",
              "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
              "        <thead>\n",
              "        <tr style=\"border: none;\">\n",
              "            \n",
              "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
              "                    Contribution<sup>?</sup>\n",
              "                </th>\n",
              "            \n",
              "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
              "            \n",
              "        </tr>\n",
              "        </thead>\n",
              "        <tbody>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +1.272\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        &lt;BIAS&gt;\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "        \n",
              "\n",
              "        \n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 90.76%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -0.422\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        Highlighted in text (sum)\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "\n",
              "        </tbody>\n",
              "    </table>\n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n",
              "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
              "        <span style=\"background-color: hsl(0, 100.00%, 91.80%); opacity: 0.82\" title=\"-0.289\">mark</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(0, 100.00%, 87.58%); opacity: 0.84\" title=\"-0.523\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 84.45%); opacity: 0.85\" title=\"0.721\">experience</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 65.61%); opacity: 0.96\" title=\"-2.240\">you</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.54%); opacity: 0.82\" title=\"-0.252\">are</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 60.00%); opacity: 1.00\" title=\"-2.780\">describing</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 87.81%); opacity: 0.84\" title=\"-0.509\">is</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.96%); opacity: 0.81\" title=\"-0.144\">something</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 71.82%); opacity: 0.92\" title=\"-1.685\">we</span><span style=\"opacity: 0.80\">&#x27;</span><span style=\"background-color: hsl(120, 100.00%, 77.01%); opacity: 0.89\" title=\"1.260\">d</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 70.08%); opacity: 0.93\" title=\"-1.836\">never</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.63%); opacity: 0.81\" title=\"0.118\">do</span><span style=\"opacity: 0.80\">.</span>\n",
              "    </p>\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For assessing the supervised classifier FN and FP\n",
        "predictor.explain(\"Not sure what that is\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "id": "CmZKiXyCbTMC",
        "outputId": "bf9a779d-be21-45e5-9202-adbcf1ee0978"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <style>\n",
              "    table.eli5-weights tr:hover {\n",
              "        filter: brightness(85%);\n",
              "    }\n",
              "</style>\n",
              "\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "        \n",
              "\n",
              "    \n",
              "\n",
              "        \n",
              "\n",
              "        \n",
              "    \n",
              "        \n",
              "        \n",
              "    \n",
              "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
              "            <b>\n",
              "    \n",
              "        y=not_Misunderstanding\n",
              "    \n",
              "</b>\n",
              "\n",
              "    \n",
              "    (probability <b>0.432</b>, score <b>0.275</b>)\n",
              "\n",
              "top features\n",
              "        </p>\n",
              "    \n",
              "    <table class=\"eli5-weights\"\n",
              "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
              "        <thead>\n",
              "        <tr style=\"border: none;\">\n",
              "            \n",
              "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
              "                    Contribution<sup>?</sup>\n",
              "                </th>\n",
              "            \n",
              "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
              "            \n",
              "        </tr>\n",
              "        </thead>\n",
              "        <tbody>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 83.32%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +0.929\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        &lt;BIAS&gt;\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "        \n",
              "\n",
              "        \n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 80.00%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -1.204\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        Highlighted in text (sum)\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "\n",
              "        </tbody>\n",
              "    </table>\n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n",
              "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
              "        <span style=\"background-color: hsl(120, 100.00%, 81.83%); opacity: 0.86\" title=\"0.456\">not</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 71.37%); opacity: 0.92\" title=\"0.873\">sure</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 67.48%); opacity: 0.95\" title=\"-1.047\">what</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 60.00%); opacity: 1.00\" title=\"-1.407\">that</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 64.52%); opacity: 0.97\" title=\"-1.186\">is</span>\n",
              "    </p>\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For assessing the supervised classifier FN and FP\n",
        "predictor.explain(\"But... They do.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "id": "dWDBjWMGzCFk",
        "outputId": "2caca445-afc6-458c-c38e-067d452478d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <style>\n",
              "    table.eli5-weights tr:hover {\n",
              "        filter: brightness(85%);\n",
              "    }\n",
              "</style>\n",
              "\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "        \n",
              "\n",
              "    \n",
              "\n",
              "        \n",
              "\n",
              "        \n",
              "    \n",
              "        \n",
              "        \n",
              "    \n",
              "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
              "            <b>\n",
              "    \n",
              "        y=not_Misunderstanding\n",
              "    \n",
              "</b>\n",
              "\n",
              "    \n",
              "    (probability <b>0.997</b>, score <b>-5.930</b>)\n",
              "\n",
              "top features\n",
              "        </p>\n",
              "    \n",
              "    <table class=\"eli5-weights\"\n",
              "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
              "        <thead>\n",
              "        <tr style=\"border: none;\">\n",
              "            \n",
              "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
              "                    Contribution<sup>?</sup>\n",
              "                </th>\n",
              "            \n",
              "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
              "            \n",
              "        </tr>\n",
              "        </thead>\n",
              "        <tbody>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +5.248\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        Highlighted in text (sum)\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 95.21%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +0.682\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        &lt;BIAS&gt;\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "        \n",
              "\n",
              "        \n",
              "        \n",
              "\n",
              "        </tbody>\n",
              "    </table>\n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n",
              "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
              "        <span style=\"background-color: hsl(120, 100.00%, 84.97%); opacity: 0.85\" title=\"0.600\">but</span><span style=\"opacity: 0.80\">... </span><span style=\"background-color: hsl(120, 100.00%, 72.94%); opacity: 0.91\" title=\"1.390\">they</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 60.00%); opacity: 1.00\" title=\"2.429\">do</span><span style=\"opacity: 0.80\">.</span>\n",
              "    </p>\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Conclusions\n",
        "\n",
        "In Stage 1, we had acceptable inter-rater reliability (Krippendorff's Alpha = 0.79) following 5 training rounds.\n",
        "In Stage 2, we created three different text classifiers, one rule-based, one supervised, and one LLM. Overall, the supervised machine learning classifier – a fine-tuned BERT model – is much better than both the LLM and rule-based classifiers. The classifier's performance is acceptable (AUC PR = 0.73) with room for improvement.\n",
        "\n",
        " When troubleshooting the results, we can see that the false negatiives are missing some key clarification questions (e.g., \"So what about everyone else?\"). We can also see that the classifiers are picking up on \"new information\" questions, not directed at another's perspeective (e.g., \"Are you having this issue with any other channels?\"). The misclassifications indicate that the classifier is generally struggling with edge cases more than standard cases."
      ],
      "metadata": {
        "id": "VbMaI0IKk_0H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Export notebook:"
      ],
      "metadata": {
        "id": "RW6oyH4WK7U3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary packages\n",
        "!sudo apt-get install texlive-xetex texlive-fonts-recommended texlive-plain-generic"
      ],
      "metadata": {
        "id": "M15jQ7qrK5j5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# First MANUALLY download locally to the working directory\n",
        "# Convert the downloaded file to an HTML file\n",
        "!jupyter nbconvert --to PDF \"RAMP_CaseStudy_12May2024_v31.ipynb\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7mKMhSOIIv7f",
        "outputId": "72e7663b-8772-4065-e540-df37aa329174"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NbConvertApp] Converting notebook RAMP_CaseStudy_12May2024_v31.ipynb to PDF\n",
            "/usr/local/lib/python3.10/dist-packages/nbconvert/filters/datatypefilter.py:41: UserWarning: Your element with mimetype(s) dict_keys(['text/html']) is not able to be represented.\n",
            "  warn(\n",
            "[NbConvertApp] Writing 178109 bytes to notebook.tex\n",
            "[NbConvertApp] Building PDF\n",
            "[NbConvertApp] Running xelatex 3 times: ['xelatex', 'notebook.tex', '-quiet']\n",
            "[NbConvertApp] Running bibtex 1 time: ['bibtex', 'notebook']\n",
            "[NbConvertApp] WARNING | bibtex had problems, most likely because there were no citations\n",
            "[NbConvertApp] PDF successfully created\n",
            "[NbConvertApp] Writing 163015 bytes to RAMP_CaseStudy_12May2024_v31.pdf\n"
          ]
        }
      ]
    }
  ]
}