{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNbf9cPPcFxjNOSX3KtH1VG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alexiamhe93/RAMP_method/blob/main/RAMP_code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RAMP Case Study Python Notebook\n",
        "\n",
        "This Python notebook is used to replicate the results of the paper titled:\n",
        "\n",
        "\"RAMP: the Recursive Adjustment of Measurement Protocols method for developing textual measures in psychology\"\n",
        "\n",
        "\n",
        "The RAMP method has two main stages:\n",
        "1. A manual coding stage: Used to generate an annotated dataset for a target construct.\n",
        "2. A classifier development stage: Uses the annotated dataset to develop a text classifier.\n",
        "\n",
        "Each stage has an *input*, *throughput*, and *output* phase.\n",
        "\n",
        "Stage 1:\n",
        "1. Input (Manual): *write initial codebook*, *gather data*\n",
        "2. Throughput (Manual): repeat on training data: *Train coders*, *code sample data*, *inter-rater reliability on sample*, *troubleshoot misclassifications*, *adjust codebook*\n",
        "3. Output (Manual): *finalize notebook*, *code full dataset*, *inter-rater reliability on shared subset*\n",
        "\n",
        "Stage 2:\n",
        "1. Input (Automated): *define protocol parameters*, *split dataset into training and validation*\n",
        "2. Throughput (Automated): Repeat on training data: *run model on sample data*, *troubleshoot misclassifications*, *change protocol parameters*\n",
        "3. Output (Automated): *Finalize protocol*, *Run on validation data*\n",
        "\n",
        "<<< EMBED LOOP DIAGRAM >>>\n",
        "\n",
        "\n",
        "The case study applies RAMP to measuring misunderstandings in online dialogue data.\n",
        "\n",
        "The notebook is structured in terms of the RAMP stages, with an additional first section for initializing all the relevant functions and objects.\n",
        "\n",
        "The notebook was designed using Google Colab on a Nvidia T4 GPU (free with log-in). The code works locally but all dependencies from the \"Load packages\" will have to be installed."
      ],
      "metadata": {
        "id": "Ht0MhYw8ggZq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0. Initiate notebook"
      ],
      "metadata": {
        "id": "0NK-mCzVj-K0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0.1 Install and load packages"
      ],
      "metadata": {
        "id": "l1uWzkOxkBaG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3xHt9VHlgZMO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eaa4951f-ed09-4d64-fec5-9b50b01b8268"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ktrain\n",
            "  Downloading ktrain-0.41.3.tar.gz (25.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25.3/25.3 MB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from ktrain) (1.2.2)\n",
            "Requirement already satisfied: matplotlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from ktrain) (3.7.1)\n",
            "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from ktrain) (2.0.3)\n",
            "Requirement already satisfied: fastprogress>=0.1.21 in /usr/local/lib/python3.10/dist-packages (from ktrain) (1.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from ktrain) (2.31.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from ktrain) (1.4.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from ktrain) (24.0)\n",
            "Collecting langdetect (from ktrain)\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m44.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: jieba in /usr/local/lib/python3.10/dist-packages (from ktrain) (0.42.1)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.10/dist-packages (from ktrain) (3.3.2)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from ktrain) (5.2.0)\n",
            "Collecting syntok>1.3.3 (from ktrain)\n",
            "  Downloading syntok-1.4.4-py3-none-any.whl (24 kB)\n",
            "Collecting tika (from ktrain)\n",
            "  Downloading tika-2.6.0.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from ktrain) (4.40.2)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from ktrain) (0.1.99)\n",
            "Collecting keras_bert>=0.86.0 (from ktrain)\n",
            "  Downloading keras-bert-0.89.0.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting whoosh (from ktrain)\n",
            "  Downloading Whoosh-2.7.4-py2.py3-none-any.whl (468 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.8/468.8 kB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras_bert>=0.86.0->ktrain) (1.25.2)\n",
            "Collecting keras-transformer==0.40.0 (from keras_bert>=0.86.0->ktrain)\n",
            "  Downloading keras-transformer-0.40.0.tar.gz (9.7 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting keras-pos-embd==0.13.0 (from keras-transformer==0.40.0->keras_bert>=0.86.0->ktrain)\n",
            "  Downloading keras-pos-embd-0.13.0.tar.gz (5.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting keras-multi-head==0.29.0 (from keras-transformer==0.40.0->keras_bert>=0.86.0->ktrain)\n",
            "  Downloading keras-multi-head-0.29.0.tar.gz (13 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting keras-layer-normalization==0.16.0 (from keras-transformer==0.40.0->keras_bert>=0.86.0->ktrain)\n",
            "  Downloading keras-layer-normalization-0.16.0.tar.gz (3.9 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting keras-position-wise-feed-forward==0.8.0 (from keras-transformer==0.40.0->keras_bert>=0.86.0->ktrain)\n",
            "  Downloading keras-position-wise-feed-forward-0.8.0.tar.gz (4.1 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting keras-embed-sim==0.10.0 (from keras-transformer==0.40.0->keras_bert>=0.86.0->ktrain)\n",
            "  Downloading keras-embed-sim-0.10.0.tar.gz (3.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting keras-self-attention==0.51.0 (from keras-multi-head==0.29.0->keras-transformer==0.40.0->keras_bert>=0.86.0->ktrain)\n",
            "  Downloading keras-self-attention-0.51.0.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->ktrain) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->ktrain) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->ktrain) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->ktrain) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->ktrain) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->ktrain) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->ktrain) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->ktrain) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->ktrain) (2024.1)\n",
            "Requirement already satisfied: regex>2016 in /usr/local/lib/python3.10/dist-packages (from syntok>1.3.3->ktrain) (2023.12.25)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from langdetect->ktrain) (1.16.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->ktrain) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->ktrain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->ktrain) (2024.2.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->ktrain) (1.11.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->ktrain) (3.5.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tika->ktrain) (67.7.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers->ktrain) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers->ktrain) (0.20.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers->ktrain) (6.0.1)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers->ktrain) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers->ktrain) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers->ktrain) (4.66.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers->ktrain) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers->ktrain) (4.11.0)\n",
            "Building wheels for collected packages: ktrain, keras_bert, keras-transformer, keras-embed-sim, keras-layer-normalization, keras-multi-head, keras-pos-embd, keras-position-wise-feed-forward, keras-self-attention, langdetect, tika\n",
            "  Building wheel for ktrain (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ktrain: filename=ktrain-0.41.3-py3-none-any.whl size=25316960 sha256=9adb42694096de4f79b7c4eb3f136d89b942d852800d72db5f5738813c2f7690\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/76/11/5b953090eebf531f660948a30cd26e70260619f6480f186a5a\n",
            "  Building wheel for keras_bert (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras_bert: filename=keras_bert-0.89.0-py3-none-any.whl size=33500 sha256=d2d5341a3cf533f0440d7bb68e89abdfd0b262cdcb9fefe91652b46991931048\n",
            "  Stored in directory: /root/.cache/pip/wheels/89/0c/04/646b6fdf6375911b42c8d540a8a3fda8d5d77634e5dcbe7b26\n",
            "  Building wheel for keras-transformer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-transformer: filename=keras_transformer-0.40.0-py3-none-any.whl size=12286 sha256=c9e0cc64c54eb03b35eba93bcc2026e57e243f59b0ecf270f57ab66037c02b0e\n",
            "  Stored in directory: /root/.cache/pip/wheels/f2/cb/22/75a0ad376129177f7c95c0d91331a18f5368fd657f4035ba7c\n",
            "  Building wheel for keras-embed-sim (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-embed-sim: filename=keras_embed_sim-0.10.0-py3-none-any.whl size=3944 sha256=79e46ffac8fe6b44e85266b78bde5bd31b85128a544a05b465089caac8ba52c7\n",
            "  Stored in directory: /root/.cache/pip/wheels/82/32/c7/fd35d0d1b840a6c7cbd4343f808d10d0f7b87d271a4dbe796f\n",
            "  Building wheel for keras-layer-normalization (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-layer-normalization: filename=keras_layer_normalization-0.16.0-py3-none-any.whl size=4654 sha256=029bba64b51b80a7fe08055c2df5647784b2e3baaf1626c0132e0ea5ee055b4d\n",
            "  Stored in directory: /root/.cache/pip/wheels/ed/3a/4b/21db23c0cc56c4b219616e181f258eb7c57d36cc5d056fae9a\n",
            "  Building wheel for keras-multi-head (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-multi-head: filename=keras_multi_head-0.29.0-py3-none-any.whl size=14976 sha256=d859d292325f31186ff45854094161e78cb3bc901c71391332f2a41bdc511fb4\n",
            "  Stored in directory: /root/.cache/pip/wheels/cb/23/4b/06d7ae21714f70fcc25b48f972cc8e5e7f4b6b764a038b509d\n",
            "  Building wheel for keras-pos-embd (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-pos-embd: filename=keras_pos_embd-0.13.0-py3-none-any.whl size=6945 sha256=7ed10b3dc14fd12525a4a59dbec4f753f8ef4109a416adf7f46cbf30bd3f65e4\n",
            "  Stored in directory: /root/.cache/pip/wheels/78/07/1b/b1ca47b6ac338554b75c8f52c54e6a2bfbe1b07d79579979a4\n",
            "  Building wheel for keras-position-wise-feed-forward (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-position-wise-feed-forward: filename=keras_position_wise_feed_forward-0.8.0-py3-none-any.whl size=4969 sha256=c382bb19d8de7a454dd519e2f1f42d3cce87ac8aaba068f721f6e7314b588e79\n",
            "  Stored in directory: /root/.cache/pip/wheels/c1/6a/04/d1706a53b23b2cb5f9a0a76269bf87925daa1bca09eac01b21\n",
            "  Building wheel for keras-self-attention (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-self-attention: filename=keras_self_attention-0.51.0-py3-none-any.whl size=18894 sha256=8bf157278457fc83edae0e398853c43cae46b3b71517f4f44b621b82483732d0\n",
            "  Stored in directory: /root/.cache/pip/wheels/b8/f7/24/607b483144fb9c47b4ba2c5fba6b68e54aeee2d5bf6c05302e\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993227 sha256=0569d741df2ad6ac3db3d525bb0eee1b457520ea52955742e8cf2c03be09f410\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/03/7d/59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\n",
            "  Building wheel for tika (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tika: filename=tika-2.6.0-py3-none-any.whl size=32621 sha256=8555216cbdb93347e3ea07f1fdd38bf4be9a5c0612e9950df0b79c026915916d\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/71/c7/b757709531121b1700cffda5b6b0d4aad095fb507ec84316d0\n",
            "Successfully built ktrain keras_bert keras-transformer keras-embed-sim keras-layer-normalization keras-multi-head keras-pos-embd keras-position-wise-feed-forward keras-self-attention langdetect tika\n",
            "Installing collected packages: whoosh, syntok, langdetect, keras-self-attention, keras-position-wise-feed-forward, keras-pos-embd, keras-layer-normalization, keras-embed-sim, tika, keras-multi-head, keras-transformer, keras_bert, ktrain\n",
            "Successfully installed keras-embed-sim-0.10.0 keras-layer-normalization-0.16.0 keras-multi-head-0.29.0 keras-pos-embd-0.13.0 keras-position-wise-feed-forward-0.8.0 keras-self-attention-0.51.0 keras-transformer-0.40.0 keras_bert-0.89.0 ktrain-0.41.3 langdetect-1.0.9 syntok-1.4.4 tika-2.6.0 whoosh-2.7.4\n",
            "Collecting https://github.com/amaiya/eli5-tf/archive/refs/heads/master.zip\n",
            "  Downloading https://github.com/amaiya/eli5-tf/archive/refs/heads/master.zip\n",
            "\u001b[2K     \u001b[32m\\\u001b[0m \u001b[32m6.9 MB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: attrs>17.1.0 in /usr/local/lib/python3.10/dist-packages (from eli5==0.13.0) (23.2.0)\n",
            "Requirement already satisfied: jinja2>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from eli5==0.13.0) (3.1.4)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from eli5==0.13.0) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from eli5==0.13.0) (1.11.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from eli5==0.13.0) (1.16.0)\n",
            "Requirement already satisfied: scikit-learn>=0.20 in /usr/local/lib/python3.10/dist-packages (from eli5==0.13.0) (1.2.2)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from eli5==0.13.0) (0.20.3)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from eli5==0.13.0) (0.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=3.0.0->eli5==0.13.0) (2.1.5)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20->eli5==0.13.0) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20->eli5==0.13.0) (3.5.0)\n",
            "Building wheels for collected packages: eli5\n",
            "  Building wheel for eli5 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for eli5: filename=eli5-0.13.0-py2.py3-none-any.whl size=108158 sha256=8d1e1d6c029ab11c5c4dc7e90c6421ee331bb4954c63b292087e0663b0db2208\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-1izhwhbs/wheels/0b/14/54/23c07f7254b733dc3daac99ba1fda60e30f1b2991b3b8ee0bf\n",
            "Successfully built eli5\n",
            "Installing collected packages: eli5\n",
            "Successfully installed eli5-0.13.0\n",
            "Collecting openai\n",
            "  Downloading openai-1.28.1-py3-none-any.whl (320 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.1/320.1 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.2)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.28.1\n",
            "Collecting textstat\n",
            "  Downloading textstat-0.7.3-py3-none-any.whl (105 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.1/105.1 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyphen (from textstat)\n",
            "  Downloading pyphen-0.15.0-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyphen, textstat\n",
            "Successfully installed pyphen-0.15.0 textstat-0.7.3\n"
          ]
        }
      ],
      "source": [
        "# For Supervised classifier\n",
        "!pip install ktrain\n",
        "# For revealing under the classifier black box\n",
        "!pip install https://github.com/amaiya/eli5-tf/archive/refs/heads/master.zip\n",
        "# For Few-shot classifier\n",
        "!pip install openai\n",
        "# For summary statistics\n",
        "!pip install textstat"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# General use packages\n",
        "import requests, zipfile, io, os, psutil, random, time\n",
        "import torch\n",
        "import pandas as pd\n",
        "# This deactivates a warning from Pandas that frequently prints\n",
        "pd.options.mode.chained_assignment = None  # default='warn'\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "from tqdm import tqdm\n",
        "# For descriptive statistics\n",
        "from textstat.textstat import textstatistics\n",
        "import re\n",
        "# Performance evaluations for binary classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_recall_curve,roc_auc_score,classification_report,auc,confusion_matrix\n",
        "# for rule-based classification\n",
        "import spacy\n",
        "from spacy.matcher import Matcher\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "# for supervised classification\n",
        "import ktrain\n",
        "from ktrain import text\n",
        "# for few-shot classification\n",
        "import openai\n",
        "\n",
        "#for troubleshooting\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from wordcloud import WordCloud\n",
        "from nltk import agreement\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "# Plotting\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams['figure.dpi'] = 120\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KJGGvaNX8hPy",
        "outputId": "65aa0c83-069b-4805-b7ee-7431a89db4ea"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check system GPU (recommended if possible)\n",
        "# CPU cores\n",
        "num_cpu_cores = os.cpu_count()\n",
        "print(f\"Number of CPU cores: {num_cpu_cores}\")\n",
        "# GPU details\n",
        "if torch.cuda.is_available():\n",
        "    gpu_name = torch.cuda.get_device_name(0)\n",
        "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / (1024 ** 3)  # in GB\n",
        "    print(f\"GPU Name: {gpu_name}\")\n",
        "    print(f\"GPU Memory: {gpu_memory:.2f} GB\")\n",
        "else:\n",
        "    print(\"No GPU available.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mT0gjhlD8lsl",
        "outputId": "5384866b-4b87-406a-84cc-8745311c450d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of CPU cores: 2\n",
            "GPU Name: Tesla T4\n",
            "GPU Memory: 14.75 GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load in openai keys for producing topic model names\n",
        "oai_k = \"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\"\n",
        "openai.organization = \"org-7Q7DY9cZcPr6mbXa67jDCNbS\"\n",
        "openai.api_key = oai_k\n",
        "os.environ['OPENAI_API_KEY'] = oai_k"
      ],
      "metadata": {
        "id": "ifDAz7zT9Co3"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0.2 Download data and pre-trained BERT model\n"
      ],
      "metadata": {
        "id": "9NbRD_KokEAA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download data from GitHub"
      ],
      "metadata": {
        "id": "fUH0ETcp-P6p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download empirical data\n",
        "r = requests.get( 'https://github.com/alexiamhe93/RAMP_method/blob/main/Dataset/data.zip?raw=true')\n",
        "z = zipfile.ZipFile(io.BytesIO(r.content))\n",
        "z.extractall()\n",
        "\n",
        "# Load train (70%) and test (30%)\n",
        "try:\n",
        "  train = pd.read_csv(\"data/Train.csv\")\n",
        "  validation = pd.read_csv(\"data/Validation.csv\")\n",
        "  St1Through = pd.read_csv(\"data/RAMP_Stage1.csv\")\n",
        "  St2Through = pd.read_csv(\"data/RAMP_Stage2.csv\")\n",
        "  out = pd.read_csv(\"data/RAMP_Stage3.csv\")\n",
        "except:\n",
        "  train = pd.read_csv(\"Train.csv\")\n",
        "  validation = pd.read_csv(\"Validation.csv\")\n",
        "  St1Through = pd.read_csv(\"RAMP_Stage1.csv\")\n",
        "  St2Through = pd.read_csv(\"RAMP_Stage2.csv\")\n",
        "  out = pd.read_csv(\"RAMP_Stage3.csv\")"
      ],
      "metadata": {
        "id": "nTn-uqu8kIS4"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Validation n before cleaning: {len(validation)} texts\")\n",
        "# Delete any duplicates\n",
        "validation = validation.dropna(subset=[\"text\"])\n",
        "validation = validation.drop_duplicates(subset=\"text\")\n",
        "print(f\"Validation n after cleaning: {len(validation)} texts\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--VnA5j2IhmM",
        "outputId": "cfeed4ee-fb1f-43b3-cd96-be5217af1773"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation n before cleaning: 6599 texts\n",
            "Validation n after cleaning: 6420 texts\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We removed 179 sentences that are duplicates or empty values."
      ],
      "metadata": {
        "id": "wWk0GcaOJP7I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download model from Dropbox (can take some time if internet is slow - aprox 1.1GB - downloads weights and pre-processing)"
      ],
      "metadata": {
        "id": "3GFOZlP3-Eg-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O supervised_model.zip https://www.dropbox.com/scl/fi/5wtuor1ag1gktg6eukqwr/supervised_model.zip?rlkey=nfwxyataobjzt708m3gf27o3s&st=cz5r9lq0&dl=0 --quiet\n",
        "!unzip supervised_model.zip"
      ],
      "metadata": {
        "id": "i6URMHD9-GOY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b167d70-10f6-49dc-a447-f81b6db7e962"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: --quiet: command not found\n",
            "--2024-05-12 14:12:35--  https://www.dropbox.com/scl/fi/5wtuor1ag1gktg6eukqwr/supervised_model.zip?rlkey=nfwxyataobjzt708m3gf27o3s\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.5.18, 2620:100:601f:18::a27d:912\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.5.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://ucb21676431fc8ebacedeba3e662.dl.dropboxusercontent.com/cd/0/inline/CSy1bQB9Pl1DpDxdvkKLK9eX1wNIoy-sC2gyTiyuc7yfBIG0euTyJXpi7q7vRfOX14DDzDPIoGSc5tOWsxkN0eKmFLRFnNxb641SAtuBbtG3DxEd6NsKQWYjOlXIEkE5pBR1wHsGTypsOP41-qDLOw-e/file# [following]\n",
            "--2024-05-12 14:12:36--  https://ucb21676431fc8ebacedeba3e662.dl.dropboxusercontent.com/cd/0/inline/CSy1bQB9Pl1DpDxdvkKLK9eX1wNIoy-sC2gyTiyuc7yfBIG0euTyJXpi7q7vRfOX14DDzDPIoGSc5tOWsxkN0eKmFLRFnNxb641SAtuBbtG3DxEd6NsKQWYjOlXIEkE5pBR1wHsGTypsOP41-qDLOw-e/file\n",
            "Resolving ucb21676431fc8ebacedeba3e662.dl.dropboxusercontent.com (ucb21676431fc8ebacedeba3e662.dl.dropboxusercontent.com)... 162.125.80.15, 2620:100:601f:15::a27d:90f\n",
            "Connecting to ucb21676431fc8ebacedeba3e662.dl.dropboxusercontent.com (ucb21676431fc8ebacedeba3e662.dl.dropboxusercontent.com)|162.125.80.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /cd/0/inline2/CSxXUbIBhaAvc7HoOjj5YJ4gr1Es2oplt5DY7Iow2SOoIhJa9jKn26hE9wsz70NYs4rosEaw16Y3EhfvOYj6a7Q5Y4Q0rGKMRzAfV-VbyMpAg-iBN--2wMZqsUBmqP4RrrAx1gFKEgIsXaHX5VpfaNu9Vat4mOc-MrGGisRHdmGUe_qUarYdFz4gNycXu2OIRavfXcgYbr6ulvtmno_i2BGe2kQFX7WUPs0Q5VV-DulEJk8DaPuQ_LDdkDpa6792U7WRdnlCLeh48oDgKgxeUQL8aay1M-tnRmxOJx9r_rMDy3OUAB0pGrMUjuO9pCr98q4LAyu7WBz2fJgpWD2zzADGQEelhI1ZyjcNyyMMHT38wpdhnP0UFTlVKGIDv4XScwI/file [following]\n",
            "--2024-05-12 14:12:37--  https://ucb21676431fc8ebacedeba3e662.dl.dropboxusercontent.com/cd/0/inline2/CSxXUbIBhaAvc7HoOjj5YJ4gr1Es2oplt5DY7Iow2SOoIhJa9jKn26hE9wsz70NYs4rosEaw16Y3EhfvOYj6a7Q5Y4Q0rGKMRzAfV-VbyMpAg-iBN--2wMZqsUBmqP4RrrAx1gFKEgIsXaHX5VpfaNu9Vat4mOc-MrGGisRHdmGUe_qUarYdFz4gNycXu2OIRavfXcgYbr6ulvtmno_i2BGe2kQFX7WUPs0Q5VV-DulEJk8DaPuQ_LDdkDpa6792U7WRdnlCLeh48oDgKgxeUQL8aay1M-tnRmxOJx9r_rMDy3OUAB0pGrMUjuO9pCr98q4LAyu7WBz2fJgpWD2zzADGQEelhI1ZyjcNyyMMHT38wpdhnP0UFTlVKGIDv4XScwI/file\n",
            "Reusing existing connection to ucb21676431fc8ebacedeba3e662.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1107245706 (1.0G) [application/zip]\n",
            "Saving to: ‘supervised_model.zip’\n",
            "\n",
            "supervised_model.zi 100%[===================>]   1.03G  17.2MB/s    in 64s     \n",
            "\n",
            "2024-05-12 14:13:42 (16.4 MB/s) - ‘supervised_model.zip’ saved [1107245706/1107245706]\n",
            "\n",
            "Archive:  supervised_model.zip\n",
            "   creating: supervised_model/\n",
            "  inflating: __MACOSX/._supervised_model  \n",
            "  inflating: supervised_model/tf_model.preproc  \n",
            "  inflating: __MACOSX/supervised_model/._tf_model.preproc  \n",
            "  inflating: supervised_model/tf_model.h5  \n",
            "  inflating: __MACOSX/supervised_model/._tf_model.h5  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0.3 Load functions"
      ],
      "metadata": {
        "id": "BHYCi1z_kFl3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Classifier object and functions\n",
        "\n",
        "This class does the heavy lifting for the notebook. It integrates the three types of classifier (rule-based, supervised, few-shot) into one function so that there is a common language across the examples.\n",
        "\n",
        "The classifier produces a development report, including the following variables:\n",
        "\n",
        "1. `TP`,`TN`,`FP`,`FN`: number of true positives, true negatives, false positives, and false negatives\n",
        "2. `Precision`: TP/TP+FP - ratio of true positives to all predicted positive class. Reported for positive class only.\n",
        "3. `Recall`: TP/TP+FN – ratio of true positives to all true positive class.Reported for positive class only.\n",
        "4. `F1_avg`: Weighted harmonic mean of precision and recall (all classes - this F1 is not the precision and recall reported).\n",
        "5. `F1_var`: Weighted harmonic mean of precision and recall for positive class.\n",
        "6. `AUC_ROC`: Area under the receiving operating characteristic (ROC) curve\n",
        "7. `AUC_PR`: Area under the precision and recall curve.\n",
        "\n",
        "Each metric highlights a different aspect of the classifier's performance. For instance, the weighted F1 (`F1_avg`) is sensitive to imbalanced classes. For misunderstandings, the class is imbalanced (8% of turns are misunderstandings) so the area under the precision recall curve (`AUC_PR`) is more appropriate."
      ],
      "metadata": {
        "id": "Os-aIAYQDBZq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Classifier:\n",
        "  def __init__(self, texts, true_scores):\n",
        "    \"\"\"\n",
        "    Initialize the Classifier class with texts and true scores.\n",
        "    \"\"\"\n",
        "    self.texts = texts\n",
        "    self.true_scores = true_scores\n",
        "    self.train_size = len(texts)\n",
        "    self.type_ = None\n",
        "    self.pred_scores = []\n",
        "    self.nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "  def add_rule_based_terms(self, terms, pattern_type):\n",
        "    \"\"\"\n",
        "    Configure terms and pattern matching type for rule-based classifiers.\n",
        "    \"\"\"\n",
        "    self.terms = terms\n",
        "    if pattern_type == \"pattern\":\n",
        "        self.type_ = \"rule-based-1\"\n",
        "    elif pattern_type == \"lemma\":\n",
        "        self.type_ = \"rule-based-2\"\n",
        "    else:\n",
        "        raise ValueError(\"Invalid pattern type specified.\")\n",
        "  def classify_with_spacy_pattern(self):\n",
        "    \"\"\"\n",
        "    Classify texts using SpaCy's pattern matcher based on predefined terms.\n",
        "    \"\"\"\n",
        "    matcher = Matcher(self.nlp.vocab)\n",
        "    for term in self.terms:\n",
        "        matcher.add(term[\"label\"], [term[\"pattern\"]])\n",
        "    self.pred_scores = [bool(matcher(self.nlp(text))) for text in self.texts]\n",
        "  def classify_with_spacy_lemma(self):\n",
        "    \"\"\"\n",
        "    Classify texts by checking if any lemmas from the terms are in the texts.\n",
        "    \"\"\"\n",
        "    lemma_doc = self.nlp(\" \".join(self.terms))\n",
        "    lemma_set = set(token.lemma_ for token in lemma_doc)\n",
        "    self.pred_scores = [bool(set(token.lemma_ for token in self.nlp(text.lower())) & lemma_set) for text in self.texts]\n",
        "  def add_SML_classifier(self, predictor, **kwargs):\n",
        "    \"\"\"\n",
        "    Configure the supervised machine learning classifier with a predictor and training parameters.\n",
        "    \"\"\"\n",
        "    self.type_ = \"supervised\"\n",
        "    self.predictor = predictor\n",
        "    self.sml_params = kwargs\n",
        "    print(\"Supervised ML classifier configured with parameters:\", kwargs)\n",
        "  def classify_with_SML(self):\n",
        "    \"\"\"\n",
        "    Perform classification using the configured supervised machine learning predictor.\n",
        "    \"\"\"\n",
        "    preds = self.predictor.predict(self.texts)\n",
        "    self.pred_scores = [0 if \"not\" in pred.lower() else 1 for pred in preds]\n",
        "\n",
        "  def add_few_shot_classifier(self, GPTmodel, prompt, role):\n",
        "    \"\"\"\n",
        "    Configure the few-shot classifier with a GPT model, prompt template, and user/system roles.\n",
        "    \"\"\"\n",
        "    self.type_ = \"few-shot\"\n",
        "    self.GPTmodel = GPTmodel\n",
        "    self.prompt = prompt\n",
        "    self.role = role\n",
        "    self.cost = 0\n",
        "    self.total_tokens = 0\n",
        "    self.LLMScores = []\n",
        "\n",
        "  def gptActualCost(self, response):\n",
        "    \"\"\"\n",
        "    Calculates the GPT cost for different models\n",
        "    \"\"\"\n",
        "    engine = self.GPTmodel\n",
        "    total_tokens=response.usage.total_tokens\n",
        "    total_tokens_1k_units = total_tokens/1000\n",
        "\n",
        "    if engine=='gpt-3.5-turbo':\n",
        "        cost=total_tokens_1k_units*0.0005\n",
        "    elif engine=='gpt-4-turbo':\n",
        "        cost=total_tokens_1k_units*0.01\n",
        "    elif engine=='gpt-4-32k':\n",
        "        cost=total_tokens_1k_units*0.12\n",
        "    else:\n",
        "        print('getCost error: engine not found')\n",
        "        return\n",
        "    return cost, total_tokens\n",
        "\n",
        "  def get_llm_response(self,messages,temperature=0, max_tokens = 100, max_attempts = 3):\n",
        "    '''\n",
        "    Function that takes messages format for ChatGPT input and returns the response text.\n",
        "    '''\n",
        "    GPTmodel = self.GPTmodel\n",
        "    for attempt in range(0, max_attempts):\n",
        "      try:\n",
        "        #. request timeout ADD IN\n",
        "        response = openai.chat.completions.create(model=GPTmodel, messages = messages, temperature=temperature, max_tokens=max_tokens)\n",
        "        response_text = response.choices[0].message.content\n",
        "        self.LLMScores.append(response_text)\n",
        "        response_cost, token_count = self.gptActualCost(response)\n",
        "        self.cost += response_cost\n",
        "        self.total_tokens += token_count\n",
        "        break  # If analysis was successful, break out of the retry loop\n",
        "      except Exception as e:\n",
        "        print(f\"Error processing text on attempt {attempt+1}: {e}\")\n",
        "        if attempt + 1 == max_attempts:\n",
        "          print(f\"Skipping text after {max_attempts} failed attempts.\")\n",
        "          response_text\n",
        "    return response_text\n",
        "  def define_messages(self, text_to_classify):\n",
        "    '''\n",
        "    Function for creating a basic messages format from a prompt, a role, and a text to classify (all strings)\n",
        "    '''\n",
        "    prompt = self.prompt\n",
        "    role = self.role\n",
        "    prompt = prompt.format(text_to_classify)\n",
        "    messages = [{'role': 'system', 'content': role},\n",
        "                {'role': 'user', 'content' : prompt}]\n",
        "    return messages\n",
        "  def convert_llm_scores_binary(self, return_scores = False):\n",
        "    '''\n",
        "    Function for converting a string \"Yes\" or \"No\" into binary format - used for the clarification requests\n",
        "    '''\n",
        "    llm_scores = self.pred_scores\n",
        "    new_scores = []\n",
        "    for s in llm_scores:\n",
        "      if \"yes\" in s.lower():\n",
        "        new_scores.append(1)\n",
        "      else:\n",
        "        new_scores.append(0)\n",
        "    if not return_scores:\n",
        "      self.pred_scores = new_scores\n",
        "    else:\n",
        "      return new_scores\n",
        "\n",
        "  def classify_with_fewshot(self,  max_tokens = 100, max_attempts = 3, temperature = 0):\n",
        "    '''\n",
        "    Function for running a prompt over a series of texts (expects a list)\n",
        "    '''\n",
        "    prompt = self.prompt\n",
        "    role = self.role\n",
        "    input_texts = self.texts\n",
        "    GPTmodel = self.GPTmodel\n",
        "    scores = []\n",
        "    for txt in tqdm(input_texts):\n",
        "      message = self.define_messages(txt)\n",
        "      try:\n",
        "        response = self.get_llm_response(message,temperature=temperature,\n",
        "                                        max_tokens=max_tokens, max_attempts=max_attempts)\n",
        "      except:\n",
        "        response = \"Error in response\"\n",
        "      scores.append(response)\n",
        "    self.pred_scores = scores\n",
        "    self.convert_llm_scores_binary()\n",
        "\n",
        "  def run_classifier(self):\n",
        "    \"\"\"\n",
        "    Execute the classifier based on the configured type.\n",
        "    \"\"\"\n",
        "    if self.type_ == \"rule-based-1\":\n",
        "        self.classify_with_spacy_pattern()\n",
        "    elif self.type_ == \"rule-based-2\":\n",
        "        self.classify_with_spacy_lemma()\n",
        "    elif self.type_ == \"supervised\":\n",
        "        self.classify_with_SML()\n",
        "    elif self.type_ == \"few-shot\":\n",
        "        self.classify_with_fewshot()\n",
        "        cost = self.cost\n",
        "        total_tokens = self.total_tokens\n",
        "        avg_tokens = self.total_tokens / self.train_size\n",
        "        print(f\"This run cost {cost:.2f}$ for {total_tokens} tokens. Average tokens: {avg_tokens:.2f}\")\n",
        "    else:\n",
        "        raise ValueError(\"Classifier type is not configured.\")\n",
        "\n",
        "  def get_model_report(self, display=True):\n",
        "    \"\"\"\n",
        "    Generate and display or return the classification report and metrics.\n",
        "    \"\"\"\n",
        "    cm = confusion_matrix(self.true_scores, self.pred_scores)\n",
        "    report = classification_report(self.true_scores, self.pred_scores, output_dict=True)\n",
        "    precision, recall, thresholds = precision_recall_curve(self.true_scores, self.pred_scores)\n",
        "    auc_pr = auc(recall, precision)\n",
        "    auc_roc = roc_auc_score(self.true_scores, self.pred_scores)\n",
        "\n",
        "    if display:\n",
        "        print(f'AUC-PR: {auc_pr:.2f}\\n')\n",
        "        print(f'AUC-ROC: {auc_roc:.2f}\\n')\n",
        "        print(classification_report(self.true_scores, self.pred_scores, output_dict=False))\n",
        "    else:\n",
        "        return {\n",
        "            \"precision\": report['1']['precision'],\n",
        "            \"recall\": report['1']['recall'],\n",
        "            \"auc_pr\": auc_pr,\n",
        "            \"auc_roc\": auc_roc,\n",
        "            \"f1_avg\": report['weighted avg']['f1-score'],\n",
        "            \"f1_var\": report['1']['f1-score']\n",
        "        }\n",
        "  def get_misclassification(self, return_all = False):\n",
        "    \"\"\"\n",
        "    Function to fetch misclassifications\n",
        "    \"\"\"\n",
        "    df = pd.DataFrame({\"text\":self.texts,\"true\":self.true_scores,\n",
        "                       \"pred\":self.pred_scores})\n",
        "    # Function to classify each row\n",
        "    def classify_row(row):\n",
        "      if row['true'] == 1 and row['pred'] == 1:\n",
        "        return 'TP'\n",
        "      elif row['true'] == 0 and row['pred'] == 1:\n",
        "        return 'FP'\n",
        "      elif row['true'] == 1 and row['pred'] == 0:\n",
        "        return 'FN'\n",
        "      elif row['true'] == 0 and row['pred'] == 0:\n",
        "        return 'TN'\n",
        "    df['Classification'] = df.apply(classify_row, axis=1)\n",
        "    if return_all:\n",
        "      return df\n",
        "    else:\n",
        "      return df[df[\"Classification\"].isin([\"FP\",\"FN\"])]\n",
        "\n",
        "  def preprocess_text(self, text):\n",
        "    \"\"\"\n",
        "    Function to process the texts.\n",
        "    \"\"\"\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    words = nltk.word_tokenize(text)\n",
        "    cleaned_text = [lemmatizer.lemmatize(word.lower()) for word in words if word.isalnum() and word.lower() not in stop_words]\n",
        "    return ' '.join(cleaned_text)\n",
        "\n",
        "  def plot_misclassifications(self, df, FN_FP=\"FN\"):\n",
        "    \"\"\"\n",
        "    Function to generate a wordcloud\n",
        "    \"\"\"\n",
        "    df['cleaned_text'] = df['text'].apply(self.preprocess_text)\n",
        "    if FN_FP == \"FN\":\n",
        "      print(\"Word Cloud for False Negatives:\")\n",
        "      texts = \" \".join(df[df['Classification'] == 'FN']['cleaned_text'])\n",
        "    else:\n",
        "      print(\"Word Cloud for False Positives:\")\n",
        "      texts = \" \".join(df[df['Classification'] == 'FP']['cleaned_text'])\n",
        "    wordcloud = WordCloud(width = 800, height = 400, background_color ='white').generate(texts)\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.imshow(wordcloud, interpolation='bilinear')\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "7_s_-YmtkItR"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Plotting and summary object\n",
        "\n",
        "This class is used throughout to do various plotting and statistical functions."
      ],
      "metadata": {
        "id": "5Y5mJpC0JtQZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TextDataStats:\n",
        "  def __init__(self, df, text_column=\"text\", binary_column=\"Misunderstanding\",\n",
        "               IRR_columns = [\"Coder1\",\"Coder2\",\"Coder3\",\"Coder4\"],\n",
        "               group_column = \"Round\"):\n",
        "    self.df = df\n",
        "    self.text_column = text_column\n",
        "    self.binary_column = binary_column\n",
        "    self.IRR_columns = IRR_columns\n",
        "    self.group_column = group_column\n",
        "\n",
        "  def preprocess_text(self):\n",
        "    \"\"\"\n",
        "    Extracts words and sentences from the text, counts them and adds to the dataframe.\n",
        "    \"\"\"\n",
        "    self.df['words'] = self.df[self.text_column].apply(lambda x: re.findall(r'\\b\\w+\\b', x.lower()))\n",
        "    self.df['word_count'] = self.df['words'].apply(len)\n",
        "\n",
        "  def basic_stats(self):\n",
        "    \"\"\"\n",
        "    Computes basic statistics for overall and grouped data.\n",
        "    \"\"\"\n",
        "    self.preprocess_text()\n",
        "\n",
        "    # General stats\n",
        "    general_stats = self.df.describe(include=[np.number]).loc[['mean', 'std', 'min', '50%', 'max'], ['word_count']]\n",
        "    general_stats.rename(index={'50%': 'median'}, inplace=True)\n",
        "    # Grouped stats by binary column\n",
        "    grouped_stats = self.df.groupby(self.binary_column).agg({\n",
        "        'word_count': ['mean', 'median', 'std', 'min', 'max'],\n",
        "    })\n",
        "    # Binary column distribution\n",
        "    binary_dist = self.df[self.binary_column].value_counts(normalize=True).to_frame('distribution')\n",
        "    return general_stats.round(2), grouped_stats.round(2), binary_dist.round(2)\n",
        "\n",
        "  def BasicReport(self):\n",
        "    \"\"\"\n",
        "    Generates a report combining all statistics in a readable text format.\n",
        "    \"\"\"\n",
        "    general_stats, grouped_stats, binary_dist = self.basic_stats()\n",
        "\n",
        "    # Creating a structured text report\n",
        "    report = \"Text Data Statistics Report\\n\\n\"\n",
        "    report += \"General Statistics:\\n\"\n",
        "    report += general_stats.to_string() + \"\\n\\n\"\n",
        "\n",
        "    report += \"Statistics by Binary Column:\\n\"\n",
        "    for name, group in self.df.groupby(self.binary_column):\n",
        "        report += f\"\\nGroup: {name}\\n\"\n",
        "        report += grouped_stats.loc[name].to_string() + \"\\n\"\n",
        "    return report\n",
        "\n",
        "  def get_IRR(self,df):\n",
        "    \"\"\"\n",
        "    Calculates Krippendorff's Alpha and overall agreement\n",
        "    \"\"\"\n",
        "    df = df[self.IRR_columns]\n",
        "    df = df.astype(int)\n",
        "    IRR_out = []\n",
        "    for i, row in df.iterrows():\n",
        "      for k in list(df.columns):\n",
        "        IRR_out.append([k, str(i), row[k]])\n",
        "    ratingtask = agreement.AnnotationTask(data=IRR_out)\n",
        "    ags = ratingtask.avg_Ao()\n",
        "    krip_alpha = ratingtask.alpha()\n",
        "    return ags, krip_alpha\n",
        "\n",
        "  def IRRreport(self):\n",
        "    \"\"\"\n",
        "    Prints Krippendorff's Alpha and the overall agreement for each round of coding\n",
        "    \"\"\"\n",
        "    df = self.df.sort_values([self.group_column])\n",
        "    rounds = df[self.group_column].unique()\n",
        "    agr = []\n",
        "    alp = []\n",
        "    ss = []\n",
        "    for i in rounds:\n",
        "      tdf = df[df[self.group_column] == i]\n",
        "      ss.append(len(tdf))\n",
        "      agr_,alp_ = self.get_IRR(tdf)\n",
        "      agr.append(agr_)\n",
        "      alp.append(alp_)\n",
        "    return pd.DataFrame({\"Round\":[\"Round\" + str(i) for i in rounds],\n",
        "                         \"Sample size\":ss,\n",
        "                         \"Agreement\":agr,\"Krippendorff's Alpha\":alp})\n",
        "\n",
        "  def get_disagreements(self,n=10, return_df = False):\n",
        "    \"\"\"\n",
        "    Prints n disagreements for the IRR results\n",
        "    \"\"\"\n",
        "    df = self.df\n",
        "    disag = []\n",
        "    for i, row in df.iterrows():\n",
        "      x = 0\n",
        "      for coder in self.IRR_columns:\n",
        "        x += row[coder]\n",
        "      disag.append(x)\n",
        "    df[\"disag\"] = disag\n",
        "    ncoders = len(self.IRR_columns)\n",
        "    df = df[df[\"disag\"] < ncoders]\n",
        "    df = df[df[\"disag\"] > 0]\n",
        "    if return_df:\n",
        "      return df.round(2)\n",
        "    else:\n",
        "      sdf = df.sample(n)\n",
        "      for s in sdf.text:\n",
        "        print(\"----------\")\n",
        "        print(s)\n",
        "\n",
        "  def get_misclassifications(self, n=5,return_all = False):\n",
        "    \"\"\"\n",
        "    Functiin to report on the misclassifications across all three classifiers\n",
        "    \"\"\"\n",
        "    df = self.df\n",
        "    FN_FP = []\n",
        "    for i,row in df.iterrows():\n",
        "      base = int(row[\"Manual\"])\n",
        "      fs = int(row[\"few-shot\"])\n",
        "      sup = int(row[\"supervised\"])\n",
        "      if sup == base:\n",
        "        if fs == base:\n",
        "          if base == 1:\n",
        "            FN_FP.append(\"TP (All)\")\n",
        "          else:\n",
        "            FN_FP.append(\"TN (All)\")\n",
        "        else:\n",
        "          if base == 1:\n",
        "            FN_FP.append(\"FN (few-shot)\")\n",
        "          else:\n",
        "            FN_FP.append(\"FP (few-shot)\")\n",
        "      else:\n",
        "        if fs == base:\n",
        "          if base == 1:\n",
        "            FN_FP.append(\"FN (supervised)\")\n",
        "          else:\n",
        "            FN_FP.append(\"FP (supervised)\")\n",
        "        else:\n",
        "          if base == 1:\n",
        "            FN_FP.append(\"FP (ALL\")\n",
        "          else:\n",
        "            FN_FP.append(\"FN (All)\")\n",
        "    df[\"FN_FP\"] = FN_FP\n",
        "    if return_all:\n",
        "      return df\n",
        "    FP_all = df[df.FN_FP == \"FP (All)\"].text.to_list()\n",
        "    FP_sup = df[df.FN_FP == \"FP (supervised)\"].text.to_list()\n",
        "    FP_fs = df[df.FN_FP == \"FP (few-shot)\"].text.to_list()\n",
        "\n",
        "    FN_all = df[df.FN_FP == \"FN (All)\"].text.to_list()\n",
        "    FN_sup = df[df.FN_FP == \"FN (supervised)\"].text.to_list()\n",
        "    FN_fs = df[df.FN_FP == \"FN (few-shot)\"].text.to_list()\n",
        "    print(f\"--- False positives count: --\")\n",
        "    print(f\"Both = {len(FP_all)}, Supervised = {len(FP_sup)}, Few-shot = {len(FP_fs)}\")\n",
        "    print(\"\\n--- False negatives count: --\")\n",
        "    print(f\"Both = {len(FN_all)}, Supervised = {len(FN_sup)}, Few-shot = {len(FN_fs)}\")\n",
        "    print(f\"\\nPrinting {n} examples of each classifier type.\\n\")\n",
        "    print(\"------ FALSE POSITIVES ------\")\n",
        "    print(\"# Few-shot & supervised false positives\")\n",
        "    for i in FP_all[0:n]:\n",
        "      print(\"- \" + i)\n",
        "    print(\"--------\")\n",
        "    print(\"# Supervised false positives\")\n",
        "    for i in FP_sup[0:n]:\n",
        "      print(\"- \" + i)\n",
        "    print(\"--------\")\n",
        "    print(\"# Few-shot false positives\")\n",
        "    for i in FP_fs[0:n]:\n",
        "      print(\"- \" + i)\n",
        "    print(\"--------\")\n",
        "    print(\"------ FALSE NEGATIVES ------\")\n",
        "    print(\"# Few-shot & supervised false negatives\")\n",
        "    for i in FN_all[0:n]:\n",
        "      print(\"- \" + i)\n",
        "    print(\"--------\")\n",
        "    print(\"# Supervised false negatives\")\n",
        "    for i in FN_sup[0:n]:\n",
        "      print(\"- \" + i)\n",
        "    print(\"--------\")\n",
        "    print(\"# Few-shot false negatives\")\n",
        "    for i in FN_fs[0:n]:\n",
        "      print(\"- \" + i)\n",
        "\n",
        "\n",
        "  def RAMP_plot(self, x_col, y_col, group_col,\n",
        "                pastel_colors = ['#77B5FE', '#FF6961', '#B19CD9'],\n",
        "                title=\"\", width=800, height=500, line_width=2, line_opacity=0.5):\n",
        "    \"\"\"\n",
        "    Creates a connected scatter plot\n",
        "    \"\"\"\n",
        "    # Ensure the group column is categorized\n",
        "    self.df[group_col] = self.df[group_col].astype('category')\n",
        "\n",
        "    # Create the connected scatter plot using Plotly Express with lines\n",
        "    scatter_fig = px.line(self.df, x=x_col, y=y_col, color=group_col,\n",
        "                          title=title, template='plotly_white',\n",
        "                          labels={x_col: x_col, y_col: y_col, group_col: group_col},\n",
        "                          markers=True,  # Include markers at data points\n",
        "                          color_discrete_sequence=pastel_colors)  # Apply the pastel color palette\n",
        "\n",
        "    # Iterate through each group to add dashed lines connecting min and max x values\n",
        "    for group, group_df in self.df.groupby(group_col):\n",
        "        # Get minimum and maximum x values and their corresponding y values\n",
        "        min_x = group_df[x_col].min()\n",
        "        max_x = group_df[x_col].max()\n",
        "        min_y = group_df[group_df[x_col] == min_x][y_col].iloc[0]\n",
        "        max_y = group_df[group_df[x_col] == max_x][y_col].iloc[0]\n",
        "\n",
        "        # Find the index of the group's color in the palette\n",
        "        color_index = group_df[group_col].cat.codes.unique()[0] % len(pastel_colors)\n",
        "\n",
        "        # Add a dashed line to the scatter plot\n",
        "        scatter_fig.add_trace(go.Scatter(\n",
        "            x=[min_x, max_x],\n",
        "            y=[min_y, max_y],\n",
        "            mode='lines',\n",
        "            name=f'{group} - Range Line',\n",
        "            line=dict(color=pastel_colors[color_index], width=line_width, dash='dash'),\n",
        "            opacity=line_opacity,\n",
        "            showlegend=False))  # Hide this line from the legend\n",
        "\n",
        "    # Update layout and display the figure\n",
        "    scatter_fig.update_layout(title=title, width=width, height=height)\n",
        "    scatter_fig.show()\n"
      ],
      "metadata": {
        "id": "aW0xRPcIKELa"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Stage 1: Manual coding"
      ],
      "metadata": {
        "id": "DMvNGUi-kJSW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1 Input (manual):"
      ],
      "metadata": {
        "id": "iK_gyvGUkLiG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data"
      ],
      "metadata": {
        "id": "e6Htv_uykRy-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "The raw dataset contains sentences from online dialogues, sampled from three sources:\n",
        "\n",
        "**Reddit conversations from 27 subreddits**.\n",
        "\n",
        "> This data was downloaded using the Reddit API by the authors.\n",
        "\n",
        "**Twitter Customer Support data** (Thought Vector & Axelbrooke, 2017).\n",
        "\n",
        "> This data was downloaded from: https://www.kaggle.com/datasets/thoughtvector/customer-support-on-twitter (Copyright: CC BY-NC-SA 4.0).\n",
        "\n",
        "**Wikipedia Talk Pages data**(Danescu-Niculescu-Mizil et al., 2012).\n",
        "\n",
        "> This data was downloaded using Cornell University's ConvoKit Python package (see: https://convokit.cornell.edu/documentation/wiki.html) (Copyright: CC BY 4.0)\n",
        "\n",
        "**Notes:**\n",
        "\n",
        "> All author names and sentences have been anonymized.\n",
        "> As a further precaution, the sentences are shuffled and the source (e.g., Reddit, Twitter) removed from the dataframe."
      ],
      "metadata": {
        "id": "RoxsE1Uc8HFn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Manual coded dataset final size\n",
        "print(f\"Full dataset size: {len(train) + len(validation)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wj9RKsx-YHDC",
        "outputId": "964ad4b1-67c4-4094-8b42-309a5309f9e7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Full dataset size: 21815\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the IRR from the final round (validation)\n",
        "IRR_final = St1Through[St1Through[\"Round\"]==6]\n",
        "IRR_through = St1Through[St1Through[\"Round\"]!=6]"
      ],
      "metadata": {
        "id": "5VoWDNwBRgQt"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2 Throughput (manual)"
      ],
      "metadata": {
        "id": "zX-a78DVkbbi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inter rater reliability across rour rounds of coder training:"
      ],
      "metadata": {
        "id": "0B23lDDzWzNk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tds = TextDataStats(IRR_through)\n",
        "tds.IRRreport().round(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "RCQOxLqEDsQr",
        "outputId": "e3a5f533-4cfe-4128-c736-549c30a896d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Round  Sample size  Agreement  Krippendorff's Alpha\n",
              "0  Round1          713       0.95                  0.57\n",
              "1  Round2         1228       0.97                  0.71\n",
              "2  Round3         1101       0.97                  0.72\n",
              "3  Round4          808       0.94                  0.78\n",
              "4  Round5          862       0.98                  0.76"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-18ebc3bc-4060-4506-b598-3ffd87d1ff3d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Round</th>\n",
              "      <th>Sample size</th>\n",
              "      <th>Agreement</th>\n",
              "      <th>Krippendorff's Alpha</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Round1</td>\n",
              "      <td>713</td>\n",
              "      <td>0.95</td>\n",
              "      <td>0.57</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Round2</td>\n",
              "      <td>1228</td>\n",
              "      <td>0.97</td>\n",
              "      <td>0.71</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Round3</td>\n",
              "      <td>1101</td>\n",
              "      <td>0.97</td>\n",
              "      <td>0.72</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Round4</td>\n",
              "      <td>808</td>\n",
              "      <td>0.94</td>\n",
              "      <td>0.78</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Round5</td>\n",
              "      <td>862</td>\n",
              "      <td>0.98</td>\n",
              "      <td>0.76</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-18ebc3bc-4060-4506-b598-3ffd87d1ff3d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-18ebc3bc-4060-4506-b598-3ffd87d1ff3d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-18ebc3bc-4060-4506-b598-3ffd87d1ff3d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-87afb19d-03aa-47a6-9e04-2c2a1ffc15cd\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-87afb19d-03aa-47a6-9e04-2c2a1ffc15cd')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-87afb19d-03aa-47a6-9e04-2c2a1ffc15cd button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"tds\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Round\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Round2\",\n          \"Round5\",\n          \"Round3\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sample size\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 214,\n        \"min\": 713,\n        \"max\": 1228,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1228,\n          862,\n          1101\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Agreement\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.016431676725154998,\n        \"min\": 0.94,\n        \"max\": 0.98,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.97,\n          0.98,\n          0.95\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Krippendorff's Alpha\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.08228000972289687,\n        \"min\": 0.57,\n        \"max\": 0.78,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.71,\n          0.76,\n          0.72\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that the Alpha gets progressively better. We ended the training and Round5 as the agreement diminishes from the previous round."
      ],
      "metadata": {
        "id": "iQJzLFKckjqe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.3 Output (Manual)"
      ],
      "metadata": {
        "id": "hY6VX1eAkmlv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tds = TextDataStats(IRR_final)\n",
        "tds.IRRreport().round(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "t8A04avekqPi",
        "outputId": "85779f2c-ef94-4f0a-8b75-9959350c2329"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Round  Sample size  Agreement  Krippendorff's Alpha\n",
              "0  Round6         1610       0.98                  0.79"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-98eaa41b-fa4d-4615-806b-fefc86ea569f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Round</th>\n",
              "      <th>Sample size</th>\n",
              "      <th>Agreement</th>\n",
              "      <th>Krippendorff's Alpha</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Round6</td>\n",
              "      <td>1610</td>\n",
              "      <td>0.98</td>\n",
              "      <td>0.79</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-98eaa41b-fa4d-4615-806b-fefc86ea569f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-98eaa41b-fa4d-4615-806b-fefc86ea569f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-98eaa41b-fa4d-4615-806b-fefc86ea569f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"tds\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"Round\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Round6\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sample size\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 1610,\n        \"max\": 1610,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1610\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Agreement\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.98,\n        \"max\": 0.98,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.98\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Krippendorff's Alpha\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.79,\n        \"max\": 0.79,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.79\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is very good agreement (98%) with decent reliability (Krippendorff's Alpha  = 0.79). The high agreement is down to misunderstandings being very uncommon (8%). This means they are overrepresented by a pure agreement score.\n",
        "\n",
        "We can also have a look at the disagreements for the final round of coding:"
      ],
      "metadata": {
        "id": "SPSjO8BpXDkU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tds.get_disagreements(n=25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1HL3-ZQXguV",
        "outputId": "c9c699d1-a98d-42c0-9c85-1bc78e5b00e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------\n",
            "It seems to me what I'm saying is plenty nuanced compared to the general discourse.\n",
            "----------\n",
            "Why go from zero to 100 today?\n",
            "----------\n",
            "@143020 We're not having a sale tomorrow, but our current sale ends tonight!\n",
            "----------\n",
            "Why are the section headings noincluded?\n",
            "----------\n",
            "Does your understanding differ?\n",
            "----------\n",
            "In Brooklyn?\n",
            "----------\n",
            "What do you know?\n",
            "----------\n",
            "I mean yeah but your only thinking of it as an asset and not as a charecter\n",
            "----------\n",
            "but we already complaint regarding same many time more than 01 year ago , you may check  this issue.\n",
            "----------\n",
            "The rest not so rightÔ£ø√º√≤√ë thanks for correcting me!\n",
            "----------\n",
            "The crux of there arguments seem to be that the game took to long to develop?\n",
            "----------\n",
            "@Ask_Spectrum I've gave your company enough of my patience ive had enough, you just lost a customer!.\n",
            "----------\n",
            "In terms of actual video production?\n",
            "----------\n",
            "@VirginTrains Cheers other seats showing as reserved so no idea why mine (and from what I can tell a couple of others') aren't.\n",
            "----------\n",
            "By precedent I mean even the loosest form of precedence, such as a distinct community in the region.\n",
            "----------\n",
            "@TMobileHelp @115913 I will DM you but I truly do not believe there's anything you will do.\n",
            "----------\n",
            "I just wanted you to get a chance to see this new information early on.\n",
            "----------\n",
            "Are you suggesting otherwise?\n",
            "----------\n",
            ">your saying be bought the assets yes and he legally owns them so I don't see anything wrong with that\n",
            "\n",
            "That was when he was buying assets and putting them on merch.\n",
            "----------\n",
            "Did that help in any way?\n",
            "----------\n",
            "Now it's clear to me.\n",
            "----------\n",
            "Also I wouldn't really call it lazy?\n",
            "----------\n",
            "Perhaps I'm misunderstanding this and this action is actually taking place \"outside\" the black hole in the mass that I assume we would see smeared around the cusp of the event horizon (matter that has been \"captured\" by the black hole after it's formation).\n",
            "----------\n",
            "Hello, I was unfamiliar with your case and am not sure why you have contacted me, but our article on the topic was a disgrace, and I have removed the bulk of its content.\n",
            "----------\n",
            "I mean is there proof for that third one?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Stage 2: Automated"
      ],
      "metadata": {
        "id": "fivY_6dpkrZ8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1 Input (automated)"
      ],
      "metadata": {
        "id": "oYZCmJ-lkv6g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Information on the validation data = binary column is misunderstandings.\n",
        "tds = TextDataStats(validation)\n",
        "print(tds.BasicReport())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1HJN3au5YIyH",
        "outputId": "f1f01c4b-6478-4715-f410-7f686cad9e33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text Data Statistics Report\n",
            "\n",
            "General Statistics:\n",
            "        word_count\n",
            "mean         14.97\n",
            "std          11.71\n",
            "min           0.00\n",
            "median       12.00\n",
            "max         203.00\n",
            "\n",
            "Statistics by Binary Column:\n",
            "\n",
            "Group: 0\n",
            "word_count  mean       14.90\n",
            "            median     12.00\n",
            "            std        11.68\n",
            "            min         0.00\n",
            "            max       203.00\n",
            "\n",
            "Group: 1\n",
            "word_count  mean      15.82\n",
            "            median    12.00\n",
            "            std       12.09\n",
            "            min        2.00\n",
            "            max       80.00\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "These are the words for the misunderstanding dictionary rule-based classifier:"
      ],
      "metadata": {
        "id": "CUln424LEQSK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "terms = ['accord', 'acknowledge', 'actually', 'adjust', 'already', 'ambiguity',\n",
        "          'ambivalence', 'amend', 'angle', 'anomaly', 'apologize', 'approach',\n",
        "          'ask', 'assume', 'assumption', 'aware', 'awareness', 'baffle', 'befuddled',\n",
        "          'bewilderment', 'blunder', 'challenge', 'chat', 'cite',\n",
        "          'clarify', 'comprehend',  'concur', 'confirm', 'conflict',\n",
        "          'confuse', 'consensus', 'contradict', 'controversy', 'conversation',\n",
        "          'correct', 'debate', 'deceptive', 'deliberate', 'delusion', 'demonstrate',\n",
        "          'denial', 'detail', 'dialogue', 'disagree', 'disbelief', 'discombobulated',\n",
        "          'discord', 'discrepancy', 'discussion', 'disorientation', 'dispute',\n",
        "          'dissent', 'distortion', 'distrust', 'disturbance', 'doubt', 'edit',\n",
        "          'elaborate', 'elucidation', 'enlightened', 'equivocation', 'erroneous', 'error',\n",
        "          'examine', 'expand', 'explain', 'explication', 'exposition',\n",
        "          'expound', 'fallacy', 'false', 'fault', 'feedback', 'flaw', 'flummoxed',\n",
        "          'follow', 'gap', 'grasp', 'hear', 'highlight', 'how', 'hypothesis',\n",
        "          'ignorance', 'illusion', 'illustrate', 'imbalance', 'inaccuracy',\n",
        "          'incomprehension', 'incongruence', 'incorrect',\n",
        "          'informed', 'input', 'inquire', 'insight', 'interpret',\n",
        "          'interpretation', 'interrogate', 'investigate', 'justification',\n",
        "          'listen', 'mean', 'misacknowledge', 'misadvise',\n",
        "          'misalign', 'misaligned', 'misapply', 'misapprehend', 'misattribute',\n",
        "          'miscalculate', 'miscalibration', 'mischaracterize', 'misclassify',\n",
        "          'miscommunication', 'miscomprehend', 'misconceive', 'misconception',\n",
        "          'misconclude', 'misconstruction', 'misconstrue', 'misconstrued',\n",
        "          'miscontextualize', 'misconvey', 'misdiagnose', 'misdirect',\n",
        "          'misestimate', 'misfathom', 'misgauge', 'misgiving', 'mishandle',\n",
        "          'mishear', 'misinform', 'misinterpret',\n",
        "          'misjudge', 'misjudgment', 'mislead', 'mismanage', 'mismatch', 'misperceive',\n",
        "          'misplace', 'misportray', 'misread', 'misreport', 'misrepresentation',\n",
        "          'misstate', 'misstep', 'mistake', 'mistranslate','misunderstand', 'modify',\n",
        "          'muddle', 'nonconformity', 'nonplussed', 'objection', 'obscure', 'overlook',\n",
        "          'oversight','reinterpret', 'oversimplification', 'perceive',\n",
        "          'perplexity', 'perspective', 'presumption', 'probe', 'puzzle', 'puzzlement',\n",
        "          'query', 'question', 'quote', 'rationale', 'readdress', 'realize',\n",
        "          'reanalyze', 'reasoning', 'reassess', 'recognize', 'reconfirm', 'recontextualize',\n",
        "          'rectify', 'redress', 'reevaluate', 'reference', 'reiterate', 'rejection',\n",
        "          'rejoinder', 'reply', 'response', 'restate', 'rethink', 'retort', 'revise',\n",
        "          'said', 'saying', 'scrutinize', 'skepticism', 'slip', 'sorry', 'specify',\n",
        "          'speculation', 'standpoint', 'stumped', 'supposition', 'suspicion', 'unawareness',\n",
        "          'uncertainty', 'understand', 'unease', 'unpack', 'validate',\n",
        "          'verify', 'viewpoint', 'what', 'when', 'where', 'which', 'who', 'why',\n",
        "          \"wtf\", \"reflection\", \"delineate\", \"rebuttal\", \"synopsis\", \"evaluation\",\n",
        "          \"reconsider\", \"diverge\", \"introspection\", \"articulate\", \"review\", \"discern\",\n",
        "          \"analyze\", \"contravene\"]"
      ],
      "metadata": {
        "id": "iFGXqvH9kubG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is the pre-trained BERT model for the supervised classifier:"
      ],
      "metadata": {
        "id": "YHkOiOmKEWBC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictor = ktrain.load_predictor('supervised_model')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JonSwZrcEV2M",
        "outputId": "55875407-a2d6-47dd-bec2-a41c7b2b4726"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/initializers/initializers.py:120: UserWarning: The initializer GlorotNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initializer instance more than once.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is the prompt for the few-shot classifier:"
      ],
      "metadata": {
        "id": "ZUFUiABGETYf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "role = \"\"\"\n",
        "*Role* You are a research assistant tasked with identifying whether a sentence indicates a misunderstanding.\n",
        "*Misunderstanding definition* A misunderstanding occurs during dialogue when one participant has an incorrect understanding of another’s perspective.\n",
        "\"\"\"\n",
        "prompt = \"\"\"\n",
        "There are two categories of misunderstanding:\n",
        "1. “Direct” misunderstandings. These occur when a participant evidences a misunderstanding of another participant’s point.\n",
        "2. “Felt” misunderstandings. These occur when a participant feels their previous turn was misunderstood by another participant.\n",
        "This is a non-exhaustive list of possible sentences indicating misunderstanding.\n",
        "1. Explicit statement: The sentence explicitly indicates the speaker doesn't understand another’s perspective (e.g., \"I don't get what you're trying to say about the dog\")\n",
        "2. Clarification question: The question seeks to clarify the other’s perspective (e.g., \"What do you mean?\")\n",
        "3. Request for confirmation: A question that seeks confirmation on the other’s understanding of the speaker’s previous turn(e.g., \"You really think that I meant all dogs?\")\n",
        "4. Correction of Other: Correcting another speaker’s misunderstanding of the present speaker’s previous turn(e.g., \"You've misunderstood my point\", “You don’t get it.”)\n",
        "5. Clarification or apology about speaker's intentions: Clarifying the meaning of what the speaker previously said (e.g., \"Sorry, I meant to say X\")\n",
        "6. Misunderstanding due to lack of response (e.g., \"Why did you change the subject?\")\n",
        "7. Editing a message at a later time: This is when a speaker in text-based dialogue comes back to edit their comment after the fact (e.g., \"EDIT\": That's what I said)\n",
        "Here are some examples of sentences indicating misunderstandings:\n",
        "- Jane, that article was what I was talking about.\n",
        "- Why not go further? - Do you think that was ok?\n",
        "- I apologise for saying that, but I meant the other stuff.\n",
        "- @John But when? - @John Please tell me why I've been stuck here for so long.\n",
        "- What drove that thought? - I actually said \"sure thing\".\n",
        "- You serious?\n",
        "- I'm not sure what I could have done differently.\n",
        "TASK:\n",
        "Does the below sentence indicate a possible misunderstanding?\n",
        "Only respond with \"Yes\" or \"No\"\n",
        "Sentence: {}\n",
        "Response:\"\"\""
      ],
      "metadata": {
        "id": "IjUet6QSkz1m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2 Throughput (automated)"
      ],
      "metadata": {
        "id": "KBCsSzjWk1EW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "These two plots show the classifier performance according to (1) Weighted F1 for the classifier and (2) Area Under the Precision Recall Curve"
      ],
      "metadata": {
        "id": "vKwY5i75e2Gu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "target_cols = [\"Order\",\"Classifier\",\"F1_avg\",\"F1_var\",\"AUC_PR\", \"AUC_ROC\",\"Precision\",\"Recall\",\"FP\",\"FN\",\"TP\",\"TN\"]\n",
        "ThroughRes = St2Through[target_cols].round(2).sort_values(\"AUC_PR\", ascending = False)\n",
        "ThroughRes = ThroughRes.rename(columns={\"F1_avg\": \"Weighted F1\", \"AUC_PR\":\"Area Under the Presicion-Recall Curve\"})\n",
        "tdf = ThroughRes.sort_values(by=[\"Order\",\"Classifier\"])\n",
        "tds = TextDataStats(tdf)\n",
        "tds.RAMP_plot(\"Order\", \"Weighted F1\",\"Classifier\",width=800,height=500)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        },
        "id": "VlRkLaBcfABm",
        "outputId": "01556b64-0267-4e74-a592-d806edae3235"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"1b09293e-214a-406f-a3b2-0b8d2f1a5b79\" class=\"plotly-graph-div\" style=\"height:500px; width:800px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"1b09293e-214a-406f-a3b2-0b8d2f1a5b79\")) {                    Plotly.newPlot(                        \"1b09293e-214a-406f-a3b2-0b8d2f1a5b79\",                        [{\"hovertemplate\":\"Classifier=few-shot\\u003cbr\\u003eOrder=%{x}\\u003cbr\\u003eWeighted F1=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"few-shot\",\"line\":{\"color\":\"#77B5FE\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines+markers\",\"name\":\"few-shot\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21],\"xaxis\":\"x\",\"y\":[0.79,0.78,0.86,0.87,0.88,0.91,0.88,0.88,0.87,0.88,0.88,0.86,0.91,0.91,0.88,0.84,0.87,0.9,0.91,0.88,0.9],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":\"Classifier=rule-based\\u003cbr\\u003eOrder=%{x}\\u003cbr\\u003eWeighted F1=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"rule-based\",\"line\":{\"color\":\"#FF6961\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines+markers\",\"name\":\"rule-based\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21],\"xaxis\":\"x\",\"y\":[0.85,0.85,0.82,0.81,0.82,0.87,0.87,0.87,0.87,0.87,0.87,0.87,0.87,0.87,0.83,0.79,0.78,0.78,0.76,0.75,0.74],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":\"Classifier=supervised\\u003cbr\\u003eOrder=%{x}\\u003cbr\\u003eWeighted F1=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"supervised\",\"line\":{\"color\":\"#B19CD9\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines+markers\",\"name\":\"supervised\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21],\"xaxis\":\"x\",\"y\":[0.93,0.93,0.93,0.93,0.94,0.94,0.93,0.94,0.94,0.93,0.93,0.94,0.93,0.93,0.93,0.93,0.94,0.93,0.93,0.94,0.93],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"line\":{\"color\":\"#77B5FE\",\"dash\":\"dash\",\"width\":2},\"mode\":\"lines\",\"name\":\"few-shot - Range Line\",\"opacity\":0.5,\"showlegend\":false,\"x\":[1,21],\"y\":[0.79,0.9],\"type\":\"scatter\"},{\"line\":{\"color\":\"#FF6961\",\"dash\":\"dash\",\"width\":2},\"mode\":\"lines\",\"name\":\"rule-based - Range Line\",\"opacity\":0.5,\"showlegend\":false,\"x\":[1,21],\"y\":[0.85,0.74],\"type\":\"scatter\"},{\"line\":{\"color\":\"#B19CD9\",\"dash\":\"dash\",\"width\":2},\"mode\":\"lines\",\"name\":\"supervised - Range Line\",\"opacity\":0.5,\"showlegend\":false,\"x\":[1,21],\"y\":[0.93,0.93],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Order\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Weighted F1\"}},\"legend\":{\"title\":{\"text\":\"Classifier\"},\"tracegroupgap\":0},\"margin\":{\"t\":60},\"title\":{\"text\":\"\"},\"width\":800,\"height\":500},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('1b09293e-214a-406f-a3b2-0b8d2f1a5b79');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tds.RAMP_plot(\"Order\", \"Area Under the Presicion-Recall Curve\",\"Classifier\", width=800,height=500)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        },
        "id": "TDcsjlrFfDkU",
        "outputId": "b4eee884-bb50-46b3-9f94-bab790dbd61e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"437771e4-e4bf-43e7-b33a-546a553a7534\" class=\"plotly-graph-div\" style=\"height:500px; width:800px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"437771e4-e4bf-43e7-b33a-546a553a7534\")) {                    Plotly.newPlot(                        \"437771e4-e4bf-43e7-b33a-546a553a7534\",                        [{\"hovertemplate\":\"Classifier=few-shot\\u003cbr\\u003eOrder=%{x}\\u003cbr\\u003eArea Under the Presicion-Recall Curve=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"few-shot\",\"line\":{\"color\":\"#77B5FE\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines+markers\",\"name\":\"few-shot\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21],\"xaxis\":\"x\",\"y\":[0.22,0.43,0.41,0.49,0.56,0.53,0.54,0.53,0.55,0.52,0.48,0.49,0.58,0.56,0.52,0.52,0.52,0.53,0.56,0.55,0.53],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":\"Classifier=rule-based\\u003cbr\\u003eOrder=%{x}\\u003cbr\\u003eArea Under the Presicion-Recall Curve=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"rule-based\",\"line\":{\"color\":\"#FF6961\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines+markers\",\"name\":\"rule-based\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21],\"xaxis\":\"x\",\"y\":[0.15,0.18,0.28,0.3,0.34,0.32,0.32,0.32,0.32,0.32,0.32,0.32,0.32,0.32,0.32,0.33,0.38,0.33,0.4,0.39,0.41],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":\"Classifier=supervised\\u003cbr\\u003eOrder=%{x}\\u003cbr\\u003eArea Under the Presicion-Recall Curve=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"supervised\",\"line\":{\"color\":\"#B19CD9\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines+markers\",\"name\":\"supervised\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21],\"xaxis\":\"x\",\"y\":[0.64,0.66,0.65,0.67,0.69,0.69,0.67,0.69,0.7,0.67,0.67,0.69,0.68,0.68,0.66,0.66,0.69,0.67,0.68,0.7,0.68],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"line\":{\"color\":\"#77B5FE\",\"dash\":\"dash\",\"width\":2},\"mode\":\"lines\",\"name\":\"few-shot - Range Line\",\"opacity\":0.5,\"showlegend\":false,\"x\":[1,21],\"y\":[0.22,0.53],\"type\":\"scatter\"},{\"line\":{\"color\":\"#FF6961\",\"dash\":\"dash\",\"width\":2},\"mode\":\"lines\",\"name\":\"rule-based - Range Line\",\"opacity\":0.5,\"showlegend\":false,\"x\":[1,21],\"y\":[0.15,0.41],\"type\":\"scatter\"},{\"line\":{\"color\":\"#B19CD9\",\"dash\":\"dash\",\"width\":2},\"mode\":\"lines\",\"name\":\"supervised - Range Line\",\"opacity\":0.5,\"showlegend\":false,\"x\":[1,21],\"y\":[0.64,0.68],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Order\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Area Under the Presicion-Recall Curve\"}},\"legend\":{\"title\":{\"text\":\"Classifier\"},\"tracegroupgap\":0},\"margin\":{\"t\":60},\"title\":{\"text\":\"\"},\"width\":800,\"height\":500},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('437771e4-e4bf-43e7-b33a-546a553a7534');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Best supervised classifier and parameters\n",
        "supdf = St2Through[[\"Order\",\"Classifier\",\"F1_avg\",\"AUC_PR\",\"Precision\",\"Recall\",\"validation_size\",\"epochs\",\"learning_rate\",\"batch_size\"]]\n",
        "supdf[supdf[\"Classifier\"]==\"supervised\"].sort_values(\"AUC_PR\", ascending = False).head(1).round(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "H7ct4xwOb7JI",
        "outputId": "0ceec030-00d2-4fdd-b744-ce94b18de121"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Order  Classifier  F1_avg  AUC_PR  Precision  Recall  validation_size  \\\n",
              "61     20  supervised    0.94     0.7       0.74    0.62              0.3   \n",
              "\n",
              "    epochs  learning_rate  batch_size  \n",
              "61     4.0            0.0        64.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7760ff16-ed99-4b4a-9f28-fe6d3ec3d232\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Order</th>\n",
              "      <th>Classifier</th>\n",
              "      <th>F1_avg</th>\n",
              "      <th>AUC_PR</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>validation_size</th>\n",
              "      <th>epochs</th>\n",
              "      <th>learning_rate</th>\n",
              "      <th>batch_size</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>20</td>\n",
              "      <td>supervised</td>\n",
              "      <td>0.94</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.74</td>\n",
              "      <td>0.62</td>\n",
              "      <td>0.3</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>64.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7760ff16-ed99-4b4a-9f28-fe6d3ec3d232')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7760ff16-ed99-4b4a-9f28-fe6d3ec3d232 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7760ff16-ed99-4b4a-9f28-fe6d3ec3d232');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"supdf[supdf[\\\"Classifier\\\"]==\\\"supervised\\\"]\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"Order\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 20,\n        \"max\": 20,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          20\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Classifier\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"supervised\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1_avg\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.94,\n        \"max\": 0.94,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.94\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AUC_PR\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.7,\n        \"max\": 0.7,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.74,\n        \"max\": 0.74,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.74\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.62,\n        \"max\": 0.62,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.62\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"validation_size\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.3,\n        \"max\": 0.3,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"epochs\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 4.0,\n        \"max\": 4.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          4.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"learning_rate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"batch_size\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 64.0,\n        \"max\": 64.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          64.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Best rule-based classifier (using lemma list)\n",
        "rbdf = St2Through[[\"Order\",\"Classifier\",\"F1_avg\",\"AUC_PR\",\"Precision\",\"Recall\",\"PatternOrLemma\",\"train_size\",\"nTerms\"]]\n",
        "rbdf[rbdf[\"Classifier\"]==\"rule-based\"].sort_values(\"AUC_PR\", ascending = False).head(1).round(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "evTmH1ZWdVRO",
        "outputId": "72dc24a4-ccaa-4bf0-d426-bf4f109c500b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Order  Classifier  F1_avg  AUC_PR  Precision  Recall PatternOrLemma  \\\n",
              "41     21  rule-based    0.74    0.41       0.17    0.61          lemma   \n",
              "\n",
              "    train_size  nTerms  \n",
              "41       14728   230.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ae4129af-679b-411a-a137-73f9b45ef6ca\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Order</th>\n",
              "      <th>Classifier</th>\n",
              "      <th>F1_avg</th>\n",
              "      <th>AUC_PR</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>PatternOrLemma</th>\n",
              "      <th>train_size</th>\n",
              "      <th>nTerms</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>21</td>\n",
              "      <td>rule-based</td>\n",
              "      <td>0.74</td>\n",
              "      <td>0.41</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.61</td>\n",
              "      <td>lemma</td>\n",
              "      <td>14728</td>\n",
              "      <td>230.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ae4129af-679b-411a-a137-73f9b45ef6ca')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ae4129af-679b-411a-a137-73f9b45ef6ca button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ae4129af-679b-411a-a137-73f9b45ef6ca');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"rbdf[rbdf[\\\"Classifier\\\"]==\\\"rule-based\\\"]\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"Order\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 21,\n        \"max\": 21,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          21\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Classifier\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"rule-based\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1_avg\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.74,\n        \"max\": 0.74,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.74\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AUC_PR\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.41,\n        \"max\": 0.41,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.41\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.17,\n        \"max\": 0.17,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.17\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.61,\n        \"max\": 0.61,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.61\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"PatternOrLemma\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"lemma\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"train_size\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 14728,\n        \"max\": 14728,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          14728\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"nTerms\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 230.0,\n        \"max\": 230.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          230.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Best few-shot classifiers (using prompt)\n",
        "rbdf = St2Through[[\"Order\",\"Classifier\",\"F1_avg\",\"AUC_PR\",\"Precision\",\"Recall\", \"train_size\",\"GPTmodel\"]]\n",
        "rbdf[rbdf[\"Classifier\"]==\"few-shot\"].sort_values(\"AUC_PR\", ascending = False).head(1).round(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "q34Rv6ofehT9",
        "outputId": "8926c57f-a888-4bcf-a644-31f941737484"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Order Classifier  F1_avg  AUC_PR  Precision  Recall  train_size  \\\n",
              "12     13   few-shot    0.91    0.58       0.54    0.59        1000   \n",
              "\n",
              "       GPTmodel  \n",
              "12  gpt-4-turbo  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a27b1dd7-50c2-40e4-a567-6a006f06e163\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Order</th>\n",
              "      <th>Classifier</th>\n",
              "      <th>F1_avg</th>\n",
              "      <th>AUC_PR</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>train_size</th>\n",
              "      <th>GPTmodel</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>13</td>\n",
              "      <td>few-shot</td>\n",
              "      <td>0.91</td>\n",
              "      <td>0.58</td>\n",
              "      <td>0.54</td>\n",
              "      <td>0.59</td>\n",
              "      <td>1000</td>\n",
              "      <td>gpt-4-turbo</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a27b1dd7-50c2-40e4-a567-6a006f06e163')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a27b1dd7-50c2-40e4-a567-6a006f06e163 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a27b1dd7-50c2-40e4-a567-6a006f06e163');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"rbdf[rbdf[\\\"Classifier\\\"]==\\\"few-shot\\\"]\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"Order\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 13,\n        \"max\": 13,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          13\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Classifier\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"few-shot\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1_avg\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.91,\n        \"max\": 0.91,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.91\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AUC_PR\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.58,\n        \"max\": 0.58,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.58\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.54,\n        \"max\": 0.54,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.54\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.59,\n        \"max\": 0.59,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.59\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"train_size\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 1000,\n        \"max\": 1000,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1000\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"GPTmodel\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"gpt-4-turbo\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.3 Output (automated)"
      ],
      "metadata": {
        "id": "jivZGllok5VD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3.1 Classification reports"
      ],
      "metadata": {
        "id": "kSU0RKIlm_9L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "out = validation.copy()\n",
        "texts = out.text.to_list()\n",
        "true_scores = out.Misunderstanding.to_list()"
      ],
      "metadata": {
        "id": "S9BJA7wlE4yp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Rule-based classifier\n",
        "rbClassifier = Classifier(texts, true_scores)\n",
        "rbClassifier.add_rule_based_terms(terms, 'lemma')\n",
        "rbClassifier.run_classifier()\n",
        "rbClassifier.get_model_report()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AdfORjN8k9aW",
        "outputId": "31090e17-49b9-426b-93ee-b62065294cb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/spacy/util.py:1740: UserWarning:\n",
            "\n",
            "[W111] Jupyter notebook detected: if using `prefer_gpu()` or `require_gpu()`, include it in the same cell right before `spacy.load()` to ensure that the model is loaded on the correct device. More information: http://spacy.io/usage/v3#jupyter-notebook-gpu\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC-PR: 0.40\n",
            "\n",
            "AUC-ROC: 0.65\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.68      0.79      5909\n",
            "           1       0.14      0.63      0.24       511\n",
            "\n",
            "    accuracy                           0.67      6420\n",
            "   macro avg       0.55      0.65      0.51      6420\n",
            "weighted avg       0.89      0.67      0.75      6420\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For supervised machine learning classifier\n",
        "smlClassifier = Classifier(texts, true_scores)\n",
        "smlClassifier.add_SML_classifier(predictor)\n",
        "smlClassifier.run_classifier()\n",
        "smlClassifier.get_model_report()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_dFRe4RExfV",
        "outputId": "c0e854e7-b805-4a90-b048-e8d2b5c99d5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/spacy/util.py:1740: UserWarning:\n",
            "\n",
            "[W111] Jupyter notebook detected: if using `prefer_gpu()` or `require_gpu()`, include it in the same cell right before `spacy.load()` to ensure that the model is loaded on the correct device. More information: http://spacy.io/usage/v3#jupyter-notebook-gpu\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Supervised ML classifier configured with parameters: {}\n",
            "AUC-PR: 0.73\n",
            "\n",
            "AUC-ROC: 0.88\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.96      0.97      5909\n",
            "           1       0.65      0.79      0.71       511\n",
            "\n",
            "    accuracy                           0.95      6420\n",
            "   macro avg       0.81      0.88      0.84      6420\n",
            "weighted avg       0.95      0.95      0.95      6420\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Few-shot classifier\n",
        "gpt_model = \"gpt-4-turbo\"\n",
        "fsClassifier = Classifier(texts, true_scores)\n",
        "fsClassifier.add_few_shot_classifier(gpt_model, prompt, role)\n",
        "fsClassifier.run_classifier()\n",
        "fsClassifier.get_model_report()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DN8TjOTjEy7N",
        "outputId": "37e17295-6bd7-48df-fa9d-d75b31da5931"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/spacy/util.py:1740: UserWarning:\n",
            "\n",
            "[W111] Jupyter notebook detected: if using `prefer_gpu()` or `require_gpu()`, include it in the same cell right before `spacy.load()` to ensure that the model is loaded on the correct device. More information: http://spacy.io/usage/v3#jupyter-notebook-gpu\n",
            "\n",
            "100%|██████████| 6420/6420 [1:29:32<00:00,  1.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This run cost 33.76$ for 3376337 tokens. Average tokens: 525.91\n",
            "AUC-PR: 0.54\n",
            "\n",
            "AUC-ROC: 0.78\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.92      0.94      5909\n",
            "           1       0.41      0.64      0.50       511\n",
            "\n",
            "    accuracy                           0.90      6420\n",
            "   macro avg       0.69      0.78      0.72      6420\n",
            "weighted avg       0.92      0.90      0.91      6420\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#out[\"rule-based\"] = rbClassifier.pred_scores\n",
        "#out[\"supervised\"] = smlClassifier.pred_scores\n",
        "#out[\"few-shot\"] = fsClassifier.pred_scores\n",
        "#out.to_csv(\"RAMP_Stage3.csv\",index=False)"
      ],
      "metadata": {
        "id": "iv3FQ3-snIdm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Stage 3: Abduction\n",
        "\n",
        "This section looks at misclassifications in order to inform the final stage of RAMP. These are used to infer surprising findings from which to identify potential problems of construct and concept validity."
      ],
      "metadata": {
        "id": "5QvklA8-nEJT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "out = out.rename(columns={\"Misunderstanding\":\"Manual\"})"
      ],
      "metadata": {
        "id": "NRF8EStoCdmG"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tds = TextDataStats(out)\n",
        "misdf = tds.get_misclassifications(return_all = True)"
      ],
      "metadata": {
        "id": "1e47fC2YZ1Gs"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For printing rule-based misclassifications - these are fairly arbitrary\n",
        "for i in misdf[misdf[\"Manual\"]==1][misdf[\"rule-based\"]==0].sample(10).text.values:\n",
        "  print(i)"
      ],
      "metadata": {
        "id": "mhrPActSaBn0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f8332fe-1a53-476b-ad05-2ee7fd040d99"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Incredible, n'est pas?\n",
            "So orders can't be partially filled?\n",
            "I don't think anyone's point here was that you won't make more if you put more time into the same job, but that hard work does not equal success, but rather is likely just a component of it.\n",
            "As I mention there, I think it's broadly within criteria but I want nothing more to do with the personalities involved and its best if someone else closed it.\n",
            "My focus is on Chinese version of wikipedia, not the English version.\n",
            "I shouldn't have dragged you along if I did.\n",
            "Stealing hubcaps?\n",
            "No put stickers on things that changed the perception of them Like he would put a woodchuck sticker on the hand operated pencil sharpener and stickers that read, \"Lies?\" on the globe because despite being a science teacher he was a flat earther.\n",
            "It's fine.\n",
            "Are you complaining about the content of the statement or just about the way it was expressed?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-3b1cc0282d4c>:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
            "  for i in misdf[misdf[\"Manual\"]==1][misdf[\"rule-based\"]==0].sample(10).text.values:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For supervised and few shot classifiers\n",
        "tds = TextDataStats(out)\n",
        "tds.get_misclassifications(n=20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7Fvi5Aenrj-",
        "outputId": "306db155-388b-4f60-c2bb-35ab704150c6"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- False positives count: --\n",
            "Both = 0, Supervised = 118, Few-shot = 372\n",
            "\n",
            "--- False negatives count: --\n",
            "Both = 104, Supervised = 46, Few-shot = 124\n",
            "\n",
            "Printing 20 examples of each classifier type.\n",
            "\n",
            "------ FALSE POSITIVES ------\n",
            "# Few-shot & supervised false positives\n",
            "--------\n",
            "# Supervised false positives\n",
            "- A google time-stamped prophecy is neither an opinion, experience nor is it an argument, so I can't see how it is original research.\n",
            "- I also have to admit that running into you has made this avocation less than enjoyable as I seek to begin to respond to the grain and chaff issue I referred to in a previous edit.\n",
            "- This proves my point too.\n",
            "- Indonesian organisations with english names as title of article and the indonesian name as the aka please?\n",
            "- Are you having this issue with any other channels?\n",
            "- I don't care about martyrdom, etc., or any dramas.\n",
            "- But why is that ideology so attractive?\n",
            "- If you can't, it's no problem; I just thought I'd ask.\n",
            "- @Company_Handle I did not hear back from you yet.\n",
            "- Now you're just being uncivil and insulting.\n",
            "- I wanted to talk to them, but didn't know where to start.\n",
            "- I understand your frustration at seeing a lot of what you've created slowly whittled away, but [http:\\/\\/en.wikipedia.org\\/w\\/index.php?title=Suzi_Suzuki&curid=4775796&diff=437390137&oldid=437364401 this] is 100% pure [[WP:POINT]].\n",
            "- As for \\\"taking recentism to new heights\\\", I stand by that attack on the edit.\n",
            "- Belatedly, I've added the material I mentioned earlier concerning individual reactions to Laurie's books upon their publication.\n",
            "- It's me, again.\n",
            "- Like you, I wrote on what I know, so it was easy.\n",
            "- Oh no!!\n",
            "- @Company_Handle ?\n",
            "- I thought not.\n",
            "- My phone been on 1x for 2 fucking days wtf is 1x?\n",
            "--------\n",
            "# Few-shot false positives\n",
            "- And I am not some crazed guy out to mock and disrupt his life, regardless of what he says ot thinks.\n",
            "- Where do you see the blog is sponsored by Parade Magazine.\n",
            "- Any clues as to how I can fix?\n",
            "- Thanks for the article, which does not in fact discuss ''how'' to distinguish empty matrices, although it does mention their distinctiveness.\n",
            "- this is amc, but i feel you\n",
            "- They fought for you to be able to, not to require you to This phrase mostly comes up when you decide not to care about something someone else feels strongly about\n",
            "- Cant tell if that's the pilot or the undercarriage that gets fired out the front.\n",
            "- Just stop thinking your above others be you only listen to a few of biggie and Christopher's songs when you don't give anything else a try.\n",
            "- Don't fool yourself, that's what's going on.\n",
            "- If my words are not clear, please point out the parts which need further explaining.\n",
            "- Do you have a source for your reversion on [[:Template:Infobox Family Guy Season 7]]?\n",
            "- @Company_Handle It say's I'm verified been when I click the user detail this is the next page.\n",
            "- So I continually request a discount that I'm entitled to with &amp; they don't give info.\n",
            "- Good Day - Sotcr Excuse my English (\n",
            "- I would appreciate if you will take other look and give your opinion.\n",
            "- Your warnings weren't placed amongst the accumulation at [[User_talk:82.111.23.171|Reading Borough Council]].\n",
            "- And I agree, it can be helpful to get an outside perspective to make sure that all readers can understand the subject, too \\u2013 myself being one that really doesn't know anything about the sport of [[drag racing]].\n",
            "- Hello, I have sent 2 coppies of my unblock request to arbcom, one in march, and one in early April, but no response, so I am seaking advice, what else is there for me to do, I'm totaly out of ideas and I have lost faith in wikipedia.\n",
            "- @Company_Handle be nice though if the whole range was available esp in an Xtra store, I currently have to drive 10km to James for more choice.. @Company_Handle hi im interested in the new ones the peppercorn and \"goats\" cheese I already know where the existing Free From cheezes can.be got.\n",
            "- Please, could someone tell me what next?\n",
            "--------\n",
            "------ FALSE NEGATIVES ------\n",
            "# Few-shot & supervised false negatives\n",
            "- Its happened a few times now.Is it supposed to be like that?\n",
            "- @Company_Handle That's so strange - clicked on the link and it isn't showing that late :( \n",
            "- Which will be better??\n",
            "- So what about everyone else?\n",
            "- @Company_Handle Will I still be getting a Scorpio editon?\n",
            "- I hope you didn't think it was serious.\n",
            "- I can't answer to all your questions since I don't think to have been involved in all the edits you talk about.\n",
            "- Was it still showing as downloading for you?\n",
            "- Two flights in a row????\n",
            "- &#x200B; It is true that they are wrong, but how should they know?\n",
            "- Does this mean that articles such as [[Duality (Song)]] and [[Mirrorcle World]] are invalid, as well as all of [[The Gazette]]'s other singles?\n",
            "- To customer CARE?\n",
            "- Is that right?\n",
            "- That's why I needed to double-check.\n",
            "- But yes obviously that Facebook whatever stuff is actually wrong i just wanted to point out that an actual number for the death rate exists and has actually existed for many months\n",
            "- I was wondering this too, or if it's something you intentionally do to trick your brain?\n",
            "- Yes, please do that, if you change it to non consensus then it stops people quoting it as if it was decided by the review when it wasn't.- \n",
            "- > Okay, when I wrote this, I was a little too focused on deliberate acts of self expression rather than things people are born with.\n",
            "- :-) On an unrelated note, I've obviously read your user page -- is your daughter killing you the same way ours is killing us?\n",
            "- No, he didn't.\n",
            "--------\n",
            "# Supervised false negatives\n",
            "- Not sure what that is\n",
            "- But... they do.\n",
            "- To the user whose page this is, examine the situation as you will, but I thought I'd leave my two cents when the person above is trying to portray me as someone out to ruin the article.\n",
            "- Mark, the experience you are describing is something we'd never do.\n",
            "- What am I doing?\n",
            "- I take that back.\n",
            "- How can you fame a Wikipedian?\n",
            "- For one i didn't even know the person \\\"personally\\\".\n",
            "- How is this photo relevant to Rachel's life?\n",
            "- How does it make it make Wikipedia more user friendly to alter [[Natasha]] to [[Kelly of England|Henry VIII]]?\n",
            "- FA work is fine and I'm sure WMC could assist in non CC related article improvement but once a bulls eye get painted on anyone of this high a profile on this project, someone is always going to be the ready to play smackdown if such an editor so much as twitches \\\"incorrectly\\\"...my understanding as it was clarified to me was that user talkpages, even your own user talkpage are taboo for issues related to the topic ban.--\n",
            "- That may be (one can never be sure), but the editors don't seem to understand the serious problems with the page.\n",
            "- Can you elaborate the implications of your argument?\n",
            "- @Company_Handle this is the enough apologies you have sent, it's enough to last me a life time .. clean up your mess \n",
            "- Might I ask you to check out my responses to the issues you raised, specifically the questions I asked about images?\n",
            "- The rest not so right thanks for correcting me!\n",
            "- Could you confirm If you have contacted the support team through link provided earlier?\n",
            "- Edit: this is for areas that don't normally get freezing temperatures, where houses aren't designed for those temperatures.\n",
            "- I guess you think more highly of userboxes than myself.\n",
            "- @Company_Handle What number are you dialing?\n",
            "--------\n",
            "# Few-shot false negatives\n",
            "- How would we know if it was true or not if someone credible hasn't verified it?\n",
            "- For the reasons stated above, I'm not sure what the right venue is.\n",
            "- If it is it.\n",
            "- @Company_Handle Hmm...you've stumped us, Jeffrey!\n",
            "- Simple Kelli, I'm sorry I wasn't able to take up the suggestion, I'm just a little busy in that pesky real world at the moment (to the extent I'll be working on the weekend, something that's unheard of for me!)\n",
            "- I said it before and say it again: the idea of mentors who are selected because \\\"they have tangled with this person before and will drop the hammer\\\" is moonbats at best, and sneaky\\/vindictive at worst.\n",
            "- My focus is on Chinese version of wikipedia, not the English version.\n",
            "- With me, you're largely preaching to the choir, although I didn't know much in the way of specifics.\n",
            "- I read [[User:SchmuckyTheCat\\/Mainland_China]] before I take action against your editing.\n",
            "- I'm not edit warring.\n",
            "- I forgot that we are on earth and that there are forces applied on objects that arent present in space lol.\n",
            "- I'm just sending everyone who's been involved with it the same generic message so I'm not seeming biased and so that I get everyone involved who has a desire to be involved :)\n",
            "- Please see my post to the article's talk page\n",
            "- Fair enough - I suppose I let some of this stuff get to me too much, which is why I felt it best to just take that contentious page off my watchlist.\n",
            "- I mean the argument is that were not a meritocracy because one not all jobs pay the same, and two we have different starting circumstances.\n",
            "- I didn't read the whole mv section.\n",
            "- Woops, no I can't, sorry.\n",
            "- Again, we can only reiterate our sincere apologies.\n",
            "- As I mention there, I think it's broadly within criteria but I want nothing more to do with the personalities involved and its best if someone else closed it.\n",
            "- I mean your proposal in bold (also bold proposal) about FSA's.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For assessing the supervised classifier FN and FP\n",
        "predictor.explain(\"It's me, again\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "id": "IxRV_yhTa7J9",
        "outputId": "417a389d-0e44-4625-a068-84e5a3a8ccec"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <style>\n",
              "    table.eli5-weights tr:hover {\n",
              "        filter: brightness(85%);\n",
              "    }\n",
              "</style>\n",
              "\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "        \n",
              "\n",
              "    \n",
              "\n",
              "        \n",
              "\n",
              "        \n",
              "    \n",
              "        \n",
              "        \n",
              "    \n",
              "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
              "            <b>\n",
              "    \n",
              "        y=Misunderstanding\n",
              "    \n",
              "</b>\n",
              "\n",
              "    \n",
              "    (probability <b>0.799</b>, score <b>1.378</b>)\n",
              "\n",
              "top features\n",
              "        </p>\n",
              "    \n",
              "    <table class=\"eli5-weights\"\n",
              "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
              "        <thead>\n",
              "        <tr style=\"border: none;\">\n",
              "            \n",
              "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
              "                    Contribution<sup>?</sup>\n",
              "                </th>\n",
              "            \n",
              "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
              "            \n",
              "        </tr>\n",
              "        </thead>\n",
              "        <tbody>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +2.777\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        Highlighted in text (sum)\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "        \n",
              "\n",
              "        \n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 87.63%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -1.399\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        &lt;BIAS&gt;\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "\n",
              "        </tbody>\n",
              "    </table>\n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n",
              "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
              "        <span style=\"background-color: hsl(120, 100.00%, 74.54%); opacity: 0.90\" title=\"1.709\">it</span><span style=\"opacity: 0.80\">&#x27;</span><span style=\"background-color: hsl(0, 100.00%, 92.22%); opacity: 0.82\" title=\"-0.314\">s</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 87.68%); opacity: 0.84\" title=\"0.606\">me</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(120, 100.00%, 60.00%); opacity: 1.00\" title=\"3.259\">again</span>\n",
              "    </p>\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictor.explain(\"Mark, the experience you are describing is something we'd never do.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "id": "-FSv-aABefP8",
        "outputId": "25634fc7-81f2-4613-f5bd-70a469c8c583"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <style>\n",
              "    table.eli5-weights tr:hover {\n",
              "        filter: brightness(85%);\n",
              "    }\n",
              "</style>\n",
              "\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "        \n",
              "\n",
              "    \n",
              "\n",
              "        \n",
              "\n",
              "        \n",
              "    \n",
              "        \n",
              "        \n",
              "    \n",
              "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
              "            <b>\n",
              "    \n",
              "        y=not_Misunderstanding\n",
              "    \n",
              "</b>\n",
              "\n",
              "    \n",
              "    (probability <b>0.701</b>, score <b>-0.850</b>)\n",
              "\n",
              "top features\n",
              "        </p>\n",
              "    \n",
              "    <table class=\"eli5-weights\"\n",
              "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
              "        <thead>\n",
              "        <tr style=\"border: none;\">\n",
              "            \n",
              "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
              "                    Contribution<sup>?</sup>\n",
              "                </th>\n",
              "            \n",
              "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
              "            \n",
              "        </tr>\n",
              "        </thead>\n",
              "        <tbody>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +1.272\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        &lt;BIAS&gt;\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "        \n",
              "\n",
              "        \n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 90.76%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -0.422\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        Highlighted in text (sum)\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "\n",
              "        </tbody>\n",
              "    </table>\n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n",
              "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
              "        <span style=\"background-color: hsl(0, 100.00%, 91.80%); opacity: 0.82\" title=\"-0.289\">mark</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(0, 100.00%, 87.58%); opacity: 0.84\" title=\"-0.523\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 84.45%); opacity: 0.85\" title=\"0.721\">experience</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 65.61%); opacity: 0.96\" title=\"-2.240\">you</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.54%); opacity: 0.82\" title=\"-0.252\">are</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 60.00%); opacity: 1.00\" title=\"-2.780\">describing</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 87.81%); opacity: 0.84\" title=\"-0.509\">is</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.96%); opacity: 0.81\" title=\"-0.144\">something</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 71.82%); opacity: 0.92\" title=\"-1.685\">we</span><span style=\"opacity: 0.80\">&#x27;</span><span style=\"background-color: hsl(120, 100.00%, 77.01%); opacity: 0.89\" title=\"1.260\">d</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 70.08%); opacity: 0.93\" title=\"-1.836\">never</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.63%); opacity: 0.81\" title=\"0.118\">do</span><span style=\"opacity: 0.80\">.</span>\n",
              "    </p>\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For assessing the supervised classifier FN and FP\n",
        "predictor.explain(\"Not sure what that is\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "id": "CmZKiXyCbTMC",
        "outputId": "bf9a779d-be21-45e5-9202-adbcf1ee0978"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <style>\n",
              "    table.eli5-weights tr:hover {\n",
              "        filter: brightness(85%);\n",
              "    }\n",
              "</style>\n",
              "\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "        \n",
              "\n",
              "    \n",
              "\n",
              "        \n",
              "\n",
              "        \n",
              "    \n",
              "        \n",
              "        \n",
              "    \n",
              "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
              "            <b>\n",
              "    \n",
              "        y=not_Misunderstanding\n",
              "    \n",
              "</b>\n",
              "\n",
              "    \n",
              "    (probability <b>0.432</b>, score <b>0.275</b>)\n",
              "\n",
              "top features\n",
              "        </p>\n",
              "    \n",
              "    <table class=\"eli5-weights\"\n",
              "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
              "        <thead>\n",
              "        <tr style=\"border: none;\">\n",
              "            \n",
              "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
              "                    Contribution<sup>?</sup>\n",
              "                </th>\n",
              "            \n",
              "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
              "            \n",
              "        </tr>\n",
              "        </thead>\n",
              "        <tbody>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 83.32%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +0.929\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        &lt;BIAS&gt;\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "        \n",
              "\n",
              "        \n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 80.00%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -1.204\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        Highlighted in text (sum)\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "\n",
              "        </tbody>\n",
              "    </table>\n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n",
              "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
              "        <span style=\"background-color: hsl(120, 100.00%, 81.83%); opacity: 0.86\" title=\"0.456\">not</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 71.37%); opacity: 0.92\" title=\"0.873\">sure</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 67.48%); opacity: 0.95\" title=\"-1.047\">what</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 60.00%); opacity: 1.00\" title=\"-1.407\">that</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 64.52%); opacity: 0.97\" title=\"-1.186\">is</span>\n",
              "    </p>\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For assessing the supervised classifier FN and FP\n",
        "predictor.explain(\"But... They do.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "id": "dWDBjWMGzCFk",
        "outputId": "2caca445-afc6-458c-c38e-067d452478d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <style>\n",
              "    table.eli5-weights tr:hover {\n",
              "        filter: brightness(85%);\n",
              "    }\n",
              "</style>\n",
              "\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "        \n",
              "\n",
              "    \n",
              "\n",
              "        \n",
              "\n",
              "        \n",
              "    \n",
              "        \n",
              "        \n",
              "    \n",
              "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
              "            <b>\n",
              "    \n",
              "        y=not_Misunderstanding\n",
              "    \n",
              "</b>\n",
              "\n",
              "    \n",
              "    (probability <b>0.997</b>, score <b>-5.930</b>)\n",
              "\n",
              "top features\n",
              "        </p>\n",
              "    \n",
              "    <table class=\"eli5-weights\"\n",
              "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
              "        <thead>\n",
              "        <tr style=\"border: none;\">\n",
              "            \n",
              "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
              "                    Contribution<sup>?</sup>\n",
              "                </th>\n",
              "            \n",
              "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
              "            \n",
              "        </tr>\n",
              "        </thead>\n",
              "        <tbody>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +5.248\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        Highlighted in text (sum)\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 95.21%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +0.682\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        &lt;BIAS&gt;\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "        \n",
              "\n",
              "        \n",
              "        \n",
              "\n",
              "        </tbody>\n",
              "    </table>\n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n",
              "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
              "        <span style=\"background-color: hsl(120, 100.00%, 84.97%); opacity: 0.85\" title=\"0.600\">but</span><span style=\"opacity: 0.80\">... </span><span style=\"background-color: hsl(120, 100.00%, 72.94%); opacity: 0.91\" title=\"1.390\">they</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 60.00%); opacity: 1.00\" title=\"2.429\">do</span><span style=\"opacity: 0.80\">.</span>\n",
              "    </p>\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Conclusions\n",
        "\n",
        "In Stage 1, we had acceptable inter-rater reliability (Krippendorff's Alpha = 0.79) following 5 training rounds.\n",
        "In Stage 2, we created three different text classifiers, one rule-based, one supervised, and one few-shot. Overall, the supervised machine learning classifier – a fine-tuned BERT model – is much better than both the few-shot and rule-based classifiers. The classifier's performance is acceptable (AUC PR = 0.73) with room for improvement.\n",
        "\n",
        " When troubleshooting the results, we can see that the false negatiives are missing some key clarification questions (e.g., \"So what about everyone else?\"). We can also see that the classifiers are picking up on \"new information\" questions, not directed at another's perspeective (e.g., \"Are you having this issue with any other channels?\"). The misclassifications indicate that the classifier is generally struggling with edge cases more than standard cases."
      ],
      "metadata": {
        "id": "VbMaI0IKk_0H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Export notebook:"
      ],
      "metadata": {
        "id": "RW6oyH4WK7U3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary packages\n",
        "!sudo apt-get install texlive-xetex texlive-fonts-recommended texlive-plain-generic"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "M15jQ7qrK5j5",
        "outputId": "c15a8c4a-def0-463c-9e12-3289e39e72d2"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  dvisvgm fonts-droid-fallback fonts-lato fonts-lmodern fonts-noto-mono\n",
            "  fonts-texgyre fonts-urw-base35 libapache-pom-java libcommons-logging-java\n",
            "  libcommons-parent-java libfontbox-java libfontenc1 libgs9 libgs9-common\n",
            "  libidn12 libijs-0.35 libjbig2dec0 libkpathsea6 libpdfbox-java libptexenc1\n",
            "  libruby3.0 libsynctex2 libteckit0 libtexlua53 libtexluajit2 libwoff1\n",
            "  libzzip-0-13 lmodern poppler-data preview-latex-style rake ruby\n",
            "  ruby-net-telnet ruby-rubygems ruby-webrick ruby-xmlrpc ruby3.0\n",
            "  rubygems-integration t1utils teckit tex-common tex-gyre texlive-base\n",
            "  texlive-binaries texlive-latex-base texlive-latex-extra\n",
            "  texlive-latex-recommended texlive-pictures tipa xfonts-encodings\n",
            "  xfonts-utils\n",
            "Suggested packages:\n",
            "  fonts-noto fonts-freefont-otf | fonts-freefont-ttf libavalon-framework-java\n",
            "  libcommons-logging-java-doc libexcalibur-logkit-java liblog4j1.2-java\n",
            "  poppler-utils ghostscript fonts-japanese-mincho | fonts-ipafont-mincho\n",
            "  fonts-japanese-gothic | fonts-ipafont-gothic fonts-arphic-ukai\n",
            "  fonts-arphic-uming fonts-nanum ri ruby-dev bundler debhelper gv\n",
            "  | postscript-viewer perl-tk xpdf | pdf-viewer xzdec\n",
            "  texlive-fonts-recommended-doc texlive-latex-base-doc python3-pygments\n",
            "  icc-profiles libfile-which-perl libspreadsheet-parseexcel-perl\n",
            "  texlive-latex-extra-doc texlive-latex-recommended-doc texlive-luatex\n",
            "  texlive-pstricks dot2tex prerex texlive-pictures-doc vprerex\n",
            "  default-jre-headless tipa-doc\n",
            "The following NEW packages will be installed:\n",
            "  dvisvgm fonts-droid-fallback fonts-lato fonts-lmodern fonts-noto-mono\n",
            "  fonts-texgyre fonts-urw-base35 libapache-pom-java libcommons-logging-java\n",
            "  libcommons-parent-java libfontbox-java libfontenc1 libgs9 libgs9-common\n",
            "  libidn12 libijs-0.35 libjbig2dec0 libkpathsea6 libpdfbox-java libptexenc1\n",
            "  libruby3.0 libsynctex2 libteckit0 libtexlua53 libtexluajit2 libwoff1\n",
            "  libzzip-0-13 lmodern poppler-data preview-latex-style rake ruby\n",
            "  ruby-net-telnet ruby-rubygems ruby-webrick ruby-xmlrpc ruby3.0\n",
            "  rubygems-integration t1utils teckit tex-common tex-gyre texlive-base\n",
            "  texlive-binaries texlive-fonts-recommended texlive-latex-base\n",
            "  texlive-latex-extra texlive-latex-recommended texlive-pictures\n",
            "  texlive-plain-generic texlive-xetex tipa xfonts-encodings xfonts-utils\n",
            "0 upgraded, 54 newly installed, 0 to remove and 45 not upgraded.\n",
            "Need to get 182 MB of archives.\n",
            "After this operation, 571 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-droid-fallback all 1:6.0.1r16-1.1build1 [1,805 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-lato all 2.0-2.1 [2,696 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 poppler-data all 0.4.11-1 [2,171 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tex-common all 6.17 [33.7 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-urw-base35 all 20200910-1 [6,367 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgs9-common all 9.55.0~dfsg1-0ubuntu5.6 [751 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libidn12 amd64 1.38-4ubuntu1 [60.0 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy/main amd64 libijs-0.35 amd64 0.35-15build2 [16.5 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy/main amd64 libjbig2dec0 amd64 0.19-3build2 [64.7 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgs9 amd64 9.55.0~dfsg1-0ubuntu5.6 [5,031 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libkpathsea6 amd64 2021.20210626.59705-1ubuntu0.2 [60.4 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy/main amd64 libwoff1 amd64 1.0.2-1build4 [45.2 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy/universe amd64 dvisvgm amd64 2.13.1-1 [1,221 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-lmodern all 2.004.5-6.1 [4,532 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-noto-mono all 20201225-1build1 [397 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-texgyre all 20180621-3.1 [10.2 MB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libapache-pom-java all 18-1 [4,720 B]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libcommons-parent-java all 43-1 [10.8 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libcommons-logging-java all 1.2-2 [60.3 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy/main amd64 libfontenc1 amd64 1:1.1.4-1build3 [14.7 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libptexenc1 amd64 2021.20210626.59705-1ubuntu0.2 [39.1 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu jammy/main amd64 rubygems-integration all 1.18 [5,336 B]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 ruby3.0 amd64 3.0.2-7ubuntu2.5 [50.1 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu jammy/main amd64 ruby-rubygems all 3.3.5-2 [228 kB]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu jammy/main amd64 ruby amd64 1:3.0~exp1 [5,100 B]\n",
            "Get:26 http://archive.ubuntu.com/ubuntu jammy/main amd64 rake all 13.0.6-2 [61.7 kB]\n",
            "Get:27 http://archive.ubuntu.com/ubuntu jammy/main amd64 ruby-net-telnet all 0.1.1-2 [12.6 kB]\n",
            "Get:28 http://archive.ubuntu.com/ubuntu jammy/universe amd64 ruby-webrick all 1.7.0-3 [51.8 kB]\n",
            "Get:29 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 ruby-xmlrpc all 0.3.2-1ubuntu0.1 [24.9 kB]\n",
            "Get:30 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libruby3.0 amd64 3.0.2-7ubuntu2.5 [5,113 kB]\n",
            "Get:31 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libsynctex2 amd64 2021.20210626.59705-1ubuntu0.2 [55.6 kB]\n",
            "Get:32 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libteckit0 amd64 2.5.11+ds1-1 [421 kB]\n",
            "Get:33 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libtexlua53 amd64 2021.20210626.59705-1ubuntu0.2 [120 kB]\n",
            "Get:34 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libtexluajit2 amd64 2021.20210626.59705-1ubuntu0.2 [267 kB]\n",
            "Get:35 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libzzip-0-13 amd64 0.13.72+dfsg.1-1.1 [27.0 kB]\n",
            "Get:36 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-encodings all 1:1.0.5-0ubuntu2 [578 kB]\n",
            "Get:37 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-utils amd64 1:7.7+6build2 [94.6 kB]\n",
            "Get:38 http://archive.ubuntu.com/ubuntu jammy/universe amd64 lmodern all 2.004.5-6.1 [9,471 kB]\n",
            "Get:39 http://archive.ubuntu.com/ubuntu jammy/universe amd64 preview-latex-style all 12.2-1ubuntu1 [185 kB]\n",
            "Get:40 http://archive.ubuntu.com/ubuntu jammy/main amd64 t1utils amd64 1.41-4build2 [61.3 kB]\n",
            "Get:41 http://archive.ubuntu.com/ubuntu jammy/universe amd64 teckit amd64 2.5.11+ds1-1 [699 kB]\n",
            "Get:42 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tex-gyre all 20180621-3.1 [6,209 kB]\n",
            "Get:43 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 texlive-binaries amd64 2021.20210626.59705-1ubuntu0.2 [9,860 kB]\n",
            "Get:44 http://archive.ubuntu.com/ubuntu jammy/universe amd64 texlive-base all 2021.20220204-1 [21.0 MB]\n",
            "Get:45 http://archive.ubuntu.com/ubuntu jammy/universe amd64 texlive-fonts-recommended all 2021.20220204-1 [4,972 kB]\n",
            "Get:46 http://archive.ubuntu.com/ubuntu jammy/universe amd64 texlive-latex-base all 2021.20220204-1 [1,128 kB]\n",
            "Get:47 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libfontbox-java all 1:1.8.16-2 [207 kB]\n",
            "Get:48 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libpdfbox-java all 1:1.8.16-2 [5,199 kB]\n",
            "Get:49 http://archive.ubuntu.com/ubuntu jammy/universe amd64 texlive-latex-recommended all 2021.20220204-1 [14.4 MB]\n",
            "Get:50 http://archive.ubuntu.com/ubuntu jammy/universe amd64 texlive-pictures all 2021.20220204-1 [8,720 kB]\n",
            "Get:51 http://archive.ubuntu.com/ubuntu jammy/universe amd64 texlive-latex-extra all 2021.20220204-1 [13.9 MB]\n",
            "Get:52 http://archive.ubuntu.com/ubuntu jammy/universe amd64 texlive-plain-generic all 2021.20220204-1 [27.5 MB]\n",
            "Get:53 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tipa all 2:1.3-21 [2,967 kB]\n",
            "Get:54 http://archive.ubuntu.com/ubuntu jammy/universe amd64 texlive-xetex all 2021.20220204-1 [12.4 MB]\n",
            "Fetched 182 MB in 5s (36.8 MB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 54.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package fonts-droid-fallback.\n",
            "(Reading database ... 121918 files and directories currently installed.)\n",
            "Preparing to unpack .../00-fonts-droid-fallback_1%3a6.0.1r16-1.1build1_all.deb ...\n",
            "Unpacking fonts-droid-fallback (1:6.0.1r16-1.1build1) ...\n",
            "Selecting previously unselected package fonts-lato.\n",
            "Preparing to unpack .../01-fonts-lato_2.0-2.1_all.deb ...\n",
            "Unpacking fonts-lato (2.0-2.1) ...\n",
            "Selecting previously unselected package poppler-data.\n",
            "Preparing to unpack .../02-poppler-data_0.4.11-1_all.deb ...\n",
            "Unpacking poppler-data (0.4.11-1) ...\n",
            "Selecting previously unselected package tex-common.\n",
            "Preparing to unpack .../03-tex-common_6.17_all.deb ...\n",
            "Unpacking tex-common (6.17) ...\n",
            "Selecting previously unselected package fonts-urw-base35.\n",
            "Preparing to unpack .../04-fonts-urw-base35_20200910-1_all.deb ...\n",
            "Unpacking fonts-urw-base35 (20200910-1) ...\n",
            "Selecting previously unselected package libgs9-common.\n",
            "Preparing to unpack .../05-libgs9-common_9.55.0~dfsg1-0ubuntu5.6_all.deb ...\n",
            "Unpacking libgs9-common (9.55.0~dfsg1-0ubuntu5.6) ...\n",
            "Selecting previously unselected package libidn12:amd64.\n",
            "Preparing to unpack .../06-libidn12_1.38-4ubuntu1_amd64.deb ...\n",
            "Unpacking libidn12:amd64 (1.38-4ubuntu1) ...\n",
            "Selecting previously unselected package libijs-0.35:amd64.\n",
            "Preparing to unpack .../07-libijs-0.35_0.35-15build2_amd64.deb ...\n",
            "Unpacking libijs-0.35:amd64 (0.35-15build2) ...\n",
            "Selecting previously unselected package libjbig2dec0:amd64.\n",
            "Preparing to unpack .../08-libjbig2dec0_0.19-3build2_amd64.deb ...\n",
            "Unpacking libjbig2dec0:amd64 (0.19-3build2) ...\n",
            "Selecting previously unselected package libgs9:amd64.\n",
            "Preparing to unpack .../09-libgs9_9.55.0~dfsg1-0ubuntu5.6_amd64.deb ...\n",
            "Unpacking libgs9:amd64 (9.55.0~dfsg1-0ubuntu5.6) ...\n",
            "Selecting previously unselected package libkpathsea6:amd64.\n",
            "Preparing to unpack .../10-libkpathsea6_2021.20210626.59705-1ubuntu0.2_amd64.deb ...\n",
            "Unpacking libkpathsea6:amd64 (2021.20210626.59705-1ubuntu0.2) ...\n",
            "Selecting previously unselected package libwoff1:amd64.\n",
            "Preparing to unpack .../11-libwoff1_1.0.2-1build4_amd64.deb ...\n",
            "Unpacking libwoff1:amd64 (1.0.2-1build4) ...\n",
            "Selecting previously unselected package dvisvgm.\n",
            "Preparing to unpack .../12-dvisvgm_2.13.1-1_amd64.deb ...\n",
            "Unpacking dvisvgm (2.13.1-1) ...\n",
            "Selecting previously unselected package fonts-lmodern.\n",
            "Preparing to unpack .../13-fonts-lmodern_2.004.5-6.1_all.deb ...\n",
            "Unpacking fonts-lmodern (2.004.5-6.1) ...\n",
            "Selecting previously unselected package fonts-noto-mono.\n",
            "Preparing to unpack .../14-fonts-noto-mono_20201225-1build1_all.deb ...\n",
            "Unpacking fonts-noto-mono (20201225-1build1) ...\n",
            "Selecting previously unselected package fonts-texgyre.\n",
            "Preparing to unpack .../15-fonts-texgyre_20180621-3.1_all.deb ...\n",
            "Unpacking fonts-texgyre (20180621-3.1) ...\n",
            "Selecting previously unselected package libapache-pom-java.\n",
            "Preparing to unpack .../16-libapache-pom-java_18-1_all.deb ...\n",
            "Unpacking libapache-pom-java (18-1) ...\n",
            "Selecting previously unselected package libcommons-parent-java.\n",
            "Preparing to unpack .../17-libcommons-parent-java_43-1_all.deb ...\n",
            "Unpacking libcommons-parent-java (43-1) ...\n",
            "Selecting previously unselected package libcommons-logging-java.\n",
            "Preparing to unpack .../18-libcommons-logging-java_1.2-2_all.deb ...\n",
            "Unpacking libcommons-logging-java (1.2-2) ...\n",
            "Selecting previously unselected package libfontenc1:amd64.\n",
            "Preparing to unpack .../19-libfontenc1_1%3a1.1.4-1build3_amd64.deb ...\n",
            "Unpacking libfontenc1:amd64 (1:1.1.4-1build3) ...\n",
            "Selecting previously unselected package libptexenc1:amd64.\n",
            "Preparing to unpack .../20-libptexenc1_2021.20210626.59705-1ubuntu0.2_amd64.deb ...\n",
            "Unpacking libptexenc1:amd64 (2021.20210626.59705-1ubuntu0.2) ...\n",
            "Selecting previously unselected package rubygems-integration.\n",
            "Preparing to unpack .../21-rubygems-integration_1.18_all.deb ...\n",
            "Unpacking rubygems-integration (1.18) ...\n",
            "Selecting previously unselected package ruby3.0.\n",
            "Preparing to unpack .../22-ruby3.0_3.0.2-7ubuntu2.5_amd64.deb ...\n",
            "Unpacking ruby3.0 (3.0.2-7ubuntu2.5) ...\n",
            "Selecting previously unselected package ruby-rubygems.\n",
            "Preparing to unpack .../23-ruby-rubygems_3.3.5-2_all.deb ...\n",
            "Unpacking ruby-rubygems (3.3.5-2) ...\n",
            "Selecting previously unselected package ruby.\n",
            "Preparing to unpack .../24-ruby_1%3a3.0~exp1_amd64.deb ...\n",
            "Unpacking ruby (1:3.0~exp1) ...\n",
            "Selecting previously unselected package rake.\n",
            "Preparing to unpack .../25-rake_13.0.6-2_all.deb ...\n",
            "Unpacking rake (13.0.6-2) ...\n",
            "Selecting previously unselected package ruby-net-telnet.\n",
            "Preparing to unpack .../26-ruby-net-telnet_0.1.1-2_all.deb ...\n",
            "Unpacking ruby-net-telnet (0.1.1-2) ...\n",
            "Selecting previously unselected package ruby-webrick.\n",
            "Preparing to unpack .../27-ruby-webrick_1.7.0-3_all.deb ...\n",
            "Unpacking ruby-webrick (1.7.0-3) ...\n",
            "Selecting previously unselected package ruby-xmlrpc.\n",
            "Preparing to unpack .../28-ruby-xmlrpc_0.3.2-1ubuntu0.1_all.deb ...\n",
            "Unpacking ruby-xmlrpc (0.3.2-1ubuntu0.1) ...\n",
            "Selecting previously unselected package libruby3.0:amd64.\n",
            "Preparing to unpack .../29-libruby3.0_3.0.2-7ubuntu2.5_amd64.deb ...\n",
            "Unpacking libruby3.0:amd64 (3.0.2-7ubuntu2.5) ...\n",
            "Selecting previously unselected package libsynctex2:amd64.\n",
            "Preparing to unpack .../30-libsynctex2_2021.20210626.59705-1ubuntu0.2_amd64.deb ...\n",
            "Unpacking libsynctex2:amd64 (2021.20210626.59705-1ubuntu0.2) ...\n",
            "Selecting previously unselected package libteckit0:amd64.\n",
            "Preparing to unpack .../31-libteckit0_2.5.11+ds1-1_amd64.deb ...\n",
            "Unpacking libteckit0:amd64 (2.5.11+ds1-1) ...\n",
            "Selecting previously unselected package libtexlua53:amd64.\n",
            "Preparing to unpack .../32-libtexlua53_2021.20210626.59705-1ubuntu0.2_amd64.deb ...\n",
            "Unpacking libtexlua53:amd64 (2021.20210626.59705-1ubuntu0.2) ...\n",
            "Selecting previously unselected package libtexluajit2:amd64.\n",
            "Preparing to unpack .../33-libtexluajit2_2021.20210626.59705-1ubuntu0.2_amd64.deb ...\n",
            "Unpacking libtexluajit2:amd64 (2021.20210626.59705-1ubuntu0.2) ...\n",
            "Selecting previously unselected package libzzip-0-13:amd64.\n",
            "Preparing to unpack .../34-libzzip-0-13_0.13.72+dfsg.1-1.1_amd64.deb ...\n",
            "Unpacking libzzip-0-13:amd64 (0.13.72+dfsg.1-1.1) ...\n",
            "Selecting previously unselected package xfonts-encodings.\n",
            "Preparing to unpack .../35-xfonts-encodings_1%3a1.0.5-0ubuntu2_all.deb ...\n",
            "Unpacking xfonts-encodings (1:1.0.5-0ubuntu2) ...\n",
            "Selecting previously unselected package xfonts-utils.\n",
            "Preparing to unpack .../36-xfonts-utils_1%3a7.7+6build2_amd64.deb ...\n",
            "Unpacking xfonts-utils (1:7.7+6build2) ...\n",
            "Selecting previously unselected package lmodern.\n",
            "Preparing to unpack .../37-lmodern_2.004.5-6.1_all.deb ...\n",
            "Unpacking lmodern (2.004.5-6.1) ...\n",
            "Selecting previously unselected package preview-latex-style.\n",
            "Preparing to unpack .../38-preview-latex-style_12.2-1ubuntu1_all.deb ...\n",
            "Unpacking preview-latex-style (12.2-1ubuntu1) ...\n",
            "Selecting previously unselected package t1utils.\n",
            "Preparing to unpack .../39-t1utils_1.41-4build2_amd64.deb ...\n",
            "Unpacking t1utils (1.41-4build2) ...\n",
            "Selecting previously unselected package teckit.\n",
            "Preparing to unpack .../40-teckit_2.5.11+ds1-1_amd64.deb ...\n",
            "Unpacking teckit (2.5.11+ds1-1) ...\n",
            "Selecting previously unselected package tex-gyre.\n",
            "Preparing to unpack .../41-tex-gyre_20180621-3.1_all.deb ...\n",
            "Unpacking tex-gyre (20180621-3.1) ...\n",
            "Selecting previously unselected package texlive-binaries.\n",
            "Preparing to unpack .../42-texlive-binaries_2021.20210626.59705-1ubuntu0.2_amd64.deb ...\n",
            "Unpacking texlive-binaries (2021.20210626.59705-1ubuntu0.2) ...\n",
            "Selecting previously unselected package texlive-base.\n",
            "Preparing to unpack .../43-texlive-base_2021.20220204-1_all.deb ...\n",
            "Unpacking texlive-base (2021.20220204-1) ...\n",
            "Selecting previously unselected package texlive-fonts-recommended.\n",
            "Preparing to unpack .../44-texlive-fonts-recommended_2021.20220204-1_all.deb ...\n",
            "Unpacking texlive-fonts-recommended (2021.20220204-1) ...\n",
            "Selecting previously unselected package texlive-latex-base.\n",
            "Preparing to unpack .../45-texlive-latex-base_2021.20220204-1_all.deb ...\n",
            "Unpacking texlive-latex-base (2021.20220204-1) ...\n",
            "Selecting previously unselected package libfontbox-java.\n",
            "Preparing to unpack .../46-libfontbox-java_1%3a1.8.16-2_all.deb ...\n",
            "Unpacking libfontbox-java (1:1.8.16-2) ...\n",
            "Selecting previously unselected package libpdfbox-java.\n",
            "Preparing to unpack .../47-libpdfbox-java_1%3a1.8.16-2_all.deb ...\n",
            "Unpacking libpdfbox-java (1:1.8.16-2) ...\n",
            "Selecting previously unselected package texlive-latex-recommended.\n",
            "Preparing to unpack .../48-texlive-latex-recommended_2021.20220204-1_all.deb ...\n",
            "Unpacking texlive-latex-recommended (2021.20220204-1) ...\n",
            "Selecting previously unselected package texlive-pictures.\n",
            "Preparing to unpack .../49-texlive-pictures_2021.20220204-1_all.deb ...\n",
            "Unpacking texlive-pictures (2021.20220204-1) ...\n",
            "Selecting previously unselected package texlive-latex-extra.\n",
            "Preparing to unpack .../50-texlive-latex-extra_2021.20220204-1_all.deb ...\n",
            "Unpacking texlive-latex-extra (2021.20220204-1) ...\n",
            "Selecting previously unselected package texlive-plain-generic.\n",
            "Preparing to unpack .../51-texlive-plain-generic_2021.20220204-1_all.deb ...\n",
            "Unpacking texlive-plain-generic (2021.20220204-1) ...\n",
            "Selecting previously unselected package tipa.\n",
            "Preparing to unpack .../52-tipa_2%3a1.3-21_all.deb ...\n",
            "Unpacking tipa (2:1.3-21) ...\n",
            "Selecting previously unselected package texlive-xetex.\n",
            "Preparing to unpack .../53-texlive-xetex_2021.20220204-1_all.deb ...\n",
            "Unpacking texlive-xetex (2021.20220204-1) ...\n",
            "Setting up fonts-lato (2.0-2.1) ...\n",
            "Setting up fonts-noto-mono (20201225-1build1) ...\n",
            "Setting up libwoff1:amd64 (1.0.2-1build4) ...\n",
            "Setting up libtexlua53:amd64 (2021.20210626.59705-1ubuntu0.2) ...\n",
            "Setting up libijs-0.35:amd64 (0.35-15build2) ...\n",
            "Setting up libtexluajit2:amd64 (2021.20210626.59705-1ubuntu0.2) ...\n",
            "Setting up libfontbox-java (1:1.8.16-2) ...\n",
            "Setting up rubygems-integration (1.18) ...\n",
            "Setting up libzzip-0-13:amd64 (0.13.72+dfsg.1-1.1) ...\n",
            "Setting up fonts-urw-base35 (20200910-1) ...\n",
            "Setting up poppler-data (0.4.11-1) ...\n",
            "Setting up tex-common (6.17) ...\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78.)\n",
            "debconf: falling back to frontend: Readline\n",
            "update-language: texlive-base not installed and configured, doing nothing!\n",
            "Setting up libfontenc1:amd64 (1:1.1.4-1build3) ...\n",
            "Setting up libjbig2dec0:amd64 (0.19-3build2) ...\n",
            "Setting up libteckit0:amd64 (2.5.11+ds1-1) ...\n",
            "Setting up libapache-pom-java (18-1) ...\n",
            "Setting up ruby-net-telnet (0.1.1-2) ...\n",
            "Setting up xfonts-encodings (1:1.0.5-0ubuntu2) ...\n",
            "Setting up t1utils (1.41-4build2) ...\n",
            "Setting up libidn12:amd64 (1.38-4ubuntu1) ...\n",
            "Setting up fonts-texgyre (20180621-3.1) ...\n",
            "Setting up libkpathsea6:amd64 (2021.20210626.59705-1ubuntu0.2) ...\n",
            "Setting up ruby-webrick (1.7.0-3) ...\n",
            "Setting up fonts-lmodern (2.004.5-6.1) ...\n",
            "Setting up fonts-droid-fallback (1:6.0.1r16-1.1build1) ...\n",
            "Setting up ruby-xmlrpc (0.3.2-1ubuntu0.1) ...\n",
            "Setting up libsynctex2:amd64 (2021.20210626.59705-1ubuntu0.2) ...\n",
            "Setting up libgs9-common (9.55.0~dfsg1-0ubuntu5.6) ...\n",
            "Setting up teckit (2.5.11+ds1-1) ...\n",
            "Setting up libpdfbox-java (1:1.8.16-2) ...\n",
            "Setting up libgs9:amd64 (9.55.0~dfsg1-0ubuntu5.6) ...\n",
            "Setting up preview-latex-style (12.2-1ubuntu1) ...\n",
            "Setting up libcommons-parent-java (43-1) ...\n",
            "Setting up dvisvgm (2.13.1-1) ...\n",
            "Setting up libcommons-logging-java (1.2-2) ...\n",
            "Setting up xfonts-utils (1:7.7+6build2) ...\n",
            "Setting up libptexenc1:amd64 (2021.20210626.59705-1ubuntu0.2) ...\n",
            "Setting up texlive-binaries (2021.20210626.59705-1ubuntu0.2) ...\n",
            "update-alternatives: using /usr/bin/xdvi-xaw to provide /usr/bin/xdvi.bin (xdvi.bin) in auto mode\n",
            "update-alternatives: using /usr/bin/bibtex.original to provide /usr/bin/bibtex (bibtex) in auto mode\n",
            "Setting up lmodern (2.004.5-6.1) ...\n",
            "Setting up texlive-base (2021.20220204-1) ...\n",
            "/usr/bin/ucfr\n",
            "/usr/bin/ucfr\n",
            "/usr/bin/ucfr\n",
            "/usr/bin/ucfr\n",
            "mktexlsr: Updating /var/lib/texmf/ls-R-TEXLIVEDIST... \n",
            "mktexlsr: Updating /var/lib/texmf/ls-R-TEXMFMAIN... \n",
            "mktexlsr: Updating /var/lib/texmf/ls-R... \n",
            "mktexlsr: Done.\n",
            "tl-paper: setting paper size for dvips to a4: /var/lib/texmf/dvips/config/config-paper.ps\n",
            "tl-paper: setting paper size for dvipdfmx to a4: /var/lib/texmf/dvipdfmx/dvipdfmx-paper.cfg\n",
            "tl-paper: setting paper size for xdvi to a4: /var/lib/texmf/xdvi/XDvi-paper\n",
            "tl-paper: setting paper size for pdftex to a4: /var/lib/texmf/tex/generic/tex-ini-files/pdftexconfig.tex\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78.)\n",
            "debconf: falling back to frontend: Readline\n",
            "Setting up tex-gyre (20180621-3.1) ...\n",
            "Setting up texlive-plain-generic (2021.20220204-1) ...\n",
            "Setting up texlive-latex-base (2021.20220204-1) ...\n",
            "Setting up texlive-latex-recommended (2021.20220204-1) ...\n",
            "Setting up texlive-pictures (2021.20220204-1) ...\n",
            "Setting up texlive-fonts-recommended (2021.20220204-1) ...\n",
            "Setting up tipa (2:1.3-21) ...\n",
            "Setting up texlive-latex-extra (2021.20220204-1) ...\n",
            "Setting up texlive-xetex (2021.20220204-1) ...\n",
            "Setting up rake (13.0.6-2) ...\n",
            "Setting up libruby3.0:amd64 (3.0.2-7ubuntu2.5) ...\n",
            "Setting up ruby3.0 (3.0.2-7ubuntu2.5) ...\n",
            "Setting up ruby (1:3.0~exp1) ...\n",
            "Setting up ruby-rubygems (3.3.5-2) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "Processing triggers for tex-common (6.17) ...\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78.)\n",
            "debconf: falling back to frontend: Readline\n",
            "Running updmap-sys. This may take some time... done.\n",
            "Running mktexlsr /var/lib/texmf ... done.\n",
            "Building format(s) --all.\n",
            "\tThis may take some time... done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# First MANUALLY download locally to the working directory\n",
        "# Convert the downloaded file to an HTML file\n",
        "!jupyter nbconvert --to PDF \"RAMP_CaseStudy_12May2024_v31.ipynb\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "7mKMhSOIIv7f",
        "outputId": "72e7663b-8772-4065-e540-df37aa329174"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NbConvertApp] Converting notebook RAMP_CaseStudy_12May2024_v31.ipynb to PDF\n",
            "/usr/local/lib/python3.10/dist-packages/nbconvert/filters/datatypefilter.py:41: UserWarning: Your element with mimetype(s) dict_keys(['text/html']) is not able to be represented.\n",
            "  warn(\n",
            "[NbConvertApp] Writing 178109 bytes to notebook.tex\n",
            "[NbConvertApp] Building PDF\n",
            "[NbConvertApp] Running xelatex 3 times: ['xelatex', 'notebook.tex', '-quiet']\n",
            "[NbConvertApp] Running bibtex 1 time: ['bibtex', 'notebook']\n",
            "[NbConvertApp] WARNING | bibtex had problems, most likely because there were no citations\n",
            "[NbConvertApp] PDF successfully created\n",
            "[NbConvertApp] Writing 163015 bytes to RAMP_CaseStudy_12May2024_v31.pdf\n"
          ]
        }
      ]
    }
  ]
}