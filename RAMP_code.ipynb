{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "authorship_tag": "ABX9TyMzWi1puz0KQdOwauXI1ilq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alexiamhe93/RAMP_method/blob/main/RAMP_code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The Recursive Adjustment of Measurement Protocols (RAMP) method: Case study code for replication\n",
        "\n",
        "This Python notebook is used to replicate the results of the paper titled:\n",
        "\n",
        "\"Recursive Adjustment of Measurement Protocols (RAMP) method for developing and validating text classifiers\"\n",
        "\n",
        "The RAMP method has three stages:\n",
        "1. A manual classification stage: Used to generate a coded dataset for a target construct.\n",
        "2. A computational classification stage: Uses the coded dataset to develop a text classifier.\n",
        "3. An evaluation stage: Identify and evaluate surprises and outliers in classifier development, with the goal of identifying construct and content validity issues\n",
        "\n",
        "Each stage has an *input*, *throughput*, and *output* phase.\n",
        "\n",
        "Manual stage:\n",
        "1. Input: *write initial codebook*, *gather data*\n",
        "2. Throughput: repeat on training data - *Train coders*, *code sample data*, *inter-rater reliability on sample*, *troubleshoot misclassifications*, *adjust codebook*\n",
        "3. Output: *finalize notebook*, *code full dataset*, *inter-rater reliability on shared subset*\n",
        "\n",
        "Computational stage:\n",
        "1. Input: *define protocol parameters*, *split dataset into training and validation*\n",
        "2. Throughput: Repeat on training data - *run model on sample data*, *troubleshoot misclassifications*, *change protocol parameters*\n",
        "3. Output: *Finalize protocol*, *Run on validation data*\n",
        "\n",
        "Evaluation stage:\n",
        "1. Input: *identify disagreements from manual stage*, *identify misclassifications from computational stage*,\n",
        "2. Throughput: *evaluate disagreements*, *evaluate misclassifications*\n",
        "3. Output: *Discuss problems of content and construct validity*\n",
        "\n",
        "\n",
        "The notebook applies RAMP to a case study on measuring misunderstandings in online dialogue data.\n",
        "\n",
        "The notebook is structured in terms of the RAMP stages, with an additional first section for initializing all the relevant functions and objects.\n",
        "\n",
        "The notebook was designed using Google Colab on an Nvidia T4 GPU (free with log-in). The code works locally but all dependencies from the \"Load packages\" will have to be installed."
      ],
      "metadata": {
        "id": "Ht0MhYw8ggZq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0. Initiate notebook"
      ],
      "metadata": {
        "id": "0NK-mCzVj-K0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0.1 Install and load packages"
      ],
      "metadata": {
        "id": "l1uWzkOxkBaG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3xHt9VHlgZMO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "1373a369-b862-4d4f-fa2d-bfc7572f1d4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ktrain\n",
            "  Downloading ktrain-0.41.3.tar.gz (25.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25.3/25.3 MB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from ktrain) (1.2.2)\n",
            "Requirement already satisfied: matplotlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from ktrain) (3.7.1)\n",
            "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from ktrain) (2.0.3)\n",
            "Requirement already satisfied: fastprogress>=0.1.21 in /usr/local/lib/python3.10/dist-packages (from ktrain) (1.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from ktrain) (2.31.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from ktrain) (1.4.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from ktrain) (24.0)\n",
            "Collecting langdetect (from ktrain)\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: jieba in /usr/local/lib/python3.10/dist-packages (from ktrain) (0.42.1)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.10/dist-packages (from ktrain) (3.3.2)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from ktrain) (5.2.0)\n",
            "Collecting syntok>1.3.3 (from ktrain)\n",
            "  Downloading syntok-1.4.4-py3-none-any.whl (24 kB)\n",
            "Collecting tika (from ktrain)\n",
            "  Downloading tika-2.6.0.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from ktrain) (4.41.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from ktrain) (0.1.99)\n",
            "Collecting keras_bert>=0.86.0 (from ktrain)\n",
            "  Downloading keras-bert-0.89.0.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting whoosh (from ktrain)\n",
            "  Downloading Whoosh-2.7.4-py2.py3-none-any.whl (468 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.8/468.8 kB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras_bert>=0.86.0->ktrain) (1.25.2)\n",
            "Collecting keras-transformer==0.40.0 (from keras_bert>=0.86.0->ktrain)\n",
            "  Downloading keras-transformer-0.40.0.tar.gz (9.7 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting keras-pos-embd==0.13.0 (from keras-transformer==0.40.0->keras_bert>=0.86.0->ktrain)\n",
            "  Downloading keras-pos-embd-0.13.0.tar.gz (5.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting keras-multi-head==0.29.0 (from keras-transformer==0.40.0->keras_bert>=0.86.0->ktrain)\n",
            "  Downloading keras-multi-head-0.29.0.tar.gz (13 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting keras-layer-normalization==0.16.0 (from keras-transformer==0.40.0->keras_bert>=0.86.0->ktrain)\n",
            "  Downloading keras-layer-normalization-0.16.0.tar.gz (3.9 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting keras-position-wise-feed-forward==0.8.0 (from keras-transformer==0.40.0->keras_bert>=0.86.0->ktrain)\n",
            "  Downloading keras-position-wise-feed-forward-0.8.0.tar.gz (4.1 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting keras-embed-sim==0.10.0 (from keras-transformer==0.40.0->keras_bert>=0.86.0->ktrain)\n",
            "  Downloading keras-embed-sim-0.10.0.tar.gz (3.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting keras-self-attention==0.51.0 (from keras-multi-head==0.29.0->keras-transformer==0.40.0->keras_bert>=0.86.0->ktrain)\n",
            "  Downloading keras-self-attention-0.51.0.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->ktrain) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->ktrain) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->ktrain) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->ktrain) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->ktrain) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->ktrain) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->ktrain) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->ktrain) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->ktrain) (2024.1)\n",
            "Requirement already satisfied: regex>2016 in /usr/local/lib/python3.10/dist-packages (from syntok>1.3.3->ktrain) (2023.12.25)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from langdetect->ktrain) (1.16.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->ktrain) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->ktrain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->ktrain) (2024.2.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->ktrain) (1.11.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->ktrain) (3.5.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tika->ktrain) (67.7.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers->ktrain) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers->ktrain) (0.23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers->ktrain) (6.0.1)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers->ktrain) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers->ktrain) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers->ktrain) (4.66.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers->ktrain) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers->ktrain) (4.11.0)\n",
            "Building wheels for collected packages: ktrain, keras_bert, keras-transformer, keras-embed-sim, keras-layer-normalization, keras-multi-head, keras-pos-embd, keras-position-wise-feed-forward, keras-self-attention, langdetect, tika\n",
            "  Building wheel for ktrain (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ktrain: filename=ktrain-0.41.3-py3-none-any.whl size=25316960 sha256=0fbbba16df050b739661dad6f283e8af3ac71365060503daf9238c27055d01c9\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/76/11/5b953090eebf531f660948a30cd26e70260619f6480f186a5a\n",
            "  Building wheel for keras_bert (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras_bert: filename=keras_bert-0.89.0-py3-none-any.whl size=33500 sha256=1b3e7bcc9bc85521ed548cff8751937326152110c96417a9f0fde3f773a1a7df\n",
            "  Stored in directory: /root/.cache/pip/wheels/89/0c/04/646b6fdf6375911b42c8d540a8a3fda8d5d77634e5dcbe7b26\n",
            "  Building wheel for keras-transformer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-transformer: filename=keras_transformer-0.40.0-py3-none-any.whl size=12286 sha256=4aa903df3b6a0014f976ebb1ffc52610e5f5b6668883ebfc29486da102c3a91c\n",
            "  Stored in directory: /root/.cache/pip/wheels/f2/cb/22/75a0ad376129177f7c95c0d91331a18f5368fd657f4035ba7c\n",
            "  Building wheel for keras-embed-sim (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-embed-sim: filename=keras_embed_sim-0.10.0-py3-none-any.whl size=3944 sha256=bed95414f55827fa5e39b0d8a1aeb2787f8dca2172697fdf5d8b806350524891\n",
            "  Stored in directory: /root/.cache/pip/wheels/82/32/c7/fd35d0d1b840a6c7cbd4343f808d10d0f7b87d271a4dbe796f\n",
            "  Building wheel for keras-layer-normalization (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-layer-normalization: filename=keras_layer_normalization-0.16.0-py3-none-any.whl size=4654 sha256=a04103bed4f309f5b1acccd39adf816f5ec36ff46b15bbb4710b3261d4f33118\n",
            "  Stored in directory: /root/.cache/pip/wheels/ed/3a/4b/21db23c0cc56c4b219616e181f258eb7c57d36cc5d056fae9a\n",
            "  Building wheel for keras-multi-head (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-multi-head: filename=keras_multi_head-0.29.0-py3-none-any.whl size=14976 sha256=c27192bf8eae6ed51661dd9d083a7f33436e6da6227c5dc6425c8ef650b5a2f1\n",
            "  Stored in directory: /root/.cache/pip/wheels/cb/23/4b/06d7ae21714f70fcc25b48f972cc8e5e7f4b6b764a038b509d\n",
            "  Building wheel for keras-pos-embd (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-pos-embd: filename=keras_pos_embd-0.13.0-py3-none-any.whl size=6945 sha256=d5adaf48e81a8a29b338b9780c1043f162f32d8d35b8341ff3a79f26372b8805\n",
            "  Stored in directory: /root/.cache/pip/wheels/78/07/1b/b1ca47b6ac338554b75c8f52c54e6a2bfbe1b07d79579979a4\n",
            "  Building wheel for keras-position-wise-feed-forward (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-position-wise-feed-forward: filename=keras_position_wise_feed_forward-0.8.0-py3-none-any.whl size=4969 sha256=ffccec34e8b05158a38ff78b1402ddcf0c0ceac50f5cbd449b7a82ec41056ccc\n",
            "  Stored in directory: /root/.cache/pip/wheels/c1/6a/04/d1706a53b23b2cb5f9a0a76269bf87925daa1bca09eac01b21\n",
            "  Building wheel for keras-self-attention (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-self-attention: filename=keras_self_attention-0.51.0-py3-none-any.whl size=18894 sha256=b35fbcce6ff7f650b1ada0543591839226774b0e0e3f74cd79d01eb025c0fa3d\n",
            "  Stored in directory: /root/.cache/pip/wheels/b8/f7/24/607b483144fb9c47b4ba2c5fba6b68e54aeee2d5bf6c05302e\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993227 sha256=24bd8530678e70371c55ee5ac12e7a8d0d3c279b39fdb14454c14b7ccfe380da\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/03/7d/59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\n",
            "  Building wheel for tika (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tika: filename=tika-2.6.0-py3-none-any.whl size=32621 sha256=a3e95e60223d994cb34c9c765ecd18e19af5a4c481c62145a1c7d37030ca6d37\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/71/c7/b757709531121b1700cffda5b6b0d4aad095fb507ec84316d0\n",
            "Successfully built ktrain keras_bert keras-transformer keras-embed-sim keras-layer-normalization keras-multi-head keras-pos-embd keras-position-wise-feed-forward keras-self-attention langdetect tika\n",
            "Installing collected packages: whoosh, syntok, langdetect, keras-self-attention, keras-position-wise-feed-forward, keras-pos-embd, keras-layer-normalization, keras-embed-sim, tika, keras-multi-head, keras-transformer, keras_bert, ktrain\n",
            "Successfully installed keras-embed-sim-0.10.0 keras-layer-normalization-0.16.0 keras-multi-head-0.29.0 keras-pos-embd-0.13.0 keras-position-wise-feed-forward-0.8.0 keras-self-attention-0.51.0 keras-transformer-0.40.0 keras_bert-0.89.0 ktrain-0.41.3 langdetect-1.0.9 syntok-1.4.4 tika-2.6.0 whoosh-2.7.4\n",
            "Collecting https://github.com/amaiya/eli5-tf/archive/refs/heads/master.zip\n",
            "  Downloading https://github.com/amaiya/eli5-tf/archive/refs/heads/master.zip\n",
            "\u001b[2K     \u001b[32m|\u001b[0m \u001b[32m6.9 MB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: attrs>17.1.0 in /usr/local/lib/python3.10/dist-packages (from eli5==0.13.0) (23.2.0)\n",
            "Requirement already satisfied: jinja2>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from eli5==0.13.0) (3.1.4)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from eli5==0.13.0) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from eli5==0.13.0) (1.11.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from eli5==0.13.0) (1.16.0)\n",
            "Requirement already satisfied: scikit-learn>=0.20 in /usr/local/lib/python3.10/dist-packages (from eli5==0.13.0) (1.2.2)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from eli5==0.13.0) (0.20.3)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from eli5==0.13.0) (0.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=3.0.0->eli5==0.13.0) (2.1.5)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20->eli5==0.13.0) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20->eli5==0.13.0) (3.5.0)\n",
            "Building wheels for collected packages: eli5\n",
            "  Building wheel for eli5 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for eli5: filename=eli5-0.13.0-py2.py3-none-any.whl size=108158 sha256=3d0db9e40b7c47098451bd70e852ff4cc54c4f2736570a6f04bf6d2e8a28be16\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-370unaza/wheels/0b/14/54/23c07f7254b733dc3daac99ba1fda60e30f1b2991b3b8ee0bf\n",
            "Successfully built eli5\n",
            "Installing collected packages: eli5\n",
            "Successfully installed eli5-0.13.0\n",
            "Collecting openai\n",
            "  Downloading openai-1.30.4-py3-none-any.whl (320 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.6/320.6 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.2)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.30.4\n",
            "Collecting textstat\n",
            "  Downloading textstat-0.7.3-py3-none-any.whl (105 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.1/105.1 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyphen (from textstat)\n",
            "  Downloading pyphen-0.15.0-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyphen, textstat\n",
            "Successfully installed pyphen-0.15.0 textstat-0.7.3\n"
          ]
        }
      ],
      "source": [
        "# For Supervised classifier\n",
        "!pip install ktrain\n",
        "# For revealing under the classifier black box\n",
        "!pip install https://github.com/amaiya/eli5-tf/archive/refs/heads/master.zip\n",
        "# For LLM classifier\n",
        "!pip install openai\n",
        "# For summary statistics\n",
        "!pip install textstat"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# General use packages\n",
        "import requests, zipfile, io, os, psutil, random, time\n",
        "import torch\n",
        "import pandas as pd\n",
        "# This deactivates a warning from Pandas that frequently prints\n",
        "pd.options.mode.chained_assignment = None  # default='warn'\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "from tqdm import tqdm\n",
        "# For descriptive statistics\n",
        "from textstat.textstat import textstatistics\n",
        "import re\n",
        "# Performance evaluations for binary classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_recall_curve,roc_auc_score,classification_report,auc,confusion_matrix\n",
        "# for rule-based classification\n",
        "import spacy\n",
        "from spacy.matcher import Matcher\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "# for supervised classification\n",
        "import ktrain\n",
        "from ktrain import text\n",
        "# for LLM classification\n",
        "import openai\n",
        "\n",
        "#for troubleshooting\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from wordcloud import WordCloud\n",
        "from nltk import agreement\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "# Plotting\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams['figure.dpi'] = 120\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KJGGvaNX8hPy",
        "outputId": "506e09f0-32fa-43a1-acf5-d0b79e647212"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check system GPU (recommended if possible)\n",
        "# CPU cores\n",
        "num_cpu_cores = os.cpu_count()\n",
        "print(f\"Number of CPU cores: {num_cpu_cores}\")\n",
        "# GPU details\n",
        "if torch.cuda.is_available():\n",
        "    gpu_name = torch.cuda.get_device_name(0)\n",
        "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / (1024 ** 3)  # in GB\n",
        "    print(f\"GPU Name: {gpu_name}\")\n",
        "    print(f\"GPU Memory: {gpu_memory:.2f} GB\")\n",
        "else:\n",
        "    print(\"No GPU available.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mT0gjhlD8lsl",
        "outputId": "3eb09627-e4e4-4fce-f1d7-289ebac9bc1d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of CPU cores: 2\n",
            "GPU Name: Tesla T4\n",
            "GPU Memory: 14.75 GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load in openai keys for producing topic model names\n",
        "oai_k = \"your-API-key-here\"\n",
        "openai.organization = \"your-organization-key-here\" #if applicable\n",
        "openai.api_key = oai_k\n",
        "os.environ['OPENAI_API_KEY'] = oai_k"
      ],
      "metadata": {
        "id": "ifDAz7zT9Co3"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0.2 Download data and pre-trained BERT model\n",
        "\n",
        "All the data for replication (<50mb) is accessed through a GitHub link and the pre-trained BERT model (1.03GB) from dropbox"
      ],
      "metadata": {
        "id": "9NbRD_KokEAA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download data from GitHub"
      ],
      "metadata": {
        "id": "fUH0ETcp-P6p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download empirical data\n",
        "r = requests.get( 'https://github.com/alexiamhe93/RAMP_method/blob/main/Dataset/data.zip?raw=true')\n",
        "z = zipfile.ZipFile(io.BytesIO(r.content))\n",
        "z.extractall()\n",
        "\n",
        "# Load train (70%) and test (30%)\n",
        "try:\n",
        "  train = pd.read_csv(\"data/Train.csv\")\n",
        "  validation = pd.read_csv(\"data/Validation.csv\")\n",
        "  St1Through = pd.read_csv(\"data/RAMP_Stage1.csv\")\n",
        "  St2Through = pd.read_csv(\"data/RAMP_Stage2.csv\")\n",
        "  out = pd.read_csv(\"data/RAMP_Stage3.csv\")\n",
        "except:\n",
        "  train = pd.read_csv(\"Train.csv\")\n",
        "  validation = pd.read_csv(\"Validation.csv\")\n",
        "  St1Through = pd.read_csv(\"RAMP_Stage1.csv\")\n",
        "  St2Through = pd.read_csv(\"RAMP_Stage2.csv\")\n",
        "  out = pd.read_csv(\"RAMP_Stage3.csv\")"
      ],
      "metadata": {
        "id": "nTn-uqu8kIS4"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Validation n before cleaning: {len(validation)} texts\")\n",
        "# Delete any duplicates\n",
        "validation = validation.dropna(subset=[\"text\"])\n",
        "validation = validation.drop_duplicates(subset=\"text\")\n",
        "print(f\"Validation n after cleaning: {len(validation)} texts\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--VnA5j2IhmM",
        "outputId": "126126e3-e69e-4d2c-9e7a-eb7b0f232f40"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation n before cleaning: 6599 texts\n",
            "Validation n after cleaning: 6420 texts\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We removed 179 sentences that are duplicates or empty values."
      ],
      "metadata": {
        "id": "wWk0GcaOJP7I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download model from Dropbox (can take some time if internet is slow - aprox 1.1GB - downloads weights and pre-processing)"
      ],
      "metadata": {
        "id": "3GFOZlP3-Eg-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O supervised_model.zip https://www.dropbox.com/scl/fi/5wtuor1ag1gktg6eukqwr/supervised_model.zip?rlkey=nfwxyataobjzt708m3gf27o3s&st=cz5r9lq0&dl=0 --quiet\n",
        "!unzip supervised_model.zip"
      ],
      "metadata": {
        "id": "i6URMHD9-GOY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b7bcdcd-2324-4d54-fca5-bf6ccaf2e33e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: --quiet: command not found\n",
            "--2024-05-28 14:10:48--  https://www.dropbox.com/scl/fi/5wtuor1ag1gktg6eukqwr/supervised_model.zip?rlkey=nfwxyataobjzt708m3gf27o3s\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.2.18, 2620:100:6021:18::a27d:4112\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.2.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://ucf454bd7436c249d411c5b11013.dl.dropboxusercontent.com/cd/0/inline/CTxsf1JuSbORrdjhVQW8UImMzm7CNPPmhiQqe6wHicwtQY-p1sdqZxJVHIehgVMxnKsM6n0gwxdkTuNTk-uOgjQB_oFlsCQbTcoxWh42WT4vqCm2ma25EX_IUK2-eJMcklbLl5SxJ4JrldUTH_sq7gWO/file# [following]\n",
            "--2024-05-28 14:10:50--  https://ucf454bd7436c249d411c5b11013.dl.dropboxusercontent.com/cd/0/inline/CTxsf1JuSbORrdjhVQW8UImMzm7CNPPmhiQqe6wHicwtQY-p1sdqZxJVHIehgVMxnKsM6n0gwxdkTuNTk-uOgjQB_oFlsCQbTcoxWh42WT4vqCm2ma25EX_IUK2-eJMcklbLl5SxJ4JrldUTH_sq7gWO/file\n",
            "Resolving ucf454bd7436c249d411c5b11013.dl.dropboxusercontent.com (ucf454bd7436c249d411c5b11013.dl.dropboxusercontent.com)... 162.125.2.15, 2620:100:6017:15::a27d:20f\n",
            "Connecting to ucf454bd7436c249d411c5b11013.dl.dropboxusercontent.com (ucf454bd7436c249d411c5b11013.dl.dropboxusercontent.com)|162.125.2.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /cd/0/inline2/CTyt39fCnLEK9kWJmu9Ls6tUJCtxT2WsWUJvHEw7jQKiLBE-Y_SyWCKmk8_y37lQVclOrmgD0tSL0AznA8JWrWGCjwFJvzdYkWAUtLI7Z9gn8K6Co93GXKgm5RFhGCeaOUTTWEH-l53MIj0Z_znqcuAkQKa7C1yc5FvRufv9V004tnbybPPf5SjZrlRftv7ZeltG44PHtM_xASC9By2auYtxbkXhzXAolhUdTITUmBUZqR77Cmx23omV3tDft0dMeg5722cbNYIif1zCokJD-EExEk8B6yoShG3xzWel4sJmlOxXHuxTaWJ-1v1CYarbgBbCtVOuKSZBS4Tj7uTHyRapI15sBr7LT7XGKfShy17WLQQHSTLjKHCa_-HB5LKhHlw/file [following]\n",
            "--2024-05-28 14:10:50--  https://ucf454bd7436c249d411c5b11013.dl.dropboxusercontent.com/cd/0/inline2/CTyt39fCnLEK9kWJmu9Ls6tUJCtxT2WsWUJvHEw7jQKiLBE-Y_SyWCKmk8_y37lQVclOrmgD0tSL0AznA8JWrWGCjwFJvzdYkWAUtLI7Z9gn8K6Co93GXKgm5RFhGCeaOUTTWEH-l53MIj0Z_znqcuAkQKa7C1yc5FvRufv9V004tnbybPPf5SjZrlRftv7ZeltG44PHtM_xASC9By2auYtxbkXhzXAolhUdTITUmBUZqR77Cmx23omV3tDft0dMeg5722cbNYIif1zCokJD-EExEk8B6yoShG3xzWel4sJmlOxXHuxTaWJ-1v1CYarbgBbCtVOuKSZBS4Tj7uTHyRapI15sBr7LT7XGKfShy17WLQQHSTLjKHCa_-HB5LKhHlw/file\n",
            "Reusing existing connection to ucf454bd7436c249d411c5b11013.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1107245706 (1.0G) [application/zip]\n",
            "Saving to: ‘supervised_model.zip’\n",
            "\n",
            "supervised_model.zi 100%[===================>]   1.03G  83.1MB/s    in 12s     \n",
            "\n",
            "2024-05-28 14:11:04 (84.6 MB/s) - ‘supervised_model.zip’ saved [1107245706/1107245706]\n",
            "\n",
            "Archive:  supervised_model.zip\n",
            "   creating: supervised_model/\n",
            "  inflating: __MACOSX/._supervised_model  \n",
            "  inflating: supervised_model/tf_model.preproc  \n",
            "  inflating: __MACOSX/supervised_model/._tf_model.preproc  \n",
            "  inflating: supervised_model/tf_model.h5  \n",
            "  inflating: __MACOSX/supervised_model/._tf_model.h5  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0.3 Load classes and functios\n",
        "\n",
        "The notebook uses two class objects for performing most of the operations across the three stages of RAMP. The classifier object is used to calculate inter-rater reliability (manual stage); run a dictionary word classifier (computational stage), a supervised classifier (computational stage) and an LLM classifier (computational stage); calculate accuracy metrics (computational stage); access disagreements and misclassifications (evaluation stage)."
      ],
      "metadata": {
        "id": "BHYCi1z_kFl3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Classifier object and functions\n",
        "\n",
        "This class does the heavy lifting for the notebook. It integrates the three types of classifier (rule-based, supervised, LLM) into one function so that there is a common language across the examples.\n",
        "\n",
        "The classifier produces a development report, including the following variables:\n",
        "\n",
        "1. `TP`,`TN`,`FP`,`FN`: number of true positives, true negatives, false positives, and false negatives\n",
        "2. `Precision`: TP/TP+FP - ratio of true positives to all predicted positive class. Reported for positive class only.\n",
        "3. `Recall`: TP/TP+FN – ratio of true positives to all true positive class.Reported for positive class only.\n",
        "4. `F1_avg`: Weighted harmonic mean of precision and recall (all classes - this F1 is not the precision and recall reported).\n",
        "5. `F1_var`: Weighted harmonic mean of precision and recall for positive class.\n",
        "6. `AUC_ROC`: Area under the receiving operating characteristic (ROC) curve\n",
        "7. `AUC_PR`: Area under the precision and recall curve.\n",
        "\n",
        "Each metric highlights a different aspect of the classifier's performance. For instance, the weighted F1 (`F1_avg`) is sensitive to imbalanced classes. For misunderstandings, the class is imbalanced (8% of turns are misunderstandings) so the area under the precision recall curve (`AUC_PR`) is more appropriate."
      ],
      "metadata": {
        "id": "Os-aIAYQDBZq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Classifier:\n",
        "  def __init__(self, texts, true_scores):\n",
        "    \"\"\"\n",
        "    Initialize the Classifier class with texts and true scores.\n",
        "    \"\"\"\n",
        "    self.texts = texts\n",
        "    self.true_scores = true_scores\n",
        "    self.train_size = len(texts)\n",
        "    self.type_ = None\n",
        "    self.pred_scores = []\n",
        "    self.nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "  def add_rule_based_terms(self, terms, pattern_type):\n",
        "    \"\"\"\n",
        "    Configure terms and pattern matching type for rule-based classifiers.\n",
        "    \"\"\"\n",
        "    self.terms = terms\n",
        "    if pattern_type == \"pattern\":\n",
        "        self.type_ = \"rule-based-1\"\n",
        "    elif pattern_type == \"lemma\":\n",
        "        self.type_ = \"rule-based-2\"\n",
        "    else:\n",
        "        raise ValueError(\"Invalid pattern type specified.\")\n",
        "  def classify_with_spacy_pattern(self):\n",
        "    \"\"\"\n",
        "    Classify texts using SpaCy's pattern matcher based on predefined terms.\n",
        "    \"\"\"\n",
        "    matcher = Matcher(self.nlp.vocab)\n",
        "    for term in self.terms:\n",
        "        matcher.add(term[\"label\"], [term[\"pattern\"]])\n",
        "    self.pred_scores = [bool(matcher(self.nlp(text))) for text in self.texts]\n",
        "  def classify_with_spacy_lemma(self):\n",
        "    \"\"\"\n",
        "    Classify texts by checking if any lemmas from the terms are in the texts.\n",
        "    \"\"\"\n",
        "    lemma_doc = self.nlp(\" \".join(self.terms))\n",
        "    lemma_set = set(token.lemma_ for token in lemma_doc)\n",
        "    self.pred_scores = [bool(set(token.lemma_ for token in self.nlp(text.lower())) & lemma_set) for text in self.texts]\n",
        "  def add_SML_classifier(self, predictor, **kwargs):\n",
        "    \"\"\"\n",
        "    Configure the supervised machine learning classifier with a predictor and training parameters.\n",
        "    \"\"\"\n",
        "    self.type_ = \"supervised\"\n",
        "    self.predictor = predictor\n",
        "    self.sml_params = kwargs\n",
        "    print(\"Supervised ML classifier configured with parameters:\", kwargs)\n",
        "  def classify_with_SML(self):\n",
        "    \"\"\"\n",
        "    Perform classification using the configured supervised machine learning predictor.\n",
        "    \"\"\"\n",
        "    preds = self.predictor.predict(self.texts)\n",
        "    self.pred_scores = [0 if \"not\" in pred.lower() else 1 for pred in preds]\n",
        "\n",
        "  def add_few_shot_classifier(self, GPTmodel, prompt, role):\n",
        "    \"\"\"\n",
        "    Configure the few-shot classifier with a GPT model, prompt template, and user/system roles.\n",
        "    \"\"\"\n",
        "    self.type_ = \"LLM\"\n",
        "    self.GPTmodel = GPTmodel\n",
        "    self.prompt = prompt\n",
        "    self.role = role\n",
        "    self.cost = 0\n",
        "    self.total_tokens = 0\n",
        "    self.LLMScores = []\n",
        "\n",
        "  def gptActualCost(self, response):\n",
        "    \"\"\"\n",
        "    Calculates the GPT cost for different models\n",
        "    \"\"\"\n",
        "    engine = self.GPTmodel\n",
        "    total_tokens=response.usage.total_tokens\n",
        "    total_tokens_1k_units = total_tokens/1000\n",
        "\n",
        "    if engine=='gpt-3.5-turbo':\n",
        "        cost=total_tokens_1k_units*0.0005\n",
        "    elif engine=='gpt-4-turbo':\n",
        "        cost=total_tokens_1k_units*0.01\n",
        "    elif engine=='gpt-4o':\n",
        "        cost=total_tokens_1k_units*0.005\n",
        "    elif engine=='gpt-4-32k':\n",
        "        cost=total_tokens_1k_units*0.12\n",
        "    else:\n",
        "        print('getCost error: engine not found')\n",
        "        return\n",
        "    return cost, total_tokens\n",
        "\n",
        "  def get_llm_response(self,messages,temperature=0, max_tokens = 100, max_attempts = 3):\n",
        "    '''\n",
        "    Function that takes messages format for ChatGPT input and returns the response text.\n",
        "    '''\n",
        "    GPTmodel = self.GPTmodel\n",
        "    for attempt in range(0, max_attempts):\n",
        "      try:\n",
        "        #. request timeout ADD IN\n",
        "        response = openai.chat.completions.create(model=GPTmodel, messages = messages, temperature=temperature, max_tokens=max_tokens)\n",
        "        response_text = response.choices[0].message.content\n",
        "        self.LLMScores.append(response_text)\n",
        "        response_cost, token_count = self.gptActualCost(response)\n",
        "        self.cost += response_cost\n",
        "        self.total_tokens += token_count\n",
        "        break  # If analysis was successful, break out of the retry loop\n",
        "      except Exception as e:\n",
        "        print(f\"Error processing text on attempt {attempt+1}: {e}\")\n",
        "        if attempt + 1 == max_attempts:\n",
        "          print(f\"Skipping text after {max_attempts} failed attempts.\")\n",
        "          response_text\n",
        "    return response_text\n",
        "  def define_messages(self, text_to_classify):\n",
        "    '''\n",
        "    Function for creating a basic messages format from a prompt, a role, and a text to classify (all strings)\n",
        "    '''\n",
        "    prompt = self.prompt\n",
        "    role = self.role\n",
        "    prompt = prompt.format(text_to_classify)\n",
        "    messages = [{'role': 'system', 'content': role},\n",
        "                {'role': 'user', 'content' : prompt}]\n",
        "    return messages\n",
        "  def convert_llm_scores_binary(self, return_scores = False):\n",
        "    '''\n",
        "    Function for converting a string \"Yes\" or \"No\" into binary format - used for the clarification requests\n",
        "    '''\n",
        "    llm_scores = self.pred_scores\n",
        "    new_scores = []\n",
        "    for s in llm_scores:\n",
        "      if \"yes\" in s.lower():\n",
        "        new_scores.append(1)\n",
        "      else:\n",
        "        new_scores.append(0)\n",
        "    if not return_scores:\n",
        "      self.pred_scores = new_scores\n",
        "    else:\n",
        "      return new_scores\n",
        "\n",
        "  def classify_with_fewshot(self,  max_tokens = 100, max_attempts = 3, temperature = 0):\n",
        "    '''\n",
        "    Function for running a prompt over a series of texts (expects a list)\n",
        "    '''\n",
        "    prompt = self.prompt\n",
        "    role = self.role\n",
        "    input_texts = self.texts\n",
        "    GPTmodel = self.GPTmodel\n",
        "    scores = []\n",
        "    for txt in tqdm(input_texts):\n",
        "      message = self.define_messages(txt)\n",
        "      try:\n",
        "        response = self.get_llm_response(message,temperature=temperature,\n",
        "                                        max_tokens=max_tokens, max_attempts=max_attempts)\n",
        "      except:\n",
        "        response = \"Error in response\"\n",
        "      scores.append(response)\n",
        "    self.pred_scores = scores\n",
        "    self.convert_llm_scores_binary()\n",
        "\n",
        "  def run_classifier(self):\n",
        "    \"\"\"\n",
        "    Execute the classifier based on the configured type.\n",
        "    \"\"\"\n",
        "    if self.type_ == \"rule-based-1\":\n",
        "        self.classify_with_spacy_pattern()\n",
        "    elif self.type_ == \"rule-based-2\":\n",
        "        self.classify_with_spacy_lemma()\n",
        "    elif self.type_ == \"supervised\":\n",
        "        self.classify_with_SML()\n",
        "    elif self.type_ == \"LLM\":\n",
        "        self.classify_with_fewshot()\n",
        "        cost = self.cost\n",
        "        total_tokens = self.total_tokens\n",
        "        avg_tokens = self.total_tokens / self.train_size\n",
        "        print(f\"This run cost {cost:.2f}$ for {total_tokens} tokens. Average tokens: {avg_tokens:.2f}\")\n",
        "    else:\n",
        "        raise ValueError(\"Classifier type is not configured.\")\n",
        "\n",
        "  def get_model_report(self, display=True):\n",
        "    \"\"\"\n",
        "    Generate and display or return the classification report and metrics.\n",
        "    \"\"\"\n",
        "    cm = confusion_matrix(self.true_scores, self.pred_scores)\n",
        "    report = classification_report(self.true_scores, self.pred_scores, output_dict=True)\n",
        "    precision, recall, thresholds = precision_recall_curve(self.true_scores, self.pred_scores)\n",
        "    auc_pr = auc(recall, precision)\n",
        "    auc_roc = roc_auc_score(self.true_scores, self.pred_scores)\n",
        "\n",
        "    if display:\n",
        "        print(f'AUC-PR: {auc_pr:.2f}\\n')\n",
        "        print(f'AUC-ROC: {auc_roc:.2f}\\n')\n",
        "        print(classification_report(self.true_scores, self.pred_scores, output_dict=False))\n",
        "    else:\n",
        "        return {\n",
        "            \"precision\": report['1']['precision'],\n",
        "            \"recall\": report['1']['recall'],\n",
        "            \"auc_pr\": auc_pr,\n",
        "            \"auc_roc\": auc_roc,\n",
        "            \"f1_avg\": report['weighted avg']['f1-score'],\n",
        "            \"f1_var\": report['1']['f1-score']\n",
        "        }\n",
        "  def get_misclassification(self, return_all = False):\n",
        "    \"\"\"\n",
        "    Function to fetch misclassifications\n",
        "    \"\"\"\n",
        "    df = pd.DataFrame({\"text\":self.texts,\"true\":self.true_scores,\n",
        "                       \"pred\":self.pred_scores})\n",
        "    # Function to classify each row\n",
        "    def classify_row(row):\n",
        "      if row['true'] == 1 and row['pred'] == 1:\n",
        "        return 'TP'\n",
        "      elif row['true'] == 0 and row['pred'] == 1:\n",
        "        return 'FP'\n",
        "      elif row['true'] == 1 and row['pred'] == 0:\n",
        "        return 'FN'\n",
        "      elif row['true'] == 0 and row['pred'] == 0:\n",
        "        return 'TN'\n",
        "    df['Classification'] = df.apply(classify_row, axis=1)\n",
        "    if return_all:\n",
        "      return df\n",
        "    else:\n",
        "      return df[df[\"Classification\"].isin([\"FP\",\"FN\"])]\n",
        "\n",
        "  def preprocess_text(self, text):\n",
        "    \"\"\"\n",
        "    Function to process the texts.\n",
        "    \"\"\"\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    words = nltk.word_tokenize(text)\n",
        "    cleaned_text = [lemmatizer.lemmatize(word.lower()) for word in words if word.isalnum() and word.lower() not in stop_words]\n",
        "    return ' '.join(cleaned_text)\n",
        "\n",
        "  def plot_misclassifications(self, df, FN_FP=\"FN\"):\n",
        "    \"\"\"\n",
        "    Function to generate a wordcloud\n",
        "    \"\"\"\n",
        "    df['cleaned_text'] = df['text'].apply(self.preprocess_text)\n",
        "    if FN_FP == \"FN\":\n",
        "      print(\"Word Cloud for False Negatives:\")\n",
        "      texts = \" \".join(df[df['Classification'] == 'FN']['cleaned_text'])\n",
        "    else:\n",
        "      print(\"Word Cloud for False Positives:\")\n",
        "      texts = \" \".join(df[df['Classification'] == 'FP']['cleaned_text'])\n",
        "    wordcloud = WordCloud(width = 800, height = 400, background_color ='white').generate(texts)\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.imshow(wordcloud, interpolation='bilinear')\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "7_s_-YmtkItR"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Plotting and summary object\n",
        "\n",
        "This class is used throughout to do various plotting and statistical functions."
      ],
      "metadata": {
        "id": "5Y5mJpC0JtQZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TextDataStats:\n",
        "  def __init__(self, df, text_column=\"text\", binary_column=\"Misunderstanding\",\n",
        "               IRR_columns = [\"Coder1\",\"Coder2\",\"Coder3\",\"Coder4\"],\n",
        "               group_column = \"Round\"):\n",
        "    self.df = df\n",
        "    self.text_column = text_column\n",
        "    self.binary_column = binary_column\n",
        "    self.IRR_columns = IRR_columns\n",
        "    self.group_column = group_column\n",
        "\n",
        "  def preprocess_text(self):\n",
        "    \"\"\"\n",
        "    Extracts words and sentences from the text, counts them and adds to the dataframe.\n",
        "    \"\"\"\n",
        "    self.df['words'] = self.df[self.text_column].apply(lambda x: re.findall(r'\\b\\w+\\b', x.lower()))\n",
        "    self.df['word_count'] = self.df['words'].apply(len)\n",
        "\n",
        "  def basic_stats(self):\n",
        "    \"\"\"\n",
        "    Computes basic statistics for overall and grouped data.\n",
        "    \"\"\"\n",
        "    self.preprocess_text()\n",
        "\n",
        "    # General stats\n",
        "    general_stats = self.df.describe(include=[np.number]).loc[['mean', 'std', 'min', '50%', 'max'], ['word_count']]\n",
        "    general_stats.rename(index={'50%': 'median'}, inplace=True)\n",
        "    # Grouped stats by binary column\n",
        "    grouped_stats = self.df.groupby(self.binary_column).agg({\n",
        "        'word_count': ['mean', 'median', 'std', 'min', 'max'],\n",
        "    })\n",
        "    # Binary column distribution\n",
        "    binary_dist = self.df[self.binary_column].value_counts(normalize=True).to_frame('distribution')\n",
        "    return general_stats.round(2), grouped_stats.round(2), binary_dist.round(2)\n",
        "\n",
        "  def BasicReport(self):\n",
        "    \"\"\"\n",
        "    Generates a report combining all statistics in a readable text format.\n",
        "    \"\"\"\n",
        "    general_stats, grouped_stats, binary_dist = self.basic_stats()\n",
        "\n",
        "    # Creating a structured text report\n",
        "    report = \"Text Data Statistics Report\\n\\n\"\n",
        "    report += \"General Statistics:\\n\"\n",
        "    report += general_stats.to_string() + \"\\n\\n\"\n",
        "\n",
        "    report += \"Statistics by Binary Column:\\n\"\n",
        "    for name, group in self.df.groupby(self.binary_column):\n",
        "        report += f\"\\nGroup: {name}\\n\"\n",
        "        report += grouped_stats.loc[name].to_string() + \"\\n\"\n",
        "    return report\n",
        "\n",
        "  def get_IRR(self,df):\n",
        "    \"\"\"\n",
        "    Calculates Krippendorff's Alpha and overall agreement\n",
        "    \"\"\"\n",
        "    df = df[self.IRR_columns]\n",
        "    df = df.astype(int)\n",
        "    IRR_out = []\n",
        "    for i, row in df.iterrows():\n",
        "      for k in list(df.columns):\n",
        "        IRR_out.append([k, str(i), row[k]])\n",
        "    ratingtask = agreement.AnnotationTask(data=IRR_out)\n",
        "    ags = ratingtask.avg_Ao()\n",
        "    krip_alpha = ratingtask.alpha()\n",
        "    return ags, krip_alpha\n",
        "\n",
        "  def IRRreport(self):\n",
        "    \"\"\"\n",
        "    Prints Krippendorff's Alpha and the overall agreement for each round of coding\n",
        "    \"\"\"\n",
        "    df = self.df.sort_values([self.group_column])\n",
        "    rounds = df[self.group_column].unique()\n",
        "    agr = []\n",
        "    alp = []\n",
        "    ss = []\n",
        "    for i in rounds:\n",
        "      tdf = df[df[self.group_column] == i]\n",
        "      ss.append(len(tdf))\n",
        "      agr_,alp_ = self.get_IRR(tdf)\n",
        "      agr.append(agr_)\n",
        "      alp.append(alp_)\n",
        "    return pd.DataFrame({\"Round\":[\"Round\" + str(i) for i in rounds],\n",
        "                         \"Sample size\":ss,\n",
        "                         \"Agreement\":agr,\"Krippendorff's Alpha\":alp})\n",
        "\n",
        "  def get_disagreements(self,n=10, return_df = False):\n",
        "    \"\"\"\n",
        "    Prints n disagreements for the IRR results\n",
        "    \"\"\"\n",
        "    df = self.df\n",
        "    disag = []\n",
        "    for i, row in df.iterrows():\n",
        "      x = 0\n",
        "      for coder in self.IRR_columns:\n",
        "        x += row[coder]\n",
        "      disag.append(x)\n",
        "    df[\"disag\"] = disag\n",
        "    ncoders = len(self.IRR_columns)\n",
        "    df = df[df[\"disag\"] < ncoders]\n",
        "    df = df[df[\"disag\"] > 0]\n",
        "    if return_df:\n",
        "      return df.round(2)\n",
        "    else:\n",
        "      sdf = df.sample(n)\n",
        "      for s in sdf.text:\n",
        "        print(\"----------\")\n",
        "        print(s)\n",
        "\n",
        "  def get_misclassifications(self, n=5, return_all=False):\n",
        "    \"\"\"\n",
        "    Function to report on the misclassifications across all three classifiers.\n",
        "    \"\"\"\n",
        "    df = self.df\n",
        "\n",
        "    def classify(row):\n",
        "      base, fs, sup = int(row[\"Manual\"]), int(row[\"LLM\"]), int(row[\"supervised\"])\n",
        "      if sup == base:\n",
        "        return \"TP (All)\" if base == 1 else \"TN (All)\" if fs == base else \"FP (LLM)\" if base == 0 else \"FN (LLM)\"\n",
        "      else:\n",
        "        return \"FN (supervised)\" if fs == base and base == 1 else \"FP (supervised)\" if fs == base else \"FP (All)\" if base == 1 else \"FN (All)\"\n",
        "\n",
        "    df[\"FN_FP\"] = df.apply(classify, axis=1)\n",
        "\n",
        "    if return_all:\n",
        "      return df\n",
        "\n",
        "    misclassifications = {\n",
        "        \"FP (All)\": df[df.FN_FP == \"FP (All)\"].text.to_list(),\n",
        "        \"FP (supervised)\": df[df.FN_FP == \"FP (supervised)\"].text.to_list(),\n",
        "        \"FP (LLM)\": df[df.FN_FP == \"FP (LLM)\"].text.to_list(),\n",
        "        \"FN (All)\": df[df.FN_FP == \"FN (All)\"].text.to_list(),\n",
        "        \"FN (supervised)\": df[df.FN_FP == \"FN (supervised)\"].text.to_list(),\n",
        "        \"FN (LLM)\": df[df.FN_FP == \"FN (LLM)\"].text.to_list()\n",
        "    }\n",
        "\n",
        "    for key, value in misclassifications.items():\n",
        "      print(f\"--- {key.replace('_', ' ')} count: -- {len(value)}\")\n",
        "\n",
        "    print(f\"\\nPrinting {n} examples of each classifier type.\\n\")\n",
        "\n",
        "    for key, value in misclassifications.items():\n",
        "      print(f\"------ {key.replace('_', ' ').upper()} ------\")\n",
        "      for example in value[:n]:\n",
        "        print(f\"- {example}\")\n",
        "      print(\"--------\")\n",
        "\n",
        "\n",
        "  def RAMP_plot(self, x_col, y_col, group_col,\n",
        "                pastel_colors = ['#77B5FE', '#FF6961', '#B19CD9'],\n",
        "                title=\"\", width=800, height=500, line_width=2, line_opacity=0.5):\n",
        "    \"\"\"\n",
        "    Creates a connected scatter plot\n",
        "    \"\"\"\n",
        "    # Ensure the group column is categorized\n",
        "    self.df[group_col] = self.df[group_col].astype('category')\n",
        "\n",
        "    # Create the connected scatter plot using Plotly Express with lines\n",
        "    scatter_fig = px.line(self.df, x=x_col, y=y_col, color=group_col,\n",
        "                          title=title, template='plotly_white',\n",
        "                          labels={x_col: x_col, y_col: y_col, group_col: group_col},\n",
        "                          markers=True,  # Include markers at data points\n",
        "                          color_discrete_sequence=pastel_colors)  # Apply the pastel color palette\n",
        "\n",
        "    # Iterate through each group to add dashed lines connecting min and max x values\n",
        "    for group, group_df in self.df.groupby(group_col):\n",
        "        # Get minimum and maximum x values and their corresponding y values\n",
        "        min_x = group_df[x_col].min()\n",
        "        max_x = group_df[x_col].max()\n",
        "        min_y = group_df[group_df[x_col] == min_x][y_col].iloc[0]\n",
        "        max_y = group_df[group_df[x_col] == max_x][y_col].iloc[0]\n",
        "\n",
        "        # Find the index of the group's color in the palette\n",
        "        color_index = group_df[group_col].cat.codes.unique()[0] % len(pastel_colors)\n",
        "\n",
        "        # Add a dashed line to the scatter plot\n",
        "        scatter_fig.add_trace(go.Scatter(\n",
        "            x=[min_x, max_x],\n",
        "            y=[min_y, max_y],\n",
        "            mode='lines',\n",
        "            name=f'{group} - Range Line',\n",
        "            line=dict(color=pastel_colors[color_index], width=line_width, dash='dash'),\n",
        "            opacity=line_opacity,\n",
        "            showlegend=False))  # Hide this line from the legend\n",
        "\n",
        "    # Update layout and display the figure\n",
        "    scatter_fig.update_layout(title=title, width=width, height=height)\n",
        "    scatter_fig.show()\n"
      ],
      "metadata": {
        "id": "aW0xRPcIKELa"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Manual classification stage\n",
        "\n",
        "The first stage of RAMP is a manual coding stage, where a codebook is developed through the process of training coders and conducting small pilot inter-rater reliability studies. This section reports the inter-rater reliability of the throughput stage and the final inter-rater reliability on a shared dataset. The shared dataset was coded blind, with coders unaware of which sentences were being shared and which were exclusive to the individual."
      ],
      "metadata": {
        "id": "DMvNGUi-kJSW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1 Input:"
      ],
      "metadata": {
        "id": "iK_gyvGUkLiG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1.1 Data"
      ],
      "metadata": {
        "id": "e6Htv_uykRy-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "The raw dataset contains sentences from online dialogues, sampled from three sources:\n",
        "\n",
        "**Reddit conversations from 27 subreddits**.\n",
        "\n",
        "> This data was downloaded using the Reddit API by the authors.\n",
        "\n",
        "**Twitter Customer Support data** (Thought Vector & Axelbrooke, 2017).\n",
        "\n",
        "> This data was downloaded from: https://www.kaggle.com/datasets/thoughtvector/customer-support-on-twitter (Copyright: CC BY-NC-SA 4.0).\n",
        "\n",
        "**Wikipedia Talk Pages data**(Danescu-Niculescu-Mizil et al., 2012).\n",
        "\n",
        "> This data was downloaded using Cornell University's ConvoKit Python package (see: https://convokit.cornell.edu/documentation/wiki.html) (Copyright: CC BY 4.0)\n",
        "\n",
        "**Notes:**\n",
        "\n",
        "> All author names and sentences have been anonymized following ethical guidelines for the study.\n",
        "> As a further precaution, the sentences are shuffled and the source (e.g., Reddit, Twitter) removed from the dataframe."
      ],
      "metadata": {
        "id": "RoxsE1Uc8HFn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Manual coded dataset final size\n",
        "print(f\"Full dataset size: {len(train) + len(validation)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wj9RKsx-YHDC",
        "outputId": "b000a709-eb71-4296-c85e-9570eb4655f1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Full dataset size: 21815\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the IRR from the final round (validation)\n",
        "IRR_final = St1Through[St1Through[\"Round\"]==6]\n",
        "IRR_through = St1Through[St1Through[\"Round\"]!=6]"
      ],
      "metadata": {
        "id": "5VoWDNwBRgQt"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2 Throughput"
      ],
      "metadata": {
        "id": "zX-a78DVkbbi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inter rater reliability across rour rounds of coder training:"
      ],
      "metadata": {
        "id": "0B23lDDzWzNk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tds = TextDataStats(IRR_through)\n",
        "tds.IRRreport().round(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "RCQOxLqEDsQr",
        "outputId": "d0404ac4-84c6-494a-ddae-b949d6409433"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Round  Sample size  Agreement  Krippendorff's Alpha\n",
              "0  Round1          713       0.95                  0.57\n",
              "1  Round2         1228       0.97                  0.71\n",
              "2  Round3         1101       0.97                  0.72\n",
              "3  Round4          808       0.94                  0.78\n",
              "4  Round5          862       0.98                  0.76"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dccd4a9e-a06b-4141-873a-6e50efed2349\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Round</th>\n",
              "      <th>Sample size</th>\n",
              "      <th>Agreement</th>\n",
              "      <th>Krippendorff's Alpha</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Round1</td>\n",
              "      <td>713</td>\n",
              "      <td>0.95</td>\n",
              "      <td>0.57</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Round2</td>\n",
              "      <td>1228</td>\n",
              "      <td>0.97</td>\n",
              "      <td>0.71</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Round3</td>\n",
              "      <td>1101</td>\n",
              "      <td>0.97</td>\n",
              "      <td>0.72</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Round4</td>\n",
              "      <td>808</td>\n",
              "      <td>0.94</td>\n",
              "      <td>0.78</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Round5</td>\n",
              "      <td>862</td>\n",
              "      <td>0.98</td>\n",
              "      <td>0.76</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dccd4a9e-a06b-4141-873a-6e50efed2349')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-dccd4a9e-a06b-4141-873a-6e50efed2349 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-dccd4a9e-a06b-4141-873a-6e50efed2349');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9c985d91-c5cb-41ad-b6c7-23f0c4a16769\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9c985d91-c5cb-41ad-b6c7-23f0c4a16769')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9c985d91-c5cb-41ad-b6c7-23f0c4a16769 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"tds\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Round\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Round2\",\n          \"Round5\",\n          \"Round3\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sample size\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 214,\n        \"min\": 713,\n        \"max\": 1228,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1228,\n          862,\n          1101\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Agreement\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.016431676725154998,\n        \"min\": 0.94,\n        \"max\": 0.98,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.97,\n          0.98,\n          0.95\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Krippendorff's Alpha\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.08228000972289687,\n        \"min\": 0.57,\n        \"max\": 0.78,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.71,\n          0.76,\n          0.72\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that the Alpha gets progressively better. We ended the training and Round5 as the agreement diminishes from the previous round."
      ],
      "metadata": {
        "id": "iQJzLFKckjqe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.3 Output"
      ],
      "metadata": {
        "id": "hY6VX1eAkmlv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tds = TextDataStats(IRR_final)\n",
        "tds.IRRreport().round(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "t8A04avekqPi",
        "outputId": "cc552605-8826-4233-8348-6aac0c25caf5"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Round  Sample size  Agreement  Krippendorff's Alpha\n",
              "0  Round6         1610       0.98                  0.79"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-af7fc54f-be3d-4461-a3e7-3555edf7ce6f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Round</th>\n",
              "      <th>Sample size</th>\n",
              "      <th>Agreement</th>\n",
              "      <th>Krippendorff's Alpha</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Round6</td>\n",
              "      <td>1610</td>\n",
              "      <td>0.98</td>\n",
              "      <td>0.79</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-af7fc54f-be3d-4461-a3e7-3555edf7ce6f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-af7fc54f-be3d-4461-a3e7-3555edf7ce6f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-af7fc54f-be3d-4461-a3e7-3555edf7ce6f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"tds\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"Round\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Round6\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sample size\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 1610,\n        \"max\": 1610,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1610\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Agreement\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.98,\n        \"max\": 0.98,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.98\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Krippendorff's Alpha\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.79,\n        \"max\": 0.79,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.79\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is very good agreement (98%) with decent reliability (Krippendorff's Alpha  = 0.79). The high agreement is down to misunderstandings being very uncommon (8%). This means they are overrepresented by a pure agreement score.\n"
      ],
      "metadata": {
        "id": "SPSjO8BpXDkU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Computational stage"
      ],
      "metadata": {
        "id": "fivY_6dpkrZ8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1 Input"
      ],
      "metadata": {
        "id": "oYZCmJ-lkv6g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Information on the validation data = binary column is misunderstandings.\n",
        "tds = TextDataStats(validation)\n",
        "print(tds.BasicReport())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1HJN3au5YIyH",
        "outputId": "d300642f-d47a-4056-db2b-934266d8d843"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text Data Statistics Report\n",
            "\n",
            "General Statistics:\n",
            "        word_count\n",
            "mean         14.97\n",
            "std          11.71\n",
            "min           0.00\n",
            "median       12.00\n",
            "max         203.00\n",
            "\n",
            "Statistics by Binary Column:\n",
            "\n",
            "Group: 0\n",
            "word_count  mean       14.90\n",
            "            median     12.00\n",
            "            std        11.68\n",
            "            min         0.00\n",
            "            max       203.00\n",
            "\n",
            "Group: 1\n",
            "word_count  mean      15.82\n",
            "            median    12.00\n",
            "            std       12.09\n",
            "            min        2.00\n",
            "            max       80.00\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "These are the words for the misunderstanding dictionary rule-based classifier:"
      ],
      "metadata": {
        "id": "CUln424LEQSK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "terms = ['accord', 'acknowledge', 'actually', 'adjust', 'already', 'ambiguity',\n",
        "          'ambivalence', 'amend', 'angle', 'anomaly', 'apologize', 'approach',\n",
        "          'ask', 'assume', 'assumption', 'aware', 'awareness', 'baffle', 'befuddled',\n",
        "          'bewilderment', 'blunder', 'challenge', 'chat', 'cite',\n",
        "          'clarify', 'comprehend',  'concur', 'confirm', 'conflict',\n",
        "          'confuse', 'consensus', 'contradict', 'controversy', 'conversation',\n",
        "          'correct', 'debate', 'deceptive', 'deliberate', 'delusion', 'demonstrate',\n",
        "          'denial', 'detail', 'dialogue', 'disagree', 'disbelief', 'discombobulated',\n",
        "          'discord', 'discrepancy', 'discussion', 'disorientation', 'dispute',\n",
        "          'dissent', 'distortion', 'distrust', 'disturbance', 'doubt', 'edit',\n",
        "          'elaborate', 'elucidation', 'enlightened', 'equivocation', 'erroneous', 'error',\n",
        "          'examine', 'expand', 'explain', 'explication', 'exposition',\n",
        "          'expound', 'fallacy', 'false', 'fault', 'feedback', 'flaw', 'flummoxed',\n",
        "          'follow', 'gap', 'grasp', 'hear', 'highlight', 'how', 'hypothesis',\n",
        "          'ignorance', 'illusion', 'illustrate', 'imbalance', 'inaccuracy',\n",
        "          'incomprehension', 'incongruence', 'incorrect',\n",
        "          'informed', 'input', 'inquire', 'insight', 'interpret',\n",
        "          'interpretation', 'interrogate', 'investigate', 'justification',\n",
        "          'listen', 'mean', 'misacknowledge', 'misadvise',\n",
        "          'misalign', 'misaligned', 'misapply', 'misapprehend', 'misattribute',\n",
        "          'miscalculate', 'miscalibration', 'mischaracterize', 'misclassify',\n",
        "          'miscommunication', 'miscomprehend', 'misconceive', 'misconception',\n",
        "          'misconclude', 'misconstruction', 'misconstrue', 'misconstrued',\n",
        "          'miscontextualize', 'misconvey', 'misdiagnose', 'misdirect',\n",
        "          'misestimate', 'misfathom', 'misgauge', 'misgiving', 'mishandle',\n",
        "          'mishear', 'misinform', 'misinterpret',\n",
        "          'misjudge', 'misjudgment', 'mislead', 'mismanage', 'mismatch', 'misperceive',\n",
        "          'misplace', 'misportray', 'misread', 'misreport', 'misrepresentation',\n",
        "          'misstate', 'misstep', 'mistake', 'mistranslate','misunderstand', 'modify',\n",
        "          'muddle', 'nonconformity', 'nonplussed', 'objection', 'obscure', 'overlook',\n",
        "          'oversight','reinterpret', 'oversimplification', 'perceive',\n",
        "          'perplexity', 'perspective', 'presumption', 'probe', 'puzzle', 'puzzlement',\n",
        "          'query', 'question', 'quote', 'rationale', 'readdress', 'realize',\n",
        "          'reanalyze', 'reasoning', 'reassess', 'recognize', 'reconfirm', 'recontextualize',\n",
        "          'rectify', 'redress', 'reevaluate', 'reference', 'reiterate', 'rejection',\n",
        "          'rejoinder', 'reply', 'response', 'restate', 'rethink', 'retort', 'revise',\n",
        "          'said', 'saying', 'scrutinize', 'skepticism', 'slip', 'sorry', 'specify',\n",
        "          'speculation', 'standpoint', 'stumped', 'supposition', 'suspicion', 'unawareness',\n",
        "          'uncertainty', 'understand', 'unease', 'unpack', 'validate',\n",
        "          'verify', 'viewpoint', 'what', 'when', 'where', 'which', 'who', 'why',\n",
        "          \"wtf\", \"reflection\", \"delineate\", \"rebuttal\", \"synopsis\", \"evaluation\",\n",
        "          \"reconsider\", \"diverge\", \"introspection\", \"articulate\", \"review\", \"discern\",\n",
        "          \"analyze\", \"contravene\"]"
      ],
      "metadata": {
        "id": "iFGXqvH9kubG"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is the pre-trained BERT model for the supervised classifier:"
      ],
      "metadata": {
        "id": "YHkOiOmKEWBC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictor = ktrain.load_predictor('supervised_model')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JonSwZrcEV2M",
        "outputId": "b522d69d-db75-48ad-cc7f-90bce2ab190c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/initializers/initializers.py:120: UserWarning: The initializer GlorotNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initializer instance more than once.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is the prompt for the LLM classifier:"
      ],
      "metadata": {
        "id": "ZUFUiABGETYf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "role = \"\"\"\n",
        "*Role* You are a research assistant tasked with identifying whether a sentence indicates a misunderstanding.\n",
        "*Misunderstanding definition* A misunderstanding occurs during dialogue when one participant has an incorrect understanding of another’s perspective.\n",
        "\"\"\"\n",
        "prompt = \"\"\"\n",
        "There are two categories of misunderstanding:\n",
        "1. “Direct” misunderstandings. These occur when a participant evidences a misunderstanding of another participant’s point.\n",
        "2. “Felt” misunderstandings. These occur when a participant feels their previous turn was misunderstood by another participant.\n",
        "This is a non-exhaustive list of possible sentences indicating misunderstanding.\n",
        "1. Explicit statement: The sentence explicitly indicates the speaker doesn't understand another’s perspective (e.g., \"I don't get what you're trying to say about the dog\")\n",
        "2. Clarification question: The question seeks to clarify the other’s perspective (e.g., \"What do you mean?\")\n",
        "3. Request for confirmation: A question that seeks confirmation on the other’s understanding of the speaker’s previous turn(e.g., \"You really think that I meant all dogs?\")\n",
        "4. Correction of Other: Correcting another speaker’s misunderstanding of the present speaker’s previous turn(e.g., \"You've misunderstood my point\", “You don’t get it.”)\n",
        "5. Clarification or apology about speaker's intentions: Clarifying the meaning of what the speaker previously said (e.g., \"Sorry, I meant to say X\")\n",
        "6. Misunderstanding due to lack of response (e.g., \"Why did you change the subject?\")\n",
        "7. Editing a message at a later time: This is when a speaker in text-based dialogue comes back to edit their comment after the fact (e.g., \"EDIT\": That's what I said)\n",
        "Here are some examples of sentences indicating misunderstandings:\n",
        "- Jane, that article was what I was talking about.\n",
        "- Why not go further? - Do you think that was ok?\n",
        "- I apologise for saying that, but I meant the other stuff.\n",
        "- @John But when? - @John Please tell me why I've been stuck here for so long.\n",
        "- What drove that thought? - I actually said \"sure thing\".\n",
        "- You serious?\n",
        "- I'm not sure what I could have done differently.\n",
        "TASK:\n",
        "Does the below sentence indicate a possible misunderstanding?\n",
        "Only respond with \"Yes\" or \"No\"\n",
        "Sentence: {}\n",
        "Response:\"\"\""
      ],
      "metadata": {
        "id": "IjUet6QSkz1m"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2 Throughput"
      ],
      "metadata": {
        "id": "KBCsSzjWk1EW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "These two plots show the classifier performance according to (1) Area Under the Precision Recall Curve (2) Weighted F1 for the classifier and"
      ],
      "metadata": {
        "id": "vKwY5i75e2Gu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "target_cols = [\"Order\",\"Classifier\",\"F1_avg\",\"F1_var\",\"AUC_PR\", \"AUC_ROC\",\"Precision\",\"Recall\",\"FP\",\"FN\",\"TP\",\"TN\"]\n",
        "ThroughRes = St2Through[target_cols].round(2).sort_values(\"AUC_PR\", ascending = False)\n",
        "ThroughRes = ThroughRes.rename(columns={\"F1_avg\": \"Weighted F1\", \"AUC_PR\":\"Area Under the Presicion-Recall Curve\"})\n",
        "tdf = ThroughRes.sort_values(by=[\"Order\",\"Classifier\"])\n",
        "tdf = tdf.replace({\"few-shot\":\"LLM\"})\n",
        "tds = TextDataStats(tdf)\n",
        "tds.RAMP_plot(\"Order\", \"Area Under the Presicion-Recall Curve\",\"Classifier\", width=800,height=500)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        },
        "id": "VlRkLaBcfABm",
        "outputId": "8b5b954d-0b6b-4da3-c25b-26d982fd7018"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"5ca98988-869e-470e-be27-e5475b8c3228\" class=\"plotly-graph-div\" style=\"height:500px; width:800px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"5ca98988-869e-470e-be27-e5475b8c3228\")) {                    Plotly.newPlot(                        \"5ca98988-869e-470e-be27-e5475b8c3228\",                        [{\"hovertemplate\":\"Classifier=LLM\\u003cbr\\u003eOrder=%{x}\\u003cbr\\u003eArea Under the Presicion-Recall Curve=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"LLM\",\"line\":{\"color\":\"#77B5FE\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"markers+lines\",\"name\":\"LLM\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21],\"xaxis\":\"x\",\"y\":[0.22,0.43,0.41,0.49,0.56,0.53,0.54,0.53,0.55,0.52,0.48,0.49,0.58,0.56,0.52,0.52,0.52,0.53,0.56,0.55,0.53],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":\"Classifier=rule-based\\u003cbr\\u003eOrder=%{x}\\u003cbr\\u003eArea Under the Presicion-Recall Curve=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"rule-based\",\"line\":{\"color\":\"#FF6961\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"markers+lines\",\"name\":\"rule-based\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21],\"xaxis\":\"x\",\"y\":[0.15,0.18,0.28,0.3,0.34,0.32,0.32,0.32,0.32,0.32,0.32,0.32,0.32,0.32,0.32,0.33,0.38,0.33,0.4,0.39,0.41],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":\"Classifier=supervised\\u003cbr\\u003eOrder=%{x}\\u003cbr\\u003eArea Under the Presicion-Recall Curve=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"supervised\",\"line\":{\"color\":\"#B19CD9\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"markers+lines\",\"name\":\"supervised\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21],\"xaxis\":\"x\",\"y\":[0.64,0.66,0.65,0.67,0.69,0.69,0.67,0.69,0.7,0.67,0.67,0.69,0.68,0.68,0.66,0.66,0.69,0.67,0.68,0.7,0.68],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"line\":{\"color\":\"#77B5FE\",\"dash\":\"dash\",\"width\":2},\"mode\":\"lines\",\"name\":\"LLM - Range Line\",\"opacity\":0.5,\"showlegend\":false,\"x\":[1,21],\"y\":[0.22,0.53],\"type\":\"scatter\"},{\"line\":{\"color\":\"#FF6961\",\"dash\":\"dash\",\"width\":2},\"mode\":\"lines\",\"name\":\"rule-based - Range Line\",\"opacity\":0.5,\"showlegend\":false,\"x\":[1,21],\"y\":[0.15,0.41],\"type\":\"scatter\"},{\"line\":{\"color\":\"#B19CD9\",\"dash\":\"dash\",\"width\":2},\"mode\":\"lines\",\"name\":\"supervised - Range Line\",\"opacity\":0.5,\"showlegend\":false,\"x\":[1,21],\"y\":[0.64,0.68],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Order\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Area Under the Presicion-Recall Curve\"}},\"legend\":{\"title\":{\"text\":\"Classifier\"},\"tracegroupgap\":0},\"margin\":{\"t\":60},\"title\":{\"text\":\"\"},\"width\":800,\"height\":500},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('5ca98988-869e-470e-be27-e5475b8c3228');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tds.RAMP_plot(\"Order\", \"Weighted F1\",\"Classifier\",width=800,height=500)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        },
        "id": "TDcsjlrFfDkU",
        "outputId": "fd68c040-ca05-4d5c-97c2-83adbeea7548"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"5fdcd37c-68d3-4e6b-9287-7c8b74b717d4\" class=\"plotly-graph-div\" style=\"height:500px; width:800px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"5fdcd37c-68d3-4e6b-9287-7c8b74b717d4\")) {                    Plotly.newPlot(                        \"5fdcd37c-68d3-4e6b-9287-7c8b74b717d4\",                        [{\"hovertemplate\":\"Classifier=LLM\\u003cbr\\u003eOrder=%{x}\\u003cbr\\u003eWeighted F1=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"LLM\",\"line\":{\"color\":\"#77B5FE\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"markers+lines\",\"name\":\"LLM\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21],\"xaxis\":\"x\",\"y\":[0.79,0.78,0.86,0.87,0.88,0.91,0.88,0.88,0.87,0.88,0.88,0.86,0.91,0.91,0.88,0.84,0.87,0.9,0.91,0.88,0.9],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":\"Classifier=rule-based\\u003cbr\\u003eOrder=%{x}\\u003cbr\\u003eWeighted F1=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"rule-based\",\"line\":{\"color\":\"#FF6961\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"markers+lines\",\"name\":\"rule-based\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21],\"xaxis\":\"x\",\"y\":[0.85,0.85,0.82,0.81,0.82,0.87,0.87,0.87,0.87,0.87,0.87,0.87,0.87,0.87,0.83,0.79,0.78,0.78,0.76,0.75,0.74],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":\"Classifier=supervised\\u003cbr\\u003eOrder=%{x}\\u003cbr\\u003eWeighted F1=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"supervised\",\"line\":{\"color\":\"#B19CD9\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"markers+lines\",\"name\":\"supervised\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21],\"xaxis\":\"x\",\"y\":[0.93,0.93,0.93,0.93,0.94,0.94,0.93,0.94,0.94,0.93,0.93,0.94,0.93,0.93,0.93,0.93,0.94,0.93,0.93,0.94,0.93],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"line\":{\"color\":\"#77B5FE\",\"dash\":\"dash\",\"width\":2},\"mode\":\"lines\",\"name\":\"LLM - Range Line\",\"opacity\":0.5,\"showlegend\":false,\"x\":[1,21],\"y\":[0.79,0.9],\"type\":\"scatter\"},{\"line\":{\"color\":\"#FF6961\",\"dash\":\"dash\",\"width\":2},\"mode\":\"lines\",\"name\":\"rule-based - Range Line\",\"opacity\":0.5,\"showlegend\":false,\"x\":[1,21],\"y\":[0.85,0.74],\"type\":\"scatter\"},{\"line\":{\"color\":\"#B19CD9\",\"dash\":\"dash\",\"width\":2},\"mode\":\"lines\",\"name\":\"supervised - Range Line\",\"opacity\":0.5,\"showlegend\":false,\"x\":[1,21],\"y\":[0.93,0.93],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Order\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Weighted F1\"}},\"legend\":{\"title\":{\"text\":\"Classifier\"},\"tracegroupgap\":0},\"margin\":{\"t\":60},\"title\":{\"text\":\"\"},\"width\":800,\"height\":500},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('5fdcd37c-68d3-4e6b-9287-7c8b74b717d4');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Best supervised classifier and parameters\n",
        "supdf = St2Through[[\"Order\",\"Classifier\",\"F1_avg\",\"AUC_PR\",\"Precision\",\"Recall\",\"validation_size\",\"epochs\",\"learning_rate\",\"batch_size\"]]\n",
        "supdf[supdf[\"Classifier\"]==\"supervised\"].sort_values(\"AUC_PR\", ascending = False).head(1).round(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "H7ct4xwOb7JI",
        "outputId": "3fa2369b-3b60-4c96-94e3-62809f5245b0"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Order  Classifier  F1_avg  AUC_PR  Precision  Recall  validation_size  \\\n",
              "61     20  supervised    0.94     0.7       0.74    0.62              0.3   \n",
              "\n",
              "    epochs  learning_rate  batch_size  \n",
              "61     4.0            0.0        64.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-253d4c7e-814c-4503-8f5d-73853c8d76e3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Order</th>\n",
              "      <th>Classifier</th>\n",
              "      <th>F1_avg</th>\n",
              "      <th>AUC_PR</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>validation_size</th>\n",
              "      <th>epochs</th>\n",
              "      <th>learning_rate</th>\n",
              "      <th>batch_size</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>20</td>\n",
              "      <td>supervised</td>\n",
              "      <td>0.94</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.74</td>\n",
              "      <td>0.62</td>\n",
              "      <td>0.3</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>64.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-253d4c7e-814c-4503-8f5d-73853c8d76e3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-253d4c7e-814c-4503-8f5d-73853c8d76e3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-253d4c7e-814c-4503-8f5d-73853c8d76e3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"supdf[supdf[\\\"Classifier\\\"]==\\\"supervised\\\"]\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"Order\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 20,\n        \"max\": 20,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          20\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Classifier\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"supervised\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1_avg\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.94,\n        \"max\": 0.94,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.94\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AUC_PR\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.7,\n        \"max\": 0.7,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.74,\n        \"max\": 0.74,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.74\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.62,\n        \"max\": 0.62,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.62\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"validation_size\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.3,\n        \"max\": 0.3,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"epochs\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 4.0,\n        \"max\": 4.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          4.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"learning_rate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"batch_size\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 64.0,\n        \"max\": 64.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          64.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Best rule-based classifier (using lemma list)\n",
        "rbdf = St2Through[[\"Order\",\"Classifier\",\"F1_avg\",\"AUC_PR\",\"Precision\",\"Recall\",\"PatternOrLemma\",\"train_size\",\"nTerms\"]]\n",
        "rbdf[rbdf[\"Classifier\"]==\"rule-based\"].sort_values(\"AUC_PR\", ascending = False).head(1).round(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "evTmH1ZWdVRO",
        "outputId": "72dc24a4-ccaa-4bf0-d426-bf4f109c500b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Order  Classifier  F1_avg  AUC_PR  Precision  Recall PatternOrLemma  \\\n",
              "41     21  rule-based    0.74    0.41       0.17    0.61          lemma   \n",
              "\n",
              "    train_size  nTerms  \n",
              "41       14728   230.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ae4129af-679b-411a-a137-73f9b45ef6ca\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Order</th>\n",
              "      <th>Classifier</th>\n",
              "      <th>F1_avg</th>\n",
              "      <th>AUC_PR</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>PatternOrLemma</th>\n",
              "      <th>train_size</th>\n",
              "      <th>nTerms</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>21</td>\n",
              "      <td>rule-based</td>\n",
              "      <td>0.74</td>\n",
              "      <td>0.41</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.61</td>\n",
              "      <td>lemma</td>\n",
              "      <td>14728</td>\n",
              "      <td>230.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ae4129af-679b-411a-a137-73f9b45ef6ca')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ae4129af-679b-411a-a137-73f9b45ef6ca button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ae4129af-679b-411a-a137-73f9b45ef6ca');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"rbdf[rbdf[\\\"Classifier\\\"]==\\\"rule-based\\\"]\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"Order\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 21,\n        \"max\": 21,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          21\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Classifier\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"rule-based\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1_avg\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.74,\n        \"max\": 0.74,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.74\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AUC_PR\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.41,\n        \"max\": 0.41,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.41\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.17,\n        \"max\": 0.17,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.17\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.61,\n        \"max\": 0.61,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.61\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"PatternOrLemma\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"lemma\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"train_size\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 14728,\n        \"max\": 14728,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          14728\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"nTerms\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 230.0,\n        \"max\": 230.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          230.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Best LLM classifiers (using prompt)\n",
        "rbdf = St2Through[[\"Order\",\"Classifier\",\"F1_avg\",\"AUC_PR\",\"Precision\",\"Recall\", \"train_size\",\"GPTmodel\"]]\n",
        "rbdf[rbdf[\"Classifier\"]==\"LLM\"].sort_values(\"AUC_PR\", ascending = False).head(1).round(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "q34Rv6ofehT9",
        "outputId": "8926c57f-a888-4bcf-a644-31f941737484"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Order Classifier  F1_avg  AUC_PR  Precision  Recall  train_size  \\\n",
              "12     13   few-shot    0.91    0.58       0.54    0.59        1000   \n",
              "\n",
              "       GPTmodel  \n",
              "12  gpt-4-turbo  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a27b1dd7-50c2-40e4-a567-6a006f06e163\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Order</th>\n",
              "      <th>Classifier</th>\n",
              "      <th>F1_avg</th>\n",
              "      <th>AUC_PR</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>train_size</th>\n",
              "      <th>GPTmodel</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>13</td>\n",
              "      <td>few-shot</td>\n",
              "      <td>0.91</td>\n",
              "      <td>0.58</td>\n",
              "      <td>0.54</td>\n",
              "      <td>0.59</td>\n",
              "      <td>1000</td>\n",
              "      <td>gpt-4-turbo</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a27b1dd7-50c2-40e4-a567-6a006f06e163')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a27b1dd7-50c2-40e4-a567-6a006f06e163 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a27b1dd7-50c2-40e4-a567-6a006f06e163');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"rbdf[rbdf[\\\"Classifier\\\"]==\\\"few-shot\\\"]\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"Order\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 13,\n        \"max\": 13,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          13\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Classifier\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"few-shot\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1_avg\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.91,\n        \"max\": 0.91,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.91\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AUC_PR\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.58,\n        \"max\": 0.58,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.58\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.54,\n        \"max\": 0.54,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.54\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.59,\n        \"max\": 0.59,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.59\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"train_size\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 1000,\n        \"max\": 1000,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1000\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"GPTmodel\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"gpt-4-turbo\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.3 Output"
      ],
      "metadata": {
        "id": "jivZGllok5VD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3.1 Classification reports"
      ],
      "metadata": {
        "id": "kSU0RKIlm_9L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "out = validation.copy()\n",
        "texts = out.text.to_list()\n",
        "true_scores = out.Misunderstanding.to_list()"
      ],
      "metadata": {
        "id": "S9BJA7wlE4yp"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Rule-based classifier\n",
        "rbClassifier = Classifier(texts, true_scores)\n",
        "rbClassifier.add_rule_based_terms(terms, 'lemma')\n",
        "rbClassifier.run_classifier()\n",
        "rbClassifier.get_model_report()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AdfORjN8k9aW",
        "outputId": "8151229e-95fc-454b-b287-ee554fd4b4b6"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/spacy/util.py:1740: UserWarning:\n",
            "\n",
            "[W111] Jupyter notebook detected: if using `prefer_gpu()` or `require_gpu()`, include it in the same cell right before `spacy.load()` to ensure that the model is loaded on the correct device. More information: http://spacy.io/usage/v3#jupyter-notebook-gpu\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC-PR: 0.40\n",
            "\n",
            "AUC-ROC: 0.65\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.68      0.79      5909\n",
            "           1       0.14      0.63      0.24       511\n",
            "\n",
            "    accuracy                           0.67      6420\n",
            "   macro avg       0.55      0.65      0.51      6420\n",
            "weighted avg       0.89      0.67      0.75      6420\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For supervised machine learning classifier\n",
        "smlClassifier = Classifier(texts, true_scores)\n",
        "smlClassifier.add_SML_classifier(predictor)\n",
        "smlClassifier.run_classifier()\n",
        "smlClassifier.get_model_report()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_dFRe4RExfV",
        "outputId": "864c7192-1b4d-46df-9274-1d6e3eb3f1a6"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/spacy/util.py:1740: UserWarning:\n",
            "\n",
            "[W111] Jupyter notebook detected: if using `prefer_gpu()` or `require_gpu()`, include it in the same cell right before `spacy.load()` to ensure that the model is loaded on the correct device. More information: http://spacy.io/usage/v3#jupyter-notebook-gpu\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Supervised ML classifier configured with parameters: {}\n",
            "AUC-PR: 0.73\n",
            "\n",
            "AUC-ROC: 0.88\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.96      0.97      5909\n",
            "           1       0.65      0.79      0.71       511\n",
            "\n",
            "    accuracy                           0.95      6420\n",
            "   macro avg       0.81      0.88      0.84      6420\n",
            "weighted avg       0.95      0.95      0.95      6420\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LLM classifier\n",
        "gpt_model = \"gpt-4o\"\n",
        "fsClassifier = Classifier(texts, true_scores)\n",
        "fsClassifier.add_few_shot_classifier(gpt_model, prompt, role)\n",
        "fsClassifier.run_classifier()\n",
        "fsClassifier.get_model_report()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DN8TjOTjEy7N",
        "outputId": "f3882bba-4103-4f4c-fe47-ff933e01353b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/spacy/util.py:1740: UserWarning:\n",
            "\n",
            "[W111] Jupyter notebook detected: if using `prefer_gpu()` or `require_gpu()`, include it in the same cell right before `spacy.load()` to ensure that the model is loaded on the correct device. More information: http://spacy.io/usage/v3#jupyter-notebook-gpu\n",
            "\n",
            "100%|██████████| 6420/6420 [47:24<00:00,  2.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This run cost 15.78$ for 3156170 tokens. Average tokens: 491.62\n",
            "AUC-PR: 0.56\n",
            "\n",
            "AUC-ROC: 0.80\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.91      0.94      5909\n",
            "           1       0.39      0.69      0.50       511\n",
            "\n",
            "    accuracy                           0.89      6420\n",
            "   macro avg       0.68      0.80      0.72      6420\n",
            "weighted avg       0.93      0.89      0.90      6420\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#out[\"rule-based\"] = rbClassifier.pred_scores\n",
        "#out[\"supervised\"] = smlClassifier.pred_scores\n",
        "#out[\"few-shot\"] = fsClassifier.pred_scores\n",
        "#out.to_csv(\"RAMP_Stage2Output_v2.csv\",index=False)"
      ],
      "metadata": {
        "id": "iv3FQ3-snIdm"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Evaluation stage\n",
        "\n",
        "This section looks at disagreements and misclassifications in order to inform the final stage of RAMP. These are used to infer surprising findings from which to identify potential problems of construct and concept validity."
      ],
      "metadata": {
        "id": "5QvklA8-nEJT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1 Disagreements evaluation"
      ],
      "metadata": {
        "id": "j4wwlA44mblb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get sample of disagreements\n",
        "tds = TextDataStats(IRR_final)\n",
        "tds.get_disagreements(25)"
      ],
      "metadata": {
        "id": "TKmaQbQ8mgYh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7458db7-d719-434a-c525-6c982d3a4c2c"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------\n",
            "In any case, everyone has different things they find satisfying to do on Wikipedia; why don't you spend time on things that give you pleasure?\n",
            "----------\n",
            "@Ask_Spectrum I've gave your company enough of my patience ive had enough, you just lost a customer!.\n",
            "----------\n",
            "Update: as a few have pointed out, the term racist was a poor choice of words.\n",
            "----------\n",
            "this is amc, but i feel you\n",
            "----------\n",
            "Well, I'm not talking about Western Sahara specifically.\n",
            "----------\n",
            "We wouldn't be able to comment further than what was discussed yesterday, until Omniserve come back.\n",
            "----------\n",
            "The rest not so rightÔ£ø√º√≤√ë thanks for correcting me!\n",
            "----------\n",
            "The article is actually a lot better and resourceful than it originally appeared but I believe my edits have improved it, even if I picked up a few horses in Jutland rather than Jutland horse and probably needed minor copyedits.\n",
            "----------\n",
            "Why go from zero to 100 today?\n",
            "----------\n",
            "I mean is there proof for that third one?\n",
            "----------\n",
            "You seem to have misread the guidelines.\n",
            "----------\n",
            "Are you suggesting otherwise?\n",
            "----------\n",
            "I forgot that we are on earth and that there are forces applied on objects that arent present in space lol.\n",
            "----------\n",
            "Now it's clear to me.\n",
            "----------\n",
            "The discrepancy between the UK self-esteem and the view the rest of the world has.\n",
            "----------\n",
            "Rather, the point I'm making is that you're applying an overly-simplified lens to this.\n",
            "----------\n",
            "If part of your point relates to the idea that religion makes it so you don't question the belief system and also divides people up into different groups by virtue of being a different religion then that could be true but even post religious societies have that aspect such as nationalism.\n",
            "----------\n",
            "Why now?\n",
            "----------\n",
            "So the service is worse than usual but its more expensive to travel?\n",
            "----------\n",
            "I understand that, but we don't need twenty plus pages to solve that problem.\n",
            "----------\n",
            "However on looking at the relevant AN\\/I section, discussion on it appears to have dried up, and given the topic of the dispute and its sheer irrelevance to anything remotely related to making Barack Obama an encyclopaedic article, and given some editors' (on both sides) single-minded obsession with the one article and the debates in and around it, I don't feel any great regrets about the action taken.\n",
            "----------\n",
            "What do you know?\n",
            "----------\n",
            "Now refusing to send elsewhere?\n",
            "----------\n",
            "So the article [[Jackal]] is wrong then?\n",
            "----------\n",
            "@361567 Hi, not to worry it will not be charged.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2 Misclassifications evaluation"
      ],
      "metadata": {
        "id": "Ym2-GFNumkRr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "out = out.rename(columns={\"Misunderstanding\":\"Manual\", \"few-shot\":\"LLM\"})"
      ],
      "metadata": {
        "id": "NRF8EStoCdmG"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tds = TextDataStats(out)\n",
        "misdf = tds.get_misclassifications(return_all = True)"
      ],
      "metadata": {
        "id": "1e47fC2YZ1Gs"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For printing rule-based misclassifications - these are fairly arbitrary\n",
        "for i in misdf[misdf[\"Manual\"]==1][misdf[\"rule-based\"]==0].sample(10).text.values:\n",
        "  print(i)"
      ],
      "metadata": {
        "id": "mhrPActSaBn0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3d434ab-2bf5-42ba-fab6-e83810cd2f24"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "btw I'm not Ronald!\n",
            "hehe, whoops!\n",
            "No news is good news?\n",
            "@Company_Handle For the type of issue reported I thought I may have at least been contacted for some information.\n",
            "Do you steal from seniors too or just kids?\n",
            "Am I missing something?\n",
            "Isn't this to show pics we've taken??\n",
            "We don't think it is.\n",
            "Like John hasn't exhibited a consistent attitude conducive to collaboration?\n",
            "Oh, I see.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-3b1cc0282d4c>:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
            "  for i in misdf[misdf[\"Manual\"]==1][misdf[\"rule-based\"]==0].sample(10).text.values:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For supervised and few shot classifiers\n",
        "tds = TextDataStats(out)\n",
        "tds.get_misclassifications(n=25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7Fvi5Aenrj-",
        "outputId": "a5a72773-f585-4cbd-bc76-f8458dedefcf"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- FP (All) count: -- 53\n",
            "--- FP (supervised) count: -- 111\n",
            "--- FP (LLM) count: -- 436\n",
            "--- FN (All) count: -- 111\n",
            "--- FN (supervised) count: -- 53\n",
            "--- FN (LLM) count: -- 0\n",
            "\n",
            "Printing 25 examples of each classifier type.\n",
            "\n",
            "------ FP (ALL) ------\n",
            "- Sure, do you want me to?\n",
            "- This is completely unacceptable and to worsen it is that you lot do not respond quick enough.\n",
            "- I am very patient as to what-will-happen-next, although I don't seem to manage it with spur-of-the-moment replies (oops).\n",
            "- I'm not really committed to extensive rewriting as it's only wiki and can be edited anyway.\n",
            "- I take that back.\n",
            "- hahahahaha my apologies\n",
            "- How can you fame a Wikipedian?\n",
            "- @Company_Handle @Company_Handle What type of ticket have you bought?\n",
            "- Again, Industry Canada is a reliable source, even if not the preferred one, and those numbers are much better than no numbers at all.\n",
            "- Anything you can do to make him believe that I mean no ill will would be very helpful.\n",
            "- For one i didn't even know the person \\\"personally\\\".\n",
            "- I thought it was a clear-cut case of \\\"notability not proven\\\" the way it stood, but if he can improve it, it's no problem as far as I'm concerned.\n",
            "- Hrafn's a constructive editor who is on my watchlist. . .\n",
            "- What's going on with the import script?\n",
            "- I want to know the cause of this delay.\n",
            "- I am the person that added all the attendances(at least most of it), I have no reason to fabricate attendances.\n",
            "- Thank you for explaining why, I withdraw my complaint.\n",
            "- Remember, I was just helping Michael with the ''Origin'', but ''Orchids'' was mostly me with a great deal of help from both of you.\n",
            "- I get there's no real answer but which option has more support?\n",
            "- No put stickers on things that changed the perception of them Like he would put a woodchuck sticker on the hand operated pencil sharpener and stickers that read, \"Lies?\" on the globe because despite being a science teacher he was a flat earther.\n",
            "- @Company_Handle Oh, okay.\n",
            "- I already have and he has done it multiple times.\n",
            "- It's not specific enough, I need something that doesn't require ps plus or Nintendo online\n",
            "- I don't really think it's necessary; I wouldn't have added the tag if I were editing the article by hand.\n",
            "- It was mostly the \\\"community\\\" name and the unprofessional look of the webpage that caused me to remove it, plus I was in \\\"mass-delete\\\" mode as I went through dozens of vehicle articles looking for links that obviously violated the guideline.\n",
            "--------\n",
            "------ FP (SUPERVISED) ------\n",
            "- A google time-stamped prophecy is neither an opinion, experience nor is it an argument, so I can't see how it is original research.\n",
            "- I also have to admit that running into you has made this avocation less than enjoyable as I seek to begin to respond to the grain and chaff issue I referred to in a previous edit.\n",
            "- This proves my point too.\n",
            "- Indonesian organisations with english names as title of article and the indonesian name as the aka please?\n",
            "- Which will be better??\n",
            "- Are you having this issue with any other channels?\n",
            "- I don't care about martyrdom, etc., or any dramas.\n",
            "- If you can't, it's no problem; I just thought I'd ask.\n",
            "- @Company_Handle I did not hear back from you yet.\n",
            "- Now you're just being uncivil and insulting.\n",
            "- I wanted to talk to them, but didn't know where to start.\n",
            "- I understand your frustration at seeing a lot of what you've created slowly whittled away, but [http:\\/\\/en.wikipedia.org\\/w\\/index.php?title=Suzi_Suzuki&curid=4775796&diff=437390137&oldid=437364401 this] is 100% pure [[WP:POINT]].\n",
            "- &#x200B; It is true that they are wrong, but how should they know?\n",
            "- It's me, again.\n",
            "- Like you, I wrote on what I know, so it was easy.\n",
            "- Oh no!!\n",
            "- I thought not.\n",
            "- But yes obviously that Facebook whatever stuff is actually wrong i just wanted to point out that an actual number for the death rate exists and has actually existed for many months\n",
            "- My phone been on 1x for 2 fucking days wtf is 1x?\n",
            "- Yes, please do that, if you change it to non consensus then it stops people quoting it as if it was decided by the review when it wasn't.- \n",
            "- Do you think its function could be impoved?\n",
            "- :-) On an unrelated note, I've obviously read your user page -- is your daughter killing you the same way ours is killing us?\n",
            "- No, he didn't.\n",
            "- Add it to the category pages?\n",
            "- Oh yeah!\n",
            "--------\n",
            "------ FP (LLM) ------\n",
            "- @Company_Handle We apologize for any confusion, it looks like this item sold out quickly!\n",
            "- And I am not some crazed guy out to mock and disrupt his life, regardless of what he says ot thinks.\n",
            "- But I do not think he really supports the semiprotection, neither does Sidaway or some other respected editors.\n",
            "- Where do you see the blog is sponsored by Parade Magazine.\n",
            "- Any clues as to how I can fix?\n",
            "- I have never once seen anyone on here mention anything about purchasing silver.\n",
            "- Thanks for the article, which does not in fact discuss ''how'' to distinguish empty matrices, although it does mention their distinctiveness.\n",
            "- @Company_Handle That's not okay.\n",
            "- They fought for you to be able to, not to require you to This phrase mostly comes up when you decide not to care about something someone else feels strongly about\n",
            "- Cant tell if that's the pilot or the undercarriage that gets fired out the front.\n",
            "- I was thinking the Piney Woods school article itself needed more additions, but you already did that too.\n",
            "- Just stop thinking your above others be you only listen to a few of biggie and Christopher's songs when you don't give anything else a try.\n",
            "- Don't fool yourself, that's what's going on.\n",
            "- If my words are not clear, please point out the parts which need further explaining.\n",
            "- @Company_Handle It say's I'm verified been when I click the user detail this is the next page.\n",
            "- So I continually request a discount that I'm entitled to with &amp; they don't give info.\n",
            "- @Company_Handle looks like am not only one having this issue!\n",
            "- There are bigger issues at hand - like maybe the fact that the masks are fake, not that the wearers are upset the masks are fake\n",
            "- I fail to see the danger.\n",
            "- (My memory might be wrong, but I'm sure I would not have allowed that photo to be used in the article without double-checking that it was okay.)\n",
            "- Hello, I have sent 2 coppies of my unblock request to arbcom, one in march, and one in early April, but no response, so I am seaking advice, what else is there for me to do, I'm totaly out of ideas and I have lost faith in wikipedia.\n",
            "- I don't recall EVER seeing how people also abandon their own parents when they're old.\n",
            "- @Company_Handle be nice though if the whole range was available esp in an Xtra store, I currently have to drive 10km to James for more choice.. @Company_Handle hi im interested in the new ones the peppercorn and \"goats\" cheese I already know where the existing Free From cheezes can.be got.\n",
            "- Please, could someone tell me what next?\n",
            "- As for your comment about Lisa Millerton people\\\", Wikipedia policy is that content is based on reliable sources, not what is insulting to any group of people (for example, we refer to that landlocked country north of East Michael as Harperport, even though that term seems to be offensive to many Greeks).\n",
            "--------\n",
            "------ FN (ALL) ------\n",
            "- Its happened a few times now.Is it supposed to be like that?\n",
            "- @Company_Handle That's so strange - clicked on the link and it isn't showing that late :( \n",
            "- So what about everyone else?\n",
            "- But why is that ideology so attractive?\n",
            "- @Company_Handle Will I still be getting a Scorpio editon?\n",
            "- I hope you didn't think it was serious.\n",
            "- I can't answer to all your questions since I don't think to have been involved in all the edits you talk about.\n",
            "- As for \\\"taking recentism to new heights\\\", I stand by that attack on the edit.\n",
            "- Was it still showing as downloading for you?\n",
            "- Belatedly, I've added the material I mentioned earlier concerning individual reactions to Laurie's books upon their publication.\n",
            "- Two flights in a row????\n",
            "- Does this mean that articles such as [[Duality (Song)]] and [[Mirrorcle World]] are invalid, as well as all of [[The Gazette]]'s other singles?\n",
            "- To customer CARE?\n",
            "- Is that right?\n",
            "- @Company_Handle ?\n",
            "- That's why I needed to double-check.\n",
            "- I was wondering this too, or if it's something you intentionally do to trick your brain?\n",
            "- > Okay, when I wrote this, I was a little too focused on deliberate acts of self expression rather than things people are born with.\n",
            "- I'm not saying don't thrift shop.\n",
            "- EDIT - wow, I can't spell apparently....\"known for being he Cofounder\" whoops.\n",
            "- why the elderly man refused hot coffee ?\n",
            "- @Company_Handle can you tell me why I was promised a manager call me in 1 hour &amp; they haven't?\n",
            "- @Company_Handle I haven't order anything from you guys!\n",
            "- Why is that?\n",
            "- Wtf was that ending?\n",
            "--------\n",
            "------ FN (SUPERVISED) ------\n",
            "- Not sure what that is\n",
            "- But... they do.\n",
            "- To the user whose page this is, examine the situation as you will, but I thought I'd leave my two cents when the person above is trying to portray me as someone out to ruin the article.\n",
            "- Mark, the experience you are describing is something we'd never do.\n",
            "- What am I doing?\n",
            "- How is this photo relevant to Rachel's life?\n",
            "- How does it make it make Wikipedia more user friendly to alter [[Natasha]] to [[Kelly of England|Henry VIII]]?\n",
            "- FA work is fine and I'm sure WMC could assist in non CC related article improvement but once a bulls eye get painted on anyone of this high a profile on this project, someone is always going to be the ready to play smackdown if such an editor so much as twitches \\\"incorrectly\\\"...my understanding as it was clarified to me was that user talkpages, even your own user talkpage are taboo for issues related to the topic ban.--\n",
            "- @Company_Handle I provided you all with the info 5 hours ago\n",
            "- @Company_Handle We are not the bots you are looking for.\n",
            "- That may be (one can never be sure), but the editors don't seem to understand the serious problems with the page.\n",
            "- Hold up.\n",
            "- Can you elaborate the implications of your argument?\n",
            "- @Company_Handle this is the enough apologies you have sent, it's enough to last me a life time .. clean up your mess \n",
            "- Might I ask you to check out my responses to the issues you raised, specifically the questions I asked about images?\n",
            "- The rest not so right thanks for correcting me!\n",
            "- Could you confirm If you have contacted the support team through link provided earlier?\n",
            "- Edit: this is for areas that don't normally get freezing temperatures, where houses aren't designed for those temperatures.\n",
            "- I guess you think more highly of userboxes than myself.\n",
            "- @Company_Handle What number are you dialing?\n",
            "- @Company_Handle This is the same trip.\n",
            "- so, if the national cancer... has cancer, what's the problem\n",
            "- I understand that, but we don't need twenty plus pages to solve that problem.\n",
            "- However, at the [[Talk:List of Farscape episodes#Upcoming Merge & Redirect per Wikipedia Guidelines & Notability Standards|''Farscape'' talk page]], you stated that I was ''Anthony\"'' with these same policies.\n",
            "- And what's wrong with reading through five+ paragraphs?\n",
            "--------\n",
            "------ FN (LLM) ------\n",
            "--------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2.1 Using LIME to explore BERT classifier"
      ],
      "metadata": {
        "id": "C6djwU6rmv6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For assessing the supervised classifier FN and FP\n",
        "predictor.explain(\"It's me, again\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "id": "IxRV_yhTa7J9",
        "outputId": "417a389d-0e44-4625-a068-84e5a3a8ccec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <style>\n",
              "    table.eli5-weights tr:hover {\n",
              "        filter: brightness(85%);\n",
              "    }\n",
              "</style>\n",
              "\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "        \n",
              "\n",
              "    \n",
              "\n",
              "        \n",
              "\n",
              "        \n",
              "    \n",
              "        \n",
              "        \n",
              "    \n",
              "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
              "            <b>\n",
              "    \n",
              "        y=Misunderstanding\n",
              "    \n",
              "</b>\n",
              "\n",
              "    \n",
              "    (probability <b>0.799</b>, score <b>1.378</b>)\n",
              "\n",
              "top features\n",
              "        </p>\n",
              "    \n",
              "    <table class=\"eli5-weights\"\n",
              "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
              "        <thead>\n",
              "        <tr style=\"border: none;\">\n",
              "            \n",
              "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
              "                    Contribution<sup>?</sup>\n",
              "                </th>\n",
              "            \n",
              "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
              "            \n",
              "        </tr>\n",
              "        </thead>\n",
              "        <tbody>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +2.777\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        Highlighted in text (sum)\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "        \n",
              "\n",
              "        \n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 87.63%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -1.399\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        &lt;BIAS&gt;\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "\n",
              "        </tbody>\n",
              "    </table>\n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n",
              "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
              "        <span style=\"background-color: hsl(120, 100.00%, 74.54%); opacity: 0.90\" title=\"1.709\">it</span><span style=\"opacity: 0.80\">&#x27;</span><span style=\"background-color: hsl(0, 100.00%, 92.22%); opacity: 0.82\" title=\"-0.314\">s</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 87.68%); opacity: 0.84\" title=\"0.606\">me</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(120, 100.00%, 60.00%); opacity: 1.00\" title=\"3.259\">again</span>\n",
              "    </p>\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictor.explain(\"Mark, the experience you are describing is something we'd never do.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "id": "-FSv-aABefP8",
        "outputId": "25634fc7-81f2-4613-f5bd-70a469c8c583"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <style>\n",
              "    table.eli5-weights tr:hover {\n",
              "        filter: brightness(85%);\n",
              "    }\n",
              "</style>\n",
              "\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "        \n",
              "\n",
              "    \n",
              "\n",
              "        \n",
              "\n",
              "        \n",
              "    \n",
              "        \n",
              "        \n",
              "    \n",
              "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
              "            <b>\n",
              "    \n",
              "        y=not_Misunderstanding\n",
              "    \n",
              "</b>\n",
              "\n",
              "    \n",
              "    (probability <b>0.701</b>, score <b>-0.850</b>)\n",
              "\n",
              "top features\n",
              "        </p>\n",
              "    \n",
              "    <table class=\"eli5-weights\"\n",
              "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
              "        <thead>\n",
              "        <tr style=\"border: none;\">\n",
              "            \n",
              "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
              "                    Contribution<sup>?</sup>\n",
              "                </th>\n",
              "            \n",
              "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
              "            \n",
              "        </tr>\n",
              "        </thead>\n",
              "        <tbody>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +1.272\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        &lt;BIAS&gt;\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "        \n",
              "\n",
              "        \n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 90.76%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -0.422\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        Highlighted in text (sum)\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "\n",
              "        </tbody>\n",
              "    </table>\n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n",
              "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
              "        <span style=\"background-color: hsl(0, 100.00%, 91.80%); opacity: 0.82\" title=\"-0.289\">mark</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(0, 100.00%, 87.58%); opacity: 0.84\" title=\"-0.523\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 84.45%); opacity: 0.85\" title=\"0.721\">experience</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 65.61%); opacity: 0.96\" title=\"-2.240\">you</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.54%); opacity: 0.82\" title=\"-0.252\">are</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 60.00%); opacity: 1.00\" title=\"-2.780\">describing</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 87.81%); opacity: 0.84\" title=\"-0.509\">is</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.96%); opacity: 0.81\" title=\"-0.144\">something</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 71.82%); opacity: 0.92\" title=\"-1.685\">we</span><span style=\"opacity: 0.80\">&#x27;</span><span style=\"background-color: hsl(120, 100.00%, 77.01%); opacity: 0.89\" title=\"1.260\">d</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 70.08%); opacity: 0.93\" title=\"-1.836\">never</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.63%); opacity: 0.81\" title=\"0.118\">do</span><span style=\"opacity: 0.80\">.</span>\n",
              "    </p>\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For assessing the supervised classifier FN and FP\n",
        "predictor.explain(\"Not sure what that is\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "id": "CmZKiXyCbTMC",
        "outputId": "bf9a779d-be21-45e5-9202-adbcf1ee0978"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <style>\n",
              "    table.eli5-weights tr:hover {\n",
              "        filter: brightness(85%);\n",
              "    }\n",
              "</style>\n",
              "\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "        \n",
              "\n",
              "    \n",
              "\n",
              "        \n",
              "\n",
              "        \n",
              "    \n",
              "        \n",
              "        \n",
              "    \n",
              "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
              "            <b>\n",
              "    \n",
              "        y=not_Misunderstanding\n",
              "    \n",
              "</b>\n",
              "\n",
              "    \n",
              "    (probability <b>0.432</b>, score <b>0.275</b>)\n",
              "\n",
              "top features\n",
              "        </p>\n",
              "    \n",
              "    <table class=\"eli5-weights\"\n",
              "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
              "        <thead>\n",
              "        <tr style=\"border: none;\">\n",
              "            \n",
              "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
              "                    Contribution<sup>?</sup>\n",
              "                </th>\n",
              "            \n",
              "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
              "            \n",
              "        </tr>\n",
              "        </thead>\n",
              "        <tbody>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 83.32%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +0.929\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        &lt;BIAS&gt;\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "        \n",
              "\n",
              "        \n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 80.00%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -1.204\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        Highlighted in text (sum)\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "\n",
              "        </tbody>\n",
              "    </table>\n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n",
              "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
              "        <span style=\"background-color: hsl(120, 100.00%, 81.83%); opacity: 0.86\" title=\"0.456\">not</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 71.37%); opacity: 0.92\" title=\"0.873\">sure</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 67.48%); opacity: 0.95\" title=\"-1.047\">what</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 60.00%); opacity: 1.00\" title=\"-1.407\">that</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 64.52%); opacity: 0.97\" title=\"-1.186\">is</span>\n",
              "    </p>\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For assessing the supervised classifier FN and FP\n",
        "predictor.explain(\"But... They do.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "id": "dWDBjWMGzCFk",
        "outputId": "2caca445-afc6-458c-c38e-067d452478d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <style>\n",
              "    table.eli5-weights tr:hover {\n",
              "        filter: brightness(85%);\n",
              "    }\n",
              "</style>\n",
              "\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "        \n",
              "\n",
              "    \n",
              "\n",
              "        \n",
              "\n",
              "        \n",
              "    \n",
              "        \n",
              "        \n",
              "    \n",
              "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
              "            <b>\n",
              "    \n",
              "        y=not_Misunderstanding\n",
              "    \n",
              "</b>\n",
              "\n",
              "    \n",
              "    (probability <b>0.997</b>, score <b>-5.930</b>)\n",
              "\n",
              "top features\n",
              "        </p>\n",
              "    \n",
              "    <table class=\"eli5-weights\"\n",
              "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
              "        <thead>\n",
              "        <tr style=\"border: none;\">\n",
              "            \n",
              "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
              "                    Contribution<sup>?</sup>\n",
              "                </th>\n",
              "            \n",
              "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
              "            \n",
              "        </tr>\n",
              "        </thead>\n",
              "        <tbody>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +5.248\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        Highlighted in text (sum)\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 95.21%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +0.682\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        &lt;BIAS&gt;\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "        \n",
              "\n",
              "        \n",
              "        \n",
              "\n",
              "        </tbody>\n",
              "    </table>\n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n",
              "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
              "        <span style=\"background-color: hsl(120, 100.00%, 84.97%); opacity: 0.85\" title=\"0.600\">but</span><span style=\"opacity: 0.80\">... </span><span style=\"background-color: hsl(120, 100.00%, 72.94%); opacity: 0.91\" title=\"1.390\">they</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 60.00%); opacity: 1.00\" title=\"2.429\">do</span><span style=\"opacity: 0.80\">.</span>\n",
              "    </p>\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Conclusions\n",
        "\n",
        "In Stage 1, we had acceptable inter-rater reliability (Krippendorff's Alpha = 0.79) following 5 training rounds.\n",
        "In Stage 2, we created three different text classifiers, one rule-based, one supervised, and one LLM. Overall, the supervised machine learning classifier – a fine-tuned BERT model – is much better than both the LLM and rule-based classifiers. The classifier's performance is acceptable (AUC PR = 0.73) with room for improvement.\n",
        "\n",
        " When troubleshooting the results, we can see that the false negatiives are missing some key clarification questions (e.g., \"So what about everyone else?\"). We can also see that the classifiers are picking up on \"new information\" questions, not directed at another's perspeective (e.g., \"Are you having this issue with any other channels?\"). The misclassifications indicate that the classifier is generally struggling with edge cases more than standard cases."
      ],
      "metadata": {
        "id": "VbMaI0IKk_0H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Export notebook:"
      ],
      "metadata": {
        "id": "RW6oyH4WK7U3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary packages\n",
        "!sudo apt-get install texlive-xetex texlive-fonts-recommended texlive-plain-generic"
      ],
      "metadata": {
        "id": "M15jQ7qrK5j5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# First MANUALLY download locally to the working directory\n",
        "# Convert the downloaded file to an HTML file\n",
        "!jupyter nbconvert --to PDF \"RAMP_CaseStudy_12May2024_v31.ipynb\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7mKMhSOIIv7f",
        "outputId": "72e7663b-8772-4065-e540-df37aa329174"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NbConvertApp] Converting notebook RAMP_CaseStudy_12May2024_v31.ipynb to PDF\n",
            "/usr/local/lib/python3.10/dist-packages/nbconvert/filters/datatypefilter.py:41: UserWarning: Your element with mimetype(s) dict_keys(['text/html']) is not able to be represented.\n",
            "  warn(\n",
            "[NbConvertApp] Writing 178109 bytes to notebook.tex\n",
            "[NbConvertApp] Building PDF\n",
            "[NbConvertApp] Running xelatex 3 times: ['xelatex', 'notebook.tex', '-quiet']\n",
            "[NbConvertApp] Running bibtex 1 time: ['bibtex', 'notebook']\n",
            "[NbConvertApp] WARNING | bibtex had problems, most likely because there were no citations\n",
            "[NbConvertApp] PDF successfully created\n",
            "[NbConvertApp] Writing 163015 bytes to RAMP_CaseStudy_12May2024_v31.pdf\n"
          ]
        }
      ]
    }
  ]
}