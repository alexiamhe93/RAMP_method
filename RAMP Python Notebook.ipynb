{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyN5fhUfTIv1uc6x34TiqxgA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alexiamhe93/RAMP_method/blob/main/RAMP%20Python%20Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Code for replicating the Repeated Adjustment of Measurement Protocols (RAMP) method case study\n",
        "\n",
        "This Python notebook is used to replicate the results of the paper titled:\n",
        "\n",
        "> \"Repeated Adjustment of Measurement Protocols (RAMP) method for developing high-validity text classifiers\"\n",
        "\n",
        "The notebook provides the code for replicating the three different stages of RAMP (manual coding, classifier development, and integrative evaluation) and compares the RAMP method against a non-iterative approach.\n",
        "\n",
        "The notebook was designed using Google Colab on an Nvidia T4 GPU (free with log-in). The code works locally but all dependencies from the \"Load packages\" will have to be installed.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Ht0MhYw8ggZq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Table of contents:"
      ],
      "metadata": {
        "id": "7x5QO1Ata5Pb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ">[Code for replicating the Repeated Adjustment of Measurement Protocols (RAMP) method case study](#scrollTo=Ht0MhYw8ggZq)\n",
        "\n",
        ">[Table of contents:](#scrollTo=7x5QO1Ata5Pb)\n",
        "\n",
        ">[Initiate notebook](#scrollTo=0NK-mCzVj-K0)\n",
        "\n",
        ">>[0.1 Install and load packages](#scrollTo=l1uWzkOxkBaG)\n",
        "\n",
        ">>[0.2 Download data and pre-trained BERT model](#scrollTo=9NbRD_KokEAA)\n",
        "\n",
        ">>[0.3 Functions used across stages](#scrollTo=6gRWX3kBIlkj)\n",
        "\n",
        ">[Manual Coding (RAMP method)](#scrollTo=7WBrqsVvvXiL)\n",
        "\n",
        ">>[1.1 Input](#scrollTo=6Q0QqaihHSSW)\n",
        "\n",
        ">>[1.2 Throughput](#scrollTo=Ci0ngC2BHryG)\n",
        "\n",
        ">>[1.3 Output](#scrollTo=twg1bGTWJjzF)\n",
        "\n",
        ">>>[1.3.1 Sense check manual coding output](#scrollTo=3ZBProBJJ2-m)\n",
        "\n",
        ">[Classifier development (RAMP method)](#scrollTo=JqxQnDCpvdG_)\n",
        "\n",
        ">>[2.1 Input](#scrollTo=jxIBD7-LvgLG)\n",
        "\n",
        ">>[2.2 Throughput](#scrollTo=W-K1ar4fvkHL)\n",
        "\n",
        ">>>[2.2.1 Training and developing classifiers](#scrollTo=RUgfO-RPvoYR)\n",
        "\n",
        ">>>>[Rule-based development](#scrollTo=iyoKT7OXv01M)\n",
        "\n",
        ">>>>[Supervised classifier training](#scrollTo=qMMmlFBbv-2r)\n",
        "\n",
        ">>>>[LLM development](#scrollTo=FAcWi6TZwBl8)\n",
        "\n",
        ">>>[2.2.2 Results](#scrollTo=_7Vgu5ejwDgP)\n",
        "\n",
        ">>[2.3 Output](#scrollTo=rLGzncfnSdhu)\n",
        "\n",
        ">>>[2.3.1 Rule-based classifier](#scrollTo=IXqrWohnSvde)\n",
        "\n",
        ">>>[2.3.2 Supervised classifier](#scrollTo=gXBsDJ9zS3DS)\n",
        "\n",
        ">>>[2.3.3 LLM classifier](#scrollTo=lVMM_HDmS85T)\n",
        "\n",
        ">[Integrative evaluation (RAMP method)](#scrollTo=5QvklA8-nEJT)\n",
        "\n",
        ">>[3.1 Inter-rater discrepancies](#scrollTo=j4wwlA44mblb)\n",
        "\n",
        ">>[3.2 Supervised misclassifications](#scrollTo=Ym2-GFNumkRr)\n",
        "\n",
        ">>>[3.2.1 Using LIME to explore BERT classifier](#scrollTo=C6djwU6rmv6K)\n",
        "\n",
        ">[Non-iterative method results](#scrollTo=hf28QA-VLCpI)\n",
        "\n",
        ">>[4.1 Manual coding](#scrollTo=bl9ZsGWlLIL-)\n",
        "\n",
        ">>>[4.1.1 Compare RAMP and non-iterative manual coding](#scrollTo=e8F_rO_6YVJB)\n",
        "\n",
        ">>[4.2 Classifier development](#scrollTo=vTckTVXjMPh8)\n",
        "\n",
        ">>>[4.2.1 Training and developing classifiers](#scrollTo=BHcGRbqhMSI2)\n",
        "\n",
        ">>>[4.2.2 Output](#scrollTo=DneDbUf3M5NB)\n",
        "\n",
        ">[Conclusions](#scrollTo=VbMaI0IKk_0H)\n",
        "\n",
        ">[References](#scrollTo=bulsXEAaP83Z)\n",
        "\n"
      ],
      "metadata": {
        "colab_type": "toc",
        "id": "oxufZu-va-PB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 0. Initiate notebook\n",
        "\n",
        "This section installs all the necessary Python packages to complete these analysis. We also download the data and pre-trained BERT model for replicating the results.\n"
      ],
      "metadata": {
        "id": "0NK-mCzVj-K0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0.1 Install and load packages\n",
        "\n",
        "A few packages require mention as they are non-standard:\n",
        "\n",
        "1. **spacy** ([Honnibal et al., 2022](https://github.com/explosion/spaCy)) This package is used for creating a rule-based dictionary classifier, similar to LIWC ([Pennebaker et al., 2001](http://downloads.liwc.net.s3.amazonaws.com/LIWC2015_OperatorManual.pdf)). This\n",
        "\n",
        "2. **ktrain** ([Maiya, 2022](https://github.com/amaiya/ktrain)): This package is a Keras wrapper for streamlining many tasks related to fine-tuning and deploying deep learning models. In this notebook we use it to fine-tune Google's BERT ([Devlin et al., 2019](https://arxiv.org/abs/1810.04805)) base model.\n",
        "\n",
        "3. **eli5** ([Korobov, 2017](https://av.tib.eu/media/33771);[Korobov & Lopuhin, 2024](https://github.com/eli5-org/eli5)): \"Explain like I'm five\" is a package used for running the LIME ([Ribeiro et al., 2016](http://arxiv.org/abs/1602.04938)) algorithm to examine how a supervised classifier is making its predictions.\n",
        "\n",
        "4. **openai** ([OpenAI et al., 2024](https://platform.openai.com/docs/api-reference/introduction\n",
        " )): This package accesses the OpenAI API for using GPT-4o within the notebook.\n",
        "\n",
        "5. **textstat** ([Shivan & Chaitanya, 2024](https://pypi.org/project/textstat/)): This package calculates simple statistical information relating to raw text data.\n"
      ],
      "metadata": {
        "id": "l1uWzkOxkBaG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ktrain relies on the tf-keras: keras with added tensorflow functionality\n",
        "!pip install tf-keras\n",
        "import os\n",
        "os.environ['TF_USE_LEGACY_KERAS'] = '1'"
      ],
      "metadata": {
        "id": "gSL_QCLYXKXO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3xHt9VHlgZMO",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# For Supervised classifier\n",
        "!pip install ktrain\n",
        "# For revealing under the classifier black box\n",
        "!pip install https://github.com/amaiya/eli5-tf/archive/refs/heads/master.zip\n",
        "# For LLM classifier\n",
        "!pip install openai\n",
        "# For summary statistics\n",
        "!pip install textstat\n",
        "# This is a port from Gwet's R package with the same name\n",
        "!pip install irrCAC"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# General use packages\n",
        "import requests, zipfile, io, os, psutil, random, time\n",
        "import torch\n",
        "import pandas as pd\n",
        "# This deactivates a warning from Pandas that frequently prints\n",
        "pd.options.mode.chained_assignment = None  # default='warn'\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "from tqdm import tqdm\n",
        "# For descriptive statistics\n",
        "from textstat.textstat import textstatistics\n",
        "import re\n",
        "# Performance evaluations for binary classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report, precision_recall_curve, auc, roc_auc_score, matthews_corrcoef\n",
        "# For calculating inter-rater reliability\n",
        "from irrCAC.raw import CAC\n",
        "#for troubleshooting\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from wordcloud import WordCloud\n",
        "from nltk import agreement\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "# Plotting\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams['figure.dpi'] = 120"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KJGGvaNX8hPy",
        "outputId": "9d488785-b865-4f0c-a1e8-9bf4a8543b44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for rule-based classification\n",
        "import spacy\n",
        "from spacy.matcher import Matcher\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "metadata": {
        "id": "wViVC6AFS19y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for supervised classification\n",
        "import ktrain\n",
        "from ktrain import text\n",
        "# for LLM classification\n",
        "import openai"
      ],
      "metadata": {
        "id": "_BQVFG7MKqJi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check system GPU (recommended if possible)\n",
        "# CPU cores\n",
        "num_cpu_cores = os.cpu_count()\n",
        "print(f\"Number of CPU cores: {num_cpu_cores}\")\n",
        "# GPU details\n",
        "if torch.cuda.is_available():\n",
        "    gpu_name = torch.cuda.get_device_name(0)\n",
        "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / (1024 ** 3)  # in GB\n",
        "    print(f\"GPU Name: {gpu_name}\")\n",
        "    print(f\"GPU Memory: {gpu_memory:.2f} GB\")\n",
        "else:\n",
        "    print(\"No GPU available.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mT0gjhlD8lsl",
        "outputId": "b9c1b34b-f9cc-4699-e39c-59da0e7a1622"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of CPU cores: 2\n",
            "No GPU available.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load in openai keys for few-shot classifier\n",
        "oai_k = \"your-API-key-here\"\n",
        "openai.organization = \"your-organization-key-here\" #if applicable\n",
        "openai.api_key = oai_k\n",
        "os.environ['OPENAI_API_KEY'] = oai_k"
      ],
      "metadata": {
        "id": "ifDAz7zT9Co3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0.2 Download data and pre-trained BERT model\n",
        "\n",
        "All the data for replication (<50mb) is accessed through a GitHub link and the pre-trained BERT model (1.03GB) from dropbox"
      ],
      "metadata": {
        "id": "9NbRD_KokEAA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download data from GitHub"
      ],
      "metadata": {
        "id": "fUH0ETcp-P6p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download empirical data\n",
        "r = requests.get('https://github.com/alexiamhe93/RAMP_method/blob/main/Dataset/data.zip?raw=true')\n",
        "z = zipfile.ZipFile(io.BytesIO(r.content))\n",
        "z.extractall()\n",
        "\n",
        "# Load data for use across the notebook\n",
        "try:\n",
        "  # Training + Validation data (70%) and Test data (30%) for RAMP and non-iterative\n",
        "  train_test = pd.read_csv(\"data/train_test_data.csv\")\n",
        "  # Throughput results for Manual Coding (1st stage)\n",
        "  St1Through = pd.read_csv(\"data/RAMP_Stage1.csv\")\n",
        "  # Throughput results for Computation (1st stage)\n",
        "  St2Through = pd.read_csv(\"data/RAMP_Stage2.csv\")\n",
        "  # Output results for 1st and 2nd Stage of RAMP / Input for Evaluation (3rd stage)\n",
        "  out = pd.read_csv(\"data/RAMP_Stage3.csv\")\n",
        "  # Results of the non-iterative method for validating RAMP\n",
        "  out_NonIterative = pd.read_csv(\"data/results_OneShot.csv\")\n",
        "except:\n",
        "  # Sometimes the unzip puts the csvs in the directory rather than a data folder\n",
        "  train_test = pd.read_csv(\"train_test_data.csv\")\n",
        "  St1Through = pd.read_csv(\"RAMP_Stage1.csv\")\n",
        "  St2Through = pd.read_csv(\"RAMP_Stage2.csv\")\n",
        "  out = pd.read_csv(\"RAMP_Stage3.csv\")\n",
        "  out_NonIterative = pd.read_csv(\"results_OneShot.csv\")"
      ],
      "metadata": {
        "id": "nTn-uqu8kIS4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split training and test data for RAMP method and non-iterative method.\n",
        "\n",
        "Although the two datasets are the same texts, the train/test split is different as they were stratified for the distribution of Misunderstandings. The non-iterative data has fewer misunderstandings so a new stratification was necessary."
      ],
      "metadata": {
        "id": "K_4XOE9VumBX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train used for training and validation data for developing the classifiers\n",
        "train = train_test[train_test[\"train_test\"] == \"train\"][[\"text\", \"Misunderstanding\"]]\n",
        "# Test withheld for validation - outputs for final classifiers on test data in \"out\" dataframe\n",
        "test = train_test[train_test[\"train_test\"] == \"test\"][[\"text\", \"Misunderstanding\"]]\n",
        "\n",
        "# Training / validation data for the non-iterative method\n",
        "train_NonIterative = train_test[train_test[\"train_test_OneShot\"] == \"train\"][[\"text\", \"Misunderstanding_OneShot\"]]\n",
        "# Test data for the non-iterative method\n",
        "test_NonIterative = train_test[train_test[\"train_test_OneShot\"] == \"test\"][[\"text\", \"Misunderstanding_OneShot\"]]"
      ],
      "metadata": {
        "id": "CnQ3pvB4uKwa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download RAMP supervised classifier model from Dropbox (~1GB). This can take some time if internet is slow ."
      ],
      "metadata": {
        "id": "3GFOZlP3-Eg-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O supervised_model.zip https://www.dropbox.com/scl/fi/5wtuor1ag1gktg6eukqwr/supervised_model.zip?rlkey=nfwxyataobjzt708m3gf27o3s&st=cz5r9lq0&dl=0 --quiet\n",
        "!unzip supervised_model.zip"
      ],
      "metadata": {
        "id": "i6URMHD9-GOY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0.3 Functions used across stages"
      ],
      "metadata": {
        "id": "6gRWX3kBIlkj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TextDataStats:\n",
        "  def __init__(self, df, text_column=\"text\", binary_column=\"Misunderstanding\",\n",
        "               IRR_columns = [\"Coder1\",\"Coder2\",\"Coder3\",\"Coder4\"],\n",
        "               group_column = \"Round\"):\n",
        "    self.df = df\n",
        "    self.text_column = text_column\n",
        "    self.binary_column = binary_column\n",
        "    self.IRR_columns = IRR_columns\n",
        "    self.group_column = group_column\n",
        "\n",
        "  def preprocess_text(self):\n",
        "    \"\"\"\n",
        "    Extracts words and sentences from the text, counts them and adds to the dataframe.\n",
        "    \"\"\"\n",
        "    self.df['words'] = self.df[self.text_column].apply(lambda x: re.findall(r'\\b\\w+\\b', x.lower()))\n",
        "    self.df['word_count'] = self.df['words'].apply(len)\n",
        "\n",
        "  def basic_stats(self):\n",
        "    \"\"\"\n",
        "    Computes basic statistics for overall and grouped data.\n",
        "    \"\"\"\n",
        "    self.preprocess_text()\n",
        "\n",
        "    # General stats\n",
        "    general_stats = self.df.describe(include=[np.number]).loc[['mean', 'std', 'min', '50%', 'max'], ['word_count']]\n",
        "    general_stats.rename(index={'50%': 'median'}, inplace=True)\n",
        "    # Grouped stats by binary column\n",
        "    grouped_stats = self.df.groupby(self.binary_column).agg({\n",
        "        'word_count': ['mean', 'median', 'std', 'min', 'max'],\n",
        "    })\n",
        "    # Binary column distribution\n",
        "    binary_dist = self.df[self.binary_column].value_counts(normalize=True).to_frame('distribution')\n",
        "    return general_stats.round(2), grouped_stats.round(2), binary_dist.round(2)\n",
        "\n",
        "  def BasicReport(self):\n",
        "    \"\"\"\n",
        "    Generates a report combining all statistics in a readable text format.\n",
        "    \"\"\"\n",
        "    general_stats, grouped_stats, binary_dist = self.basic_stats()\n",
        "\n",
        "    # Creating a structured text report\n",
        "    report = \"Text Data Statistics Report\\n\\n\"\n",
        "    report += \"General Statistics:\\n\"\n",
        "    report += general_stats.to_string() + \"\\n\\n\"\n",
        "\n",
        "    report += \"Statistics by Binary Column:\\n\"\n",
        "    for name, group in self.df.groupby(self.binary_column):\n",
        "        report += f\"\\nGroup: {name}\\n\"\n",
        "        report += grouped_stats.loc[name].to_string() + \"\\n\"\n",
        "    return report\n",
        "\n",
        "\n",
        "  def get_IRR(self, df):\n",
        "    \"\"\"\n",
        "    Fetches the absolute agreement, Krippendorff's Alpha, Gwet's AC1\n",
        "    \"\"\"\n",
        "    df = df[self.IRR_columns]\n",
        "    # Get absolute agreement\n",
        "    df = df.astype(int)\n",
        "    IRR_out = []\n",
        "    for i, row in df.iterrows():\n",
        "      for k in list(df.columns):\n",
        "        IRR_out.append([k, str(i), row[k]])\n",
        "    ratingtask = agreement.AnnotationTask(data=IRR_out)\n",
        "    ags = ratingtask.avg_Ao()\n",
        "    # Get Gwet AC1 and K Alpha\n",
        "    cac= CAC(df)\n",
        "    print(cac)\n",
        "    #print(cac_4raters)\n",
        "    Gwet_obj = cac.gwet()\n",
        "    Alpha_obj = cac.krippendorff()\n",
        "    return ags, Alpha_obj, Gwet_obj\n",
        "\n",
        "  def process_object(self, IRR_obj, sig_level = 0.001):\n",
        "    \"\"\"\n",
        "    This processes the cac output for the IRR into two strings for reporting\n",
        "    \"\"\"\n",
        "    s = IRR_obj[\"est\"][\"coefficient_value\"]\n",
        "    ci1 = IRR_obj[\"est\"][\"confidence_interval\"][0]\n",
        "    ci2 = IRR_obj[\"est\"][\"confidence_interval\"][1]\n",
        "    stat_string = f\"{s:.2f} CI = ({ci1:.2f}, {ci2:.2f})\"\n",
        "    Z = IRR_obj[\"est\"][\"z\"]\n",
        "    pval = IRR_obj[\"est\"][\"p_value\"]\n",
        "    if pval < sig_level:\n",
        "      sig_string = f\"z = {Z:.2f}; p < {sig_level}\"\n",
        "    else:\n",
        "      sig_string = f\"z = {Z:.2f}; p = {pval:.3f}\"\n",
        "\n",
        "    return stat_string, sig_string\n",
        "\n",
        "\n",
        "  def IRRreport(self):\n",
        "    \"\"\"\n",
        "    Produces the inter-rater reliability report\n",
        "    \"\"\"\n",
        "    df = self.df.sort_values([self.group_column])\n",
        "    rounds = df[self.group_column].unique()\n",
        "    agreement, alphas_, alpha_sigs_ = [],[],[]\n",
        "    ac1s, ac1s_sigs, ss = [],[],[]\n",
        "    for i in rounds:\n",
        "      tdf = df[df[self.group_column] == i]\n",
        "      ss.append(len(tdf))\n",
        "      ags, alpha_, gwets_ = self.get_IRR(tdf)\n",
        "      agreement.append(ags)\n",
        "      alpha_stat, alpha_sig = self.process_object(alpha_)\n",
        "      alphas_.append(alpha_stat)\n",
        "      alpha_sigs_.append(alpha_sig)\n",
        "\n",
        "      ac1_stat, ac1_sig = self.process_object(gwets_)\n",
        "      ac1s.append(ac1_stat)\n",
        "      ac1s_sigs.append(ac1_sig)\n",
        "\n",
        "    return pd.DataFrame({\"Round\":[\"Round \" + str(i) for i in rounds],\n",
        "                         \"Sample size\":ss, \"Agreement\":agreement,\n",
        "                         \"K's Alpha\":alphas_,\"K's Alpha significance\":alpha_sigs_,\n",
        "                         \"Gwet's AC1\":ac1s,\"Gwet's AC1 significance\":ac1s_sigs,\n",
        "                         })\n",
        "\n",
        "  def get_disagreements(self,n=10, return_df = False):\n",
        "    \"\"\"\n",
        "    Prints n disagreements for the IRR results\n",
        "    \"\"\"\n",
        "    df = self.df\n",
        "    disag = []\n",
        "    for i, row in df.iterrows():\n",
        "      x = 0\n",
        "      for coder in self.IRR_columns:\n",
        "        x += row[coder]\n",
        "      disag.append(x)\n",
        "    df[\"disag\"] = disag\n",
        "    ncoders = len(self.IRR_columns)\n",
        "    df = df[df[\"disag\"] < ncoders]\n",
        "    df = df[df[\"disag\"] > 0]\n",
        "    if return_df:\n",
        "      return df.round(2)\n",
        "    else:\n",
        "      sdf = df.sample(n)\n",
        "      for s in sdf.text:\n",
        "        print(\"----------\")\n",
        "        print(s)\n",
        "\n",
        "  def get_misclassifications(self, n=5, return_all=False):\n",
        "    \"\"\"\n",
        "    Function to report on the misclassifications across all three classifiers.\n",
        "    \"\"\"\n",
        "    df = self.df\n",
        "\n",
        "    def classify(row):\n",
        "      base, fs, sup = int(row[\"Manual\"]), int(row[\"LLM\"]), int(row[\"supervised\"])\n",
        "      if sup == base:\n",
        "        return \"TP (All)\" if base == 1 else \"TN (All)\" if fs == base else \"FP (LLM)\" if base == 0 else \"FN (LLM)\"\n",
        "      else:\n",
        "        return \"FN (supervised)\" if fs == base and base == 1 else \"FP (supervised)\" if fs == base else \"FP (All)\" if base == 1 else \"FN (All)\"\n",
        "\n",
        "    df[\"FN_FP\"] = df.apply(classify, axis=1)\n",
        "\n",
        "    if return_all:\n",
        "      return df\n",
        "\n",
        "    misclassifications = {\n",
        "        \"FP (All)\": df[df.FN_FP == \"FP (All)\"].text.to_list(),\n",
        "        \"FP (supervised)\": df[df.FN_FP == \"FP (supervised)\"].text.to_list(),\n",
        "        \"FP (LLM)\": df[df.FN_FP == \"FP (LLM)\"].text.to_list(),\n",
        "        \"FN (All)\": df[df.FN_FP == \"FN (All)\"].text.to_list(),\n",
        "        \"FN (supervised)\": df[df.FN_FP == \"FN (supervised)\"].text.to_list(),\n",
        "        \"FN (LLM)\": df[df.FN_FP == \"FN (LLM)\"].text.to_list()\n",
        "    }\n",
        "\n",
        "    for key, value in misclassifications.items():\n",
        "      print(f\"--- {key.replace('_', ' ')} count: -- {len(value)}\")\n",
        "\n",
        "    print(f\"\\nPrinting {n} examples of each classifier type.\\n\")\n",
        "\n",
        "    for key, value in misclassifications.items():\n",
        "      print(f\"------ {key.replace('_', ' ').upper()} ------\")\n",
        "      for example in value[:n]:\n",
        "        print(f\"- {example}\")\n",
        "      print(\"--------\")\n",
        "\n",
        "\n",
        "  def RAMP_plot(self, x_col, y_col, group_col,\n",
        "                pastel_colors = ['#77B5FE', '#FF6961', '#B19CD9'],\n",
        "                title=\"\", width=800, height=500, line_width=2, line_opacity=0.5,\n",
        "                font_size=14, tick_size=12):\n",
        "    \"\"\"\n",
        "    Creates a connected scatter plot with customizable font size and tick size\n",
        "    \"\"\"\n",
        "    self.df[group_col] = self.df[group_col].astype('category')\n",
        "\n",
        "    scatter_fig = px.line(self.df, x=x_col, y=y_col, color=group_col,\n",
        "                          title=title, template='plotly_white',\n",
        "                          labels={x_col: x_col, y_col: y_col, group_col: group_col},\n",
        "                          markers=True,\n",
        "                          color_discrete_sequence=pastel_colors)\n",
        "\n",
        "    for group, group_df in self.df.groupby(group_col):\n",
        "        min_x = group_df[x_col].min()\n",
        "        max_x = group_df[x_col].max()\n",
        "        min_y = group_df[group_df[x_col] == min_x][y_col].iloc[0]\n",
        "        max_y = group_df[group_df[x_col] == max_x][y_col].iloc[0]\n",
        "        color_index = group_df[group_col].cat.codes.unique()[0] % len(pastel_colors)\n",
        "        scatter_fig.add_trace(go.Scatter(\n",
        "            x=[min_x, max_x],\n",
        "            y=[min_y, max_y],\n",
        "            mode='lines',\n",
        "            name=f'{group} - Range Line',\n",
        "            line=dict(color=pastel_colors[color_index], width=line_width, dash='dash'),\n",
        "            opacity=line_opacity,\n",
        "            showlegend=False))\n",
        "\n",
        "    # Update layout to include font size and tick size settings\n",
        "    scatter_fig.update_layout(\n",
        "        title=dict(text=title, font=dict(size=font_size)),\n",
        "        xaxis=dict(title=dict(text=x_col, font=dict(size=font_size)),\n",
        "                   tickfont=dict(size=tick_size)),\n",
        "        yaxis=dict(title=dict(text=y_col, font=dict(size=font_size)),\n",
        "                   tickfont=dict(size=tick_size)),\n",
        "        legend=dict(font=dict(size=font_size)),\n",
        "        width=width, height=height\n",
        "    )\n",
        "\n",
        "    scatter_fig.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "gNDmB3xHIu8l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Manual Coding (RAMP method)\n",
        "\n",
        "This section details the results of the manual coding (1st) stage of RAMP."
      ],
      "metadata": {
        "id": "7WBrqsVvvXiL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1 Input\n",
        "\n",
        "The raw dataset contains sentences from online dialogues, sampled from three sources:\n",
        "\n",
        "1. **Reddit conversations from 27 subreddits**: This data was downloaded using the Reddit API by the authors.\n",
        "\n",
        "2. **Twitter Customer Support data**  ([Thought Vector & Axelbrooke, 2017](https://www.kaggle.com/datasets/thoughtvector/customer-support-on-twitter)): This data was downloaded from (Copyright: CC BY-NC-SA 4.0).\n",
        "\n",
        "3. **Wikipedia Talk Pages data** ([Danescu-Niculescu-Mizil et al., 2012](https://convokit.cornell.edu/documentation/wiki.html)): This data was downloaded using Cornell University's [ConvoKit](https://convokit.cornell.edu) Python package (Copyright: CC BY 4.0)\n",
        "\n",
        "**Notes:**\n",
        "\n",
        "> All author names and sentences have been anonymized following ethical guidelines for the study.\n",
        "\n",
        "> As a further precaution, the sentences are shuffled and the source (e.g., Reddit, Twitter) removed from the dataframe."
      ],
      "metadata": {
        "id": "6Q0QqaihHSSW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Manual coded dataset final size\n",
        "print(f\"Full dataset size: {len(train) + len(test)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rBfukRxDvcOL",
        "outputId": "fa6cb4f3-aa29-4694-ba9e-7cecbf2b7b47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Full dataset size: 21982\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Explanation of shared subsamples manual coding\n",
        "tdf = St1Through[St1Through.Round!=\"one-shot\"].drop([\"Coder5\",\"Coder6\"],axis=1).copy()\n",
        "prev_rounds = tdf[tdf.Round!=\"6\"]\n",
        "IRR_sample = tdf[tdf.Round==\"6\"]\n",
        "IRR_texts = IRR_sample.text.to_list()\n",
        "non_IRR_texts = prev_rounds.text.to_list()\n",
        "crossover_texts = [t for t in IRR_texts if t in non_IRR_texts]\n",
        "crossover_df = tdf[tdf.text.isin(crossover_texts)].drop_duplicates()\n",
        "crossover_df.loc[:,\"All_coders\"] = crossover_df.Coder1 + crossover_df.Coder2 + crossover_df.Coder3 + crossover_df.Coder4\n",
        "crossover_df.loc[:,\"All_coders\"] = crossover_df[\"All_coders\"].apply(lambda x: 1 if x > 1 else 0)\n",
        "\n",
        "all_rounds_len = len(tdf)\n",
        "n_crossovers_all = all_rounds_len - len(tdf.text.drop_duplicates())\n",
        "pct_all_cross = round((n_crossovers_all/all_rounds_len)*100,2)\n",
        "IRR_len = len(IRR_sample)\n",
        "n_crossovers = len(crossover_texts)\n",
        "pct_cross= round((n_crossovers/IRR_len)*100,2)\n",
        "n_mis_in_cross = crossover_df.All_coders.sum()\n",
        "pct_mis = round((n_mis_in_cross/n_crossovers)*100,2)\n",
        "print(f\"\"\"\n",
        "There are {all_rounds_len} sentences across all rounds of coding.\n",
        "{n_crossovers_all} ({pct_all_cross}%) sentences were shared across various rounds.\n",
        "\n",
        "The IRR set (Round 6) contains {IRR_len} sentences.\n",
        "Of these sentences, {n_crossovers} ({pct_cross}%) appeared in another round.\n",
        "Of these crossover sentences, {n_mis_in_cross} ({pct_mis}%) were coded for misunderstanding.\n",
        "\"\"\")\n",
        "\n",
        "IRR_df_no_crossovers = IRR_sample[~IRR_sample.text.isin(crossover_texts)]\n",
        "\n",
        "# Get the IRR from the final round of coding\n",
        "IRR_final = tdf[tdf[\"Round\"]==\"6\"]\n",
        "IRR_through = tdf[tdf[\"Round\"]!=\"6\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_v61b-7HMbG",
        "outputId": "8b49c8b7-99fc-448e-a254-96402a09c0df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "There are 6322 sentences across all rounds of coding.\n",
            "378 (5.98%) sentences were shared across various rounds.\n",
            "\n",
            "The IRR set (Round 6) contains 1610 sentences.\n",
            "Of these sentences, 174 (10.81%) appeared in another round.\n",
            "Of these crossover sentences, 16.0 (9.2%) were coded for misunderstanding.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2 Throughput"
      ],
      "metadata": {
        "id": "Ci0ngC2BHryG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tds = TextDataStats(IRR_through)\n",
        "tds.IRRreport().round(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "4UlhXatlHrhI",
        "outputId": "6b0bd9c8-62bf-4c63-c825-0cc6aed0af51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<irrCAC.raw.CAC Subjects: 713, Raters: 4, Categories: [0, 1], Weights: \"identity\">\n",
            "<irrCAC.raw.CAC Subjects: 1228, Raters: 4, Categories: [0, 1], Weights: \"identity\">\n",
            "<irrCAC.raw.CAC Subjects: 1101, Raters: 4, Categories: [0, 1], Weights: \"identity\">\n",
            "<irrCAC.raw.CAC Subjects: 808, Raters: 4, Categories: [0, 1], Weights: \"identity\">\n",
            "<irrCAC.raw.CAC Subjects: 862, Raters: 4, Categories: [0, 1], Weights: \"identity\">\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Round  Sample size  Agreement               K's Alpha  \\\n",
              "0  Round 1          713       0.95  0.57 CI = (0.48, 0.65)   \n",
              "1  Round 2         1228       0.97  0.71 CI = (0.63, 0.78)   \n",
              "2  Round 3         1101       0.97  0.72 CI = (0.66, 0.79)   \n",
              "3  Round 4          808       0.94  0.78 CI = (0.73, 0.82)   \n",
              "4  Round 5          862       0.98  0.76 CI = (0.69, 0.83)   \n",
              "\n",
              "  K's Alpha significance              Gwet's AC1 Gwet's AC1 significance  \n",
              "0   z = 13.27; p < 0.001  0.94 CI = (0.93, 0.96)   z = 132.82; p < 0.001  \n",
              "1   z = 18.77; p < 0.001  0.97 CI = (0.96, 0.98)   z = 257.43; p < 0.001  \n",
              "2   z = 21.51; p < 0.001  0.96 CI = (0.95, 0.97)   z = 205.61; p < 0.001  \n",
              "3   z = 34.45; p < 0.001  0.93 CI = (0.91, 0.94)   z = 104.24; p < 0.001  \n",
              "4   z = 21.29; p < 0.001  0.98 CI = (0.97, 0.98)   z = 240.22; p < 0.001  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-91fa70f5-1f2c-47cf-99d7-2ef8c4165ff1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Round</th>\n",
              "      <th>Sample size</th>\n",
              "      <th>Agreement</th>\n",
              "      <th>K's Alpha</th>\n",
              "      <th>K's Alpha significance</th>\n",
              "      <th>Gwet's AC1</th>\n",
              "      <th>Gwet's AC1 significance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Round 1</td>\n",
              "      <td>713</td>\n",
              "      <td>0.95</td>\n",
              "      <td>0.57 CI = (0.48, 0.65)</td>\n",
              "      <td>z = 13.27; p &lt; 0.001</td>\n",
              "      <td>0.94 CI = (0.93, 0.96)</td>\n",
              "      <td>z = 132.82; p &lt; 0.001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Round 2</td>\n",
              "      <td>1228</td>\n",
              "      <td>0.97</td>\n",
              "      <td>0.71 CI = (0.63, 0.78)</td>\n",
              "      <td>z = 18.77; p &lt; 0.001</td>\n",
              "      <td>0.97 CI = (0.96, 0.98)</td>\n",
              "      <td>z = 257.43; p &lt; 0.001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Round 3</td>\n",
              "      <td>1101</td>\n",
              "      <td>0.97</td>\n",
              "      <td>0.72 CI = (0.66, 0.79)</td>\n",
              "      <td>z = 21.51; p &lt; 0.001</td>\n",
              "      <td>0.96 CI = (0.95, 0.97)</td>\n",
              "      <td>z = 205.61; p &lt; 0.001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Round 4</td>\n",
              "      <td>808</td>\n",
              "      <td>0.94</td>\n",
              "      <td>0.78 CI = (0.73, 0.82)</td>\n",
              "      <td>z = 34.45; p &lt; 0.001</td>\n",
              "      <td>0.93 CI = (0.91, 0.94)</td>\n",
              "      <td>z = 104.24; p &lt; 0.001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Round 5</td>\n",
              "      <td>862</td>\n",
              "      <td>0.98</td>\n",
              "      <td>0.76 CI = (0.69, 0.83)</td>\n",
              "      <td>z = 21.29; p &lt; 0.001</td>\n",
              "      <td>0.98 CI = (0.97, 0.98)</td>\n",
              "      <td>z = 240.22; p &lt; 0.001</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-91fa70f5-1f2c-47cf-99d7-2ef8c4165ff1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-91fa70f5-1f2c-47cf-99d7-2ef8c4165ff1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-91fa70f5-1f2c-47cf-99d7-2ef8c4165ff1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2da4c3ca-b78e-40d9-a7aa-477a0cde7cb0\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2da4c3ca-b78e-40d9-a7aa-477a0cde7cb0')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2da4c3ca-b78e-40d9-a7aa-477a0cde7cb0 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"tds\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Round\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Round 2\",\n          \"Round 5\",\n          \"Round 3\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sample size\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 214,\n        \"min\": 713,\n        \"max\": 1228,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1228,\n          862,\n          1101\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Agreement\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.016431676725154998,\n        \"min\": 0.94,\n        \"max\": 0.98,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.97,\n          0.98,\n          0.95\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"K's Alpha\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"0.71 CI = (0.63, 0.78)\",\n          \"0.76 CI = (0.69, 0.83)\",\n          \"0.72 CI = (0.66, 0.79)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"K's Alpha significance\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"z = 18.77; p < 0.001\",\n          \"z = 21.29; p < 0.001\",\n          \"z = 21.51; p < 0.001\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Gwet's AC1\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"0.97 CI = (0.96, 0.98)\",\n          \"0.98 CI = (0.97, 0.98)\",\n          \"0.96 CI = (0.95, 0.97)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Gwet's AC1 significance\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"z = 257.43; p < 0.001\",\n          \"z = 240.22; p < 0.001\",\n          \"z = 205.61; p < 0.001\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We ended the training at Round 5, as the agreement diminishes from the previous round.\n",
        "\n",
        "We observed that the alpha gets progressively better across the inference loop iterations.\n",
        "\n",
        "We also saw the deceptive nature of absolute agreement. For instance, the low alpha of 0.57 in the first round has 95% agreement is because coders were generally good at recognizing *not* misunderstandings but bad at agreeing on what sentences were misunderstandings. The problem is caused by the skewed nature of the dataset (misunderstandings only 8% of data).\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "k8f3e9R7JJq1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.3 Output\n",
        "\n",
        "The below shows the IRRs for the final round of coding. This was done blind by the coders whilst they scored the final dataset. It used the last version of the codebook (Supplementary Materials A)."
      ],
      "metadata": {
        "id": "twg1bGTWJjzF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tds = TextDataStats(IRR_final)\n",
        "tds.IRRreport().round(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        },
        "id": "sRNxAMzGHnIJ",
        "outputId": "b40b9b57-31a7-466f-93e6-f00c3caa9467"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<irrCAC.raw.CAC Subjects: 1610, Raters: 4, Categories: [0, 1], Weights: \"identity\">\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Round  Sample size  Agreement               K's Alpha  \\\n",
              "0  Round 6         1610       0.98  0.79 CI = (0.74, 0.84)   \n",
              "\n",
              "  K's Alpha significance              Gwet's AC1 Gwet's AC1 significance  \n",
              "0   z = 29.82; p < 0.001  0.98 CI = (0.97, 0.98)   z = 344.58; p < 0.001  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9e02f542-01b3-4aa0-80b6-00248bed23cf\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Round</th>\n",
              "      <th>Sample size</th>\n",
              "      <th>Agreement</th>\n",
              "      <th>K's Alpha</th>\n",
              "      <th>K's Alpha significance</th>\n",
              "      <th>Gwet's AC1</th>\n",
              "      <th>Gwet's AC1 significance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Round 6</td>\n",
              "      <td>1610</td>\n",
              "      <td>0.98</td>\n",
              "      <td>0.79 CI = (0.74, 0.84)</td>\n",
              "      <td>z = 29.82; p &lt; 0.001</td>\n",
              "      <td>0.98 CI = (0.97, 0.98)</td>\n",
              "      <td>z = 344.58; p &lt; 0.001</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9e02f542-01b3-4aa0-80b6-00248bed23cf')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9e02f542-01b3-4aa0-80b6-00248bed23cf button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9e02f542-01b3-4aa0-80b6-00248bed23cf');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"tds\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"Round\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Round 6\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sample size\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 1610,\n        \"max\": 1610,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1610\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Agreement\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.98,\n        \"max\": 0.98,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.98\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"K's Alpha\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"0.79 CI = (0.74, 0.84)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"K's Alpha significance\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"z = 29.82; p < 0.001\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Gwet's AC1\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"0.98 CI = (0.97, 0.98)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Gwet's AC1 significance\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"z = 344.58; p < 0.001\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We found that the coders had good agreement (98%) with moderate inter-rater reliability (Krippendorff's Alpha  = 0.79)."
      ],
      "metadata": {
        "id": "6cms6Wv4KdEt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.3.1 Sense check manual coding output\n",
        "\n",
        "Some sentences were scored previous to the final coding (i.e., during the throughput). To ensure that the inter-rater reliability was not biased by these sentences, we can check the statistics after removing all sentences that appeared in the throughput. This leaves only sentences had not yet scored."
      ],
      "metadata": {
        "id": "3ZBProBJJ2-m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tds = TextDataStats(IRR_df_no_crossovers)\n",
        "tds.IRRreport().round(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        },
        "id": "akCERPsVJxuh",
        "outputId": "acb7fb99-55cb-4fb2-fce2-f6201cf89221"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<irrCAC.raw.CAC Subjects: 1436, Raters: 4, Categories: [0, 1], Weights: \"identity\">\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Round  Sample size  Agreement               K's Alpha  \\\n",
              "0  Round 6         1436       0.98  0.79 CI = (0.74, 0.85)   \n",
              "\n",
              "  K's Alpha significance              Gwet's AC1 Gwet's AC1 significance  \n",
              "0   z = 28.32; p < 0.001  0.98 CI = (0.97, 0.98)   z = 323.78; p < 0.001  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-47ba2401-fe14-4c01-88f2-b61b787d6a57\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Round</th>\n",
              "      <th>Sample size</th>\n",
              "      <th>Agreement</th>\n",
              "      <th>K's Alpha</th>\n",
              "      <th>K's Alpha significance</th>\n",
              "      <th>Gwet's AC1</th>\n",
              "      <th>Gwet's AC1 significance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Round 6</td>\n",
              "      <td>1436</td>\n",
              "      <td>0.98</td>\n",
              "      <td>0.79 CI = (0.74, 0.85)</td>\n",
              "      <td>z = 28.32; p &lt; 0.001</td>\n",
              "      <td>0.98 CI = (0.97, 0.98)</td>\n",
              "      <td>z = 323.78; p &lt; 0.001</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-47ba2401-fe14-4c01-88f2-b61b787d6a57')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-47ba2401-fe14-4c01-88f2-b61b787d6a57 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-47ba2401-fe14-4c01-88f2-b61b787d6a57');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"tds\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"Round\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Round 6\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sample size\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 1436,\n        \"max\": 1436,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1436\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Agreement\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.98,\n        \"max\": 0.98,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.98\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"K's Alpha\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"0.79 CI = (0.74, 0.85)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"K's Alpha significance\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"z = 28.32; p < 0.001\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Gwet's AC1\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"0.98 CI = (0.97, 0.98)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Gwet's AC1 significance\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"z = 323.78; p < 0.001\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We found that the statistics remain almost identical, apart from a marginal increase in the confidence intervals for the Krippendorff's alpha."
      ],
      "metadata": {
        "id": "j901vSR6KYsG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Classifier development (RAMP method)\n",
        "\n",
        "This stage reports the development of three classifiers on training and validation data (throughput) and their performance on the test data (output).\n",
        "\n",
        "The throughput phase reports evaluation metrics across 21 different attempts to improve the classifiers' performance on the training data.\n",
        "\n"
      ],
      "metadata": {
        "id": "JqxQnDCpvdG_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model_report(true_scores, pred_scores, display=True):\n",
        "  \"\"\"\n",
        "  Calculate evaluation metrics.\n",
        "  \"\"\"\n",
        "  # Load true scores and predicted scores\n",
        "  # Check predictions and true scores are the same length\n",
        "  print(f\"true:{len(true_scores)},pred:{len(pred_scores)}\")\n",
        "  # Create confusion matrix\n",
        "  cm = confusion_matrix(true_scores, pred_scores)\n",
        "  # Fetch true/false positives and true/false negatives\n",
        "  TP = cm[1, 1]\n",
        "  FP = cm[0, 1]\n",
        "  TN = cm[0, 0]\n",
        "  # Create classification reports\n",
        "  report = classification_report(true_scores, pred_scores, output_dict=True)\n",
        "  try:\n",
        "    # Fetch evaluation metrics\n",
        "    F1_var = report['1']['f1-score']  # F1 score for class '1'\n",
        "    F1_avg = report['weighted avg']['f1-score']  # Weighted average F1 score\n",
        "    Precision = report['1']['precision']\n",
        "    Recall = report['1']['recall']\n",
        "  except:\n",
        "    F1_var = report['1.0']['f1-score']  # F1 score for class '1'\n",
        "    F1_avg = report['weighted avg']['f1-score']  # Weighted average F1 score\n",
        "    Precision = report['1.0']['precision']\n",
        "    Recall = report['1.0']['recall']\n",
        "  # Calculate precision_recall_curve\n",
        "  precision, recall, thresholds = precision_recall_curve(true_scores, pred_scores)\n",
        "  # Get auea under precision recall curve\n",
        "  AUC_PR = auc(recall, precision)\n",
        "  # Get area under ROC\n",
        "  AUC_ROC = roc_auc_score(true_scores, pred_scores)\n",
        "  mcc = matthews_corrcoef(true_scores, pred_scores)\n",
        "  # Print or save results\n",
        "  if display:\n",
        "    print(f'AUC-PR: {AUC_PR:.2f}\\n')\n",
        "    print(f'AUC-ROC: {AUC_ROC:.2f}\\n')\n",
        "    print(f'MCC: {mcc:.2f}\\n')\n",
        "    print(classification_report(true_scores, pred_scores))\n",
        "  else:\n",
        "    outdf = pd.DataFrame({\"Precision\":[Precision],\n",
        "                          \"Recall\":[Recall],\n",
        "                          \"MCC\":[mcc],\n",
        "                          \"AUC_PR\":[AUC_PR],\n",
        "                          \"AUC_ROC\":[AUC_ROC],\n",
        "                          \"F1_avg\":[F1_avg],\n",
        "                          \"F1_var\":[F1_var],\n",
        "                          \"TP\":[TP],\n",
        "                          \"TN\":[TN],\n",
        "                          \"FP\":[FP],\n",
        "                          \"FN\":[FN]})\n",
        "    return outdf\n",
        "\n",
        "def matthews_correlation_coefficient(tp, tn, fp, fn):\n",
        "    numerator = (tp * tn) - (fp * fn)\n",
        "    denominator = ((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn)) ** 0.5\n",
        "    if denominator == 0:\n",
        "        return 0  # Undefined MCC, return 0 as a safe default\n",
        "    return numerator / denominator"
      ],
      "metadata": {
        "id": "UDpsFk3KNVCj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1 Input\n",
        "\n",
        "The input phase involves splitting the data into train and test data and determining the classifiers for development in the throughput.\n",
        "\n",
        "The three classifiers are:\n",
        "\n",
        "1. A rule-based dictionary classifier; This classifier labels a text as misunderstandings if it identifies any of a pre-defined set of words (the dictionary). We use this for binary classification. However, it can be used for producing a ratio or frequency count of the words. In this case, a ratio is pointless as the short sentences almost never contain two words relating to misunderstandings. The frequency count will mostly be 1 or 0, and therefore a binary classification. Ratios offer more information for longer texts, as these would generate more word counts.  \n",
        "\n",
        "2. A supervised machine learning classifier: This classifier fine-tunes a BERT ([Devlin et al., 2019](https://arxiv.org/abs/1810.04805)) model using the ktrain packages. We also plot the increasing accuracy from the development stage as we explored the use of different parameters.\n",
        "\n",
        "3. A large language model (LLM) classifier: This classifier sends a prompt to GPT-4o (version May 13, 2024) alongside the text to label. It's response is then processed into a binary classification. This is also known as zero-shot or few-shot classification, named after how many empirical examples are included in the prompt ([Brown et al., 2020](https://arxiv.org/abs/2005.14165))."
      ],
      "metadata": {
        "id": "jxIBD7-LvgLG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training and test data split:"
      ],
      "metadata": {
        "id": "O7kXOEyWOyPQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "full_data_size = len(train) + len(test)\n",
        "\n",
        "train_size = len(train)\n",
        "train_pct = round(100*(train_size/full_data_size))\n",
        "test_size = len(test)\n",
        "test_pct = round(100*(test_size/full_data_size))\n",
        "\n",
        "print(f\"\"\"\n",
        "Full data: N = {full_data_size}\n",
        "Training data: n = {train_size} ({train_pct}%)\n",
        "Test data: n = {test_size} ({test_pct}%)\n",
        "\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kb5hDHjuvfgw",
        "outputId": "52620aba-3f13-45f1-ae9f-d86656350c6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Full data: N = 21982\n",
            "Training data: n = 15391 (70%)\n",
            "Test data: n = 6591 (30%)     \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The three classifier have different protocols and parameters that were adjusted in the throughput.\n",
        "\n",
        "1. Rule-based: We adjusted the terms and the term type (words or word sequences) across iterations.\n",
        "\n",
        "2. Supervised: We adjusted the validation/training split, the number of epochs, the batch size, and the learning rate.\n",
        "\n",
        "3. Few-shot: We adjusted the prompt and empirical examples (used with the prompt.\n"
      ],
      "metadata": {
        "id": "QWr5b1-cPwjE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2 Throughput"
      ],
      "metadata": {
        "id": "W-K1ar4fvkHL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2.1 Training and developing classifiers\n",
        "\n",
        "This sub-section provides the code used in the throughput phase of the classification development stage of RAMP.\n",
        "\n",
        "The details for all the classifier parameters (e.g., rule-based terms, supervised hyperparameters, LLM prompts) for the different runs can be found in the `St2Through` dataframe."
      ],
      "metadata": {
        "id": "RUgfO-RPvoYR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Rule-based development"
      ],
      "metadata": {
        "id": "iyoKT7OXv01M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load class for running the rule-based classifier."
      ],
      "metadata": {
        "id": "YAAhs_JswwKh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Rule_based_classifier:\n",
        "  \"\"\"\n",
        "  Function for running the rule-based classifier\n",
        "  \"\"\"\n",
        "  def __init__(self,texts,true_scores):\n",
        "\n",
        "    \"\"\"\n",
        "    Initializes the Classifier with texts and their true classification scores.\n",
        "    \"\"\"\n",
        "    self.texts = texts\n",
        "    self.true_scores = true_scores\n",
        "    self.train_size = len(texts)\n",
        "\n",
        "  # _____________________\n",
        "  # Rule-based classifiers\n",
        "\n",
        "  def add_rule_based_terms(self, terms, mode):\n",
        "    \"\"\"\n",
        "    Adds terms for rule-based classification and sets the type of classification based on the mode.\n",
        "    \"\"\"\n",
        "    if mode == \"pattern\":\n",
        "      self.patterns = terms\n",
        "      self.type_ = \"rule-based-1\"\n",
        "    elif mode == \"lemma\":\n",
        "      self.lemmas = terms\n",
        "      self.type_ = \"rule-based-2\"\n",
        "\n",
        "  def classify_with_spacy_pattern(self, nlp):\n",
        "    \"\"\"\n",
        "    Classifies texts using spaCy's pattern matching for the provided patterns.\n",
        "    \"\"\"\n",
        "    # Initiated the spacy matcher object\n",
        "    matcher = Matcher(nlp.vocab)\n",
        "    # Iterate over patterns and add them to the matcher\n",
        "    for pattern in self.patterns:\n",
        "      matcher.add(pattern[\"label\"], [pattern[\"pattern\"]])\n",
        "    # Count patterns in the training texts and save results\n",
        "    results = []\n",
        "    for text in self.texts:\n",
        "      doc = nlp(text) if text else nlp(\"notext\")\n",
        "      matches = matcher(doc)\n",
        "      results.append(len(matches) > 0)\n",
        "    self.pred_scores = results\n",
        "\n",
        "  def classify_with_spacy_lemma(self, nlp):\n",
        "    \"\"\"\n",
        "    Classifies texts by checking if they contain any of the specified lemmas.\n",
        "    \"\"\"\n",
        "    # Join all words together and convert them to spacy document\n",
        "    doc = nlp(\" \".join(self.lemmas))\n",
        "    # Get lemmas from the spacy document\n",
        "    lemma_set = set(token.lemma_ for token in doc)\n",
        "    # Count lemmas in training texts and save results\n",
        "    results = []\n",
        "    for text in self.texts:\n",
        "        doc = nlp(text.lower()) if text else nlp(\"notext\")\n",
        "        text_lemmas = set(token.lemma_ for token in doc)\n",
        "        results.append(bool(text_lemmas & lemma_set))\n",
        "    self.pred_scores = results\n",
        "\n",
        "  def run_classifier(self):\n",
        "    \"\"\"\n",
        "    Determines the type of classification to use and applies it.\n",
        "    \"\"\"\n",
        "    if self.type_ == \"rule-based-1\":\n",
        "      self.classify_with_spacy_pattern(nlp)\n",
        "    elif self.type_ == \"rule-based-2\":\n",
        "      self.classify_with_spacy_lemma(nlp)\n",
        "    else:\n",
        "      raise ValueError(\"Invalid classifier type specified.\")\n",
        "\n",
        "  def get_model_report(self, display=True):\n",
        "    \"\"\"\n",
        "    Calculate evaluation metrics.\n",
        "    \"\"\"\n",
        "    # Load true scores and predicted scores\n",
        "    true_scores = self.true_scores\n",
        "    pred_scores = self.pred_scores\n",
        "    # Check predictions and true scores are the same length\n",
        "    print(f\"true:{len(true_scores)},pred:{len(pred_scores)}\")\n",
        "    # Create confusion matrix\n",
        "    cm = confusion_matrix(true_scores, pred_scores)\n",
        "    # Fetch true/false positives and true/false negatives\n",
        "    TP = cm[1, 1]\n",
        "    FP = cm[0, 1]\n",
        "    TN = cm[0, 0]\n",
        "    # Create classification reports\n",
        "    report = classification_report(true_scores, pred_scores, output_dict=True)\n",
        "    try:\n",
        "      # Fetch evaluation metrics\n",
        "      F1_var = report['1']['f1-score']  # F1 score for class '1'\n",
        "      F1_avg = report['weighted avg']['f1-score']  # Weighted average F1 score\n",
        "      Precision = report['1']['precision']\n",
        "      Recall = report['1']['recall']\n",
        "    except:\n",
        "      F1_var = report['1.0']['f1-score']  # F1 score for class '1'\n",
        "      F1_avg = report['weighted avg']['f1-score']  # Weighted average F1 score\n",
        "      Precision = report['1.0']['precision']\n",
        "      Recall = report['1.0']['recall']\n",
        "    # Calculate precision_recall_curve\n",
        "    precision, recall, thresholds = precision_recall_curve(true_scores, pred_scores)\n",
        "    # Get auea under precision recall curve\n",
        "    AUC_PR = auc(recall, precision)\n",
        "    # Get area under ROC\n",
        "    AUC_ROC = roc_auc_score(true_scores, pred_scores)\n",
        "    mcc = matthews_corrcoef(self.true_scores, self.pred_scores)\n",
        "    # Print or save results\n",
        "    if display:\n",
        "      print(f'AUC-PR: {AUC_PR:.2f}\\n')\n",
        "      print(f'AUC-ROC: {AUC_ROC:.2f}\\n')\n",
        "      print(f'MCC: {mcc:.2f}\\n')\n",
        "      print(classification_report(true_scores, pred_scores))\n",
        "    else:\n",
        "      outdf = pd.DataFrame({\"Precision\":[Precision],\n",
        "                            \"Recall\":[Recall],\n",
        "                            \"MCC\":[mcc],\n",
        "                            \"AUC_PR\":[AUC_PR],\n",
        "                            \"AUC_ROC\":[AUC_ROC],\n",
        "                            \"F1_avg\":[F1_avg],\n",
        "                            \"F1_var\":[F1_var],\n",
        "                            \"TP\":[TP],\n",
        "                            \"TN\":[TN],\n",
        "                            \"FP\":[FP],\n",
        "                            \"FN\":[FN]})\n",
        "      return outdf\n",
        "\n",
        "  def return_results(self):\n",
        "    return self.pred_scores\n",
        "\n",
        "  def run_model(self, display=True):\n",
        "    \"\"\"\n",
        "    Run the classifier and print model report.\n",
        "    \"\"\"\n",
        "    self.run_classifier()\n",
        "    self.get_model_report(display)\n",
        "\n",
        "  def get_misclassification(self, return_all = False):\n",
        "    \"\"\"\n",
        "    Identify misclassifications.\n",
        "    \"\"\"\n",
        "    df = pd.DataFrame({\"text\":self.texts,\"true\":self.true_scores,\n",
        "                       \"pred\":self.pred_scores})\n",
        "    # Function to classify each row\n",
        "    def classify_row(row):\n",
        "      if row['true'] == 1 and row['pred'] == 1:\n",
        "        return 'TP'\n",
        "      elif row['true'] == 0 and row['pred'] == 1:\n",
        "        return 'FP'\n",
        "      elif row['true'] == 1 and row['pred'] == 0:\n",
        "        return 'FN'\n",
        "      elif row['true'] == 0 and row['pred'] == 0:\n",
        "        return 'TN'\n",
        "    df['Classification'] = df.apply(classify_row, axis=1)\n",
        "    if return_all:\n",
        "      return df\n",
        "    else:\n",
        "      return df[df[\"Classification\"].isin([\"FP\",\"FN\"])]\n",
        "\n",
        "  def preprocess_text(self, text):\n",
        "    \"\"\"\n",
        "    Pre-process text to identify patterns in misclassifications.\n",
        "    \"\"\"\n",
        "    # Load stop words\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    # Initiate lematizer\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    # Tokenize text\n",
        "    words = nltk.word_tokenize(text)\n",
        "    # Lemmatize and remove stop words\n",
        "    cleaned_text = [lemmatizer.lemmatize(word.lower()) for word in words if word.isalnum() and word.lower() not in stop_words]\n",
        "    return ' '.join(cleaned_text)\n",
        "\n",
        "  def plot_misclassifications(self, df, FN_FP=\"FN\"):\n",
        "    \"\"\"\n",
        "    Create wordcloud for misclassifications.\n",
        "    \"\"\"\n",
        "    # Clean text using preprocessing function.\n",
        "    df['cleaned_text'] = df['text'].apply(self.preprocess_text)\n",
        "    # Select fales negatives or false positives.\n",
        "    if FN_FP == \"FN\":\n",
        "      print(\"Word Cloud for False Negatives:\")\n",
        "      texts = \" \".join(df[df['Classification'] == 'FN']['cleaned_text'])\n",
        "    else:\n",
        "      print(\"Word Cloud for False Positives:\")\n",
        "      texts = \" \".join(df[df['Classification'] == 'FP']['cleaned_text'])\n",
        "    # Create and print wordcloud.\n",
        "    wordcloud = WordCloud(width = 800, height = 400, background_color ='white').generate(texts)\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.imshow(wordcloud, interpolation='bilinear')\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "  def add_pred_scores(self,pred_scores):\n",
        "    \"\"\"\n",
        "    Add predicted scores (only used for calculating evaluation metrics).\n",
        "    \"\"\"\n",
        "    self.pred_scores = pred_scores\n",
        "\n"
      ],
      "metadata": {
        "id": "oJScSxKBwrXN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The below shows how to run the classifier and check performance on the training texts."
      ],
      "metadata": {
        "id": "tgwNv6BT5OKE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For exploring the terms used in the throughput.\n",
        "import ast\n",
        "import json\n",
        "def safe_literal_eval(x):\n",
        "  try:\n",
        "    return ast.literal_eval(x)\n",
        "  except (ValueError, SyntaxError):\n",
        "    return json.loads(x)\n",
        "\n",
        "rule_based_terms = St2Through[St2Through[\"Classifier\"] == \"rule-based\"].copy()\n",
        "rule_based_terms = rule_based_terms[['Classifier', 'Order','ClassiTypeStr','PatternOrLemma', 'Terms']]\n",
        "rule_based_terms['Terms'] = rule_based_terms['Terms'].apply(safe_literal_eval)\n",
        "rule_based_terms.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "JrJJ6V5O2jgi",
        "outputId": "62fef7a1-2ca0-498c-dfb7-2c28428c4323"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Classifier  Order ClassiTypeStr PatternOrLemma  \\\n",
              "21  rule-based      1  rule-based-2          lemma   \n",
              "22  rule-based      2  rule-based-2          lemma   \n",
              "23  rule-based      3  rule-based-2          lemma   \n",
              "24  rule-based      4  rule-based-2          lemma   \n",
              "25  rule-based      5  rule-based-2          lemma   \n",
              "\n",
              "                                                Terms  \n",
              "21  [mistook, misunderstood, misread, wtf, mistake...  \n",
              "22  [misapprehend, interpretation, verify, baffle,...  \n",
              "23  [response, redress, misread, misstep, aware, r...  \n",
              "24  [mishandle, misjudgment, saying, approach, awa...  \n",
              "25  [rejection, conversation, stumped, slip, incom...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-401194b2-5381-45a5-8377-8424cc3f5f15\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Classifier</th>\n",
              "      <th>Order</th>\n",
              "      <th>ClassiTypeStr</th>\n",
              "      <th>PatternOrLemma</th>\n",
              "      <th>Terms</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>rule-based</td>\n",
              "      <td>1</td>\n",
              "      <td>rule-based-2</td>\n",
              "      <td>lemma</td>\n",
              "      <td>[mistook, misunderstood, misread, wtf, mistake...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>rule-based</td>\n",
              "      <td>2</td>\n",
              "      <td>rule-based-2</td>\n",
              "      <td>lemma</td>\n",
              "      <td>[misapprehend, interpretation, verify, baffle,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>rule-based</td>\n",
              "      <td>3</td>\n",
              "      <td>rule-based-2</td>\n",
              "      <td>lemma</td>\n",
              "      <td>[response, redress, misread, misstep, aware, r...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>rule-based</td>\n",
              "      <td>4</td>\n",
              "      <td>rule-based-2</td>\n",
              "      <td>lemma</td>\n",
              "      <td>[mishandle, misjudgment, saying, approach, awa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>rule-based</td>\n",
              "      <td>5</td>\n",
              "      <td>rule-based-2</td>\n",
              "      <td>lemma</td>\n",
              "      <td>[rejection, conversation, stumped, slip, incom...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-401194b2-5381-45a5-8377-8424cc3f5f15')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-401194b2-5381-45a5-8377-8424cc3f5f15 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-401194b2-5381-45a5-8377-8424cc3f5f15');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d8bcf42e-3807-47bc-a7db-1478677968ab\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d8bcf42e-3807-47bc-a7db-1478677968ab')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d8bcf42e-3807-47bc-a7db-1478677968ab button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "rule_based_terms",
              "summary": "{\n  \"name\": \"rule_based_terms\",\n  \"rows\": 21,\n  \"fields\": [\n    {\n      \"column\": \"Classifier\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"rule-based\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Order\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6,\n        \"min\": 1,\n        \"max\": 21,\n        \"num_unique_values\": 21,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ClassiTypeStr\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"rule-based-1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"PatternOrLemma\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"pattern\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Terms\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run classifier using the best rule-based classifier from the RAMP method throughput (loop 14).\n",
        "\n",
        "> Note - this takes a very long time on the training data."
      ],
      "metadata": {
        "id": "8S4xAS2vzflb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# training texts for RAMP method\n",
        "texts = train[\"text\"].values\n",
        "# misunderstanding manually coded labels for RAMP method\n",
        "true_scores = train[\"Misunderstanding\"].values\n",
        "# Final terms used in Loop 13 (best performing)\n",
        "terms = rule_based_terms[rule_based_terms[\"Order\"] == 14][\"Terms\"].iloc[0]\n",
        "# Run the classifier\n",
        "RB_Loop14_train = Rule_based_classifier(texts=texts,true_scores=true_scores)\n",
        "RB_Loop14_train.add_rule_based_terms(terms, \"pattern\")\n",
        "RB_Loop14_train.run_classifier()\n",
        "RB_Loop14_train.get_model_report()"
      ],
      "metadata": {
        "id": "QjRGdlWTv-o_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Supervised classifier training"
      ],
      "metadata": {
        "id": "qMMmlFBbv-2r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For classification\n",
        "class supervised_classifier:\n",
        "  \"\"\"\n",
        "  Class for running the supervised classifier\n",
        "  \"\"\"\n",
        "  def __init__(self,texts,true_scores):\n",
        "\n",
        "    \"\"\"\n",
        "    Initializes the Classifier with texts and their true classification scores.\n",
        "    \"\"\"\n",
        "    self.texts = texts\n",
        "    self.true_scores = true_scores\n",
        "    self.train_size = len(texts)\n",
        "\n",
        "  # _____________________\n",
        "  # Supervised machine learning classifier\n",
        "\n",
        "  def add_SML_params(self,\n",
        "                     save_model = False,\n",
        "                     # Proportion of data to use as validation data\n",
        "                     validation_size=0.30,\n",
        "                     batch_size=16,\n",
        "                     learning_rate=2e-5,\n",
        "                     epochs=4,\n",
        "                     BERTmodel=\"bert\",\n",
        "                     preprocess_mode=\"bert\",\n",
        "                     maxlen=30,\n",
        "                     max_features = 50000):\n",
        "    self.type_ = \"supervised\"\n",
        "    self.save_model = save_model\n",
        "    self.validation_size=validation_size\n",
        "    self.batch_size=batch_size\n",
        "    self.learning_rate=learning_rate\n",
        "    self.epochs=epochs\n",
        "    self.BERTmodel=BERTmodel\n",
        "    self.preprocess_mode=preprocess_mode\n",
        "    self.maxlen=maxlen\n",
        "    self.max_features = max_features\n",
        "\n",
        "  def convert_misBinary(self, return_scores = False):\n",
        "    output = []\n",
        "    for pred in self.pred_scores:\n",
        "      if \"not\" in pred.lower():\n",
        "        output.append(0)\n",
        "      else:\n",
        "        output.append(1)\n",
        "    if not return_scores:\n",
        "      self.pred_scores = output\n",
        "    else:\n",
        "      return output\n",
        "\n",
        "  def classify_with_supervised(self):\n",
        "    # create vectors of texts from loaded dataset\n",
        "    validation_size = self.validation_size\n",
        "    preprocess_mode = self.preprocess_mode\n",
        "    sentences = self.texts\n",
        "    true_scores = self.true_scores\n",
        "\n",
        "    print(f\"s:{len(sentences)},ts:{len(true_scores)}, s(ts):{sum(true_scores)}\")\n",
        "    # split dataset into training and validation data - stratify by true scores\n",
        "    trainText, validText, trainScores, validScores = train_test_split(sentences, true_scores,\n",
        "                                                                      test_size=validation_size,\n",
        "                                                                      random_state=10, stratify=true_scores)\n",
        "    # make training dataframe\n",
        "    self.MLTrain = pd.DataFrame({\"text\": trainText, \"Misunderstanding\": [int(x) for x in trainScores]})\n",
        "    # make validation dataframe\n",
        "    self.MLValid = pd.DataFrame({\"text\": validText, \"Misunderstanding\": [int(x) for x in validScores]})\n",
        "    # get validation texts and true scores\n",
        "    self.true_scores = self.MLValid[\"Misunderstanding\"].to_list()\n",
        "    self.texts = self.MLValid[\"text\"].to_list()\n",
        "    # preprocess texts and split into validation data.\n",
        "    (x_train,  y_train), (x_validation, y_validation), preproc = text.texts_from_df(train_df = self.MLTrain, text_column = \"text\",\n",
        "                                                                            label_columns = [\"Misunderstanding\"], val_df = self.MLValid,\n",
        "                                                                            preprocess_mode=preprocess_mode, # embeddings to use\n",
        "                                                                            maxlen=self.maxlen, # max number of words for a document\n",
        "                                                                            max_features = self.max_features) # size of the network\n",
        "    # prime the model\n",
        "    model = text.text_classifier(self.BERTmodel, train_data=(x_train, y_train), preproc=preproc)\n",
        "    # create the learner object and prime the classifier\n",
        "    learner = ktrain.get_learner(model, train_data=(x_train, y_train), batch_size=self.batch_size)\n",
        "    # train the model\n",
        "    learner.fit_onecycle(self.learning_rate, self.epochs)\n",
        "    # save trained model for predictions\n",
        "    self.learner = learner\n",
        "    self.preproc = preproc\n",
        "\n",
        "  def predict_new_texts(self, save_model=False):\n",
        "    \"\"\"\n",
        "    Run classifier on the validation data to calculate evaluation metrics.\n",
        "    \"\"\"\n",
        "    texts_ = self.MLValid\n",
        "    texts_ = texts_[\"text\"].to_list()\n",
        "    learner = self.learner\n",
        "    preproc = self.preproc\n",
        "    predictor = ktrain.get_predictor(learner.model, preproc)\n",
        "    preds = predictor.predict(texts_)\n",
        "    self.predictor = predictor\n",
        "    self.pred_scores = preds\n",
        "    self.convert_misBinary()\n",
        "\n",
        "  def save_SMLmodel(self, wd = os.getcwd()):\n",
        "    \"\"\"\n",
        "    Save the trained classifier to working directory.\n",
        "    \"\"\"\n",
        "    predictor = self.predictor\n",
        "    predictor.save(wd)\n",
        "\n",
        "  def return_learner(self):\n",
        "    return self.learner, self.preproc\n",
        "\n",
        "  def return_MLValid(self):\n",
        "    return self.MLValid\n",
        "  # _____________________\n",
        "  # Functions for running classifiers\n",
        "  def run_classifier(self):\n",
        "    \"\"\"\n",
        "    Run the classifier.\n",
        "    \"\"\"\n",
        "    self.classify_with_supervised()\n",
        "    self.predict_new_texts()\n",
        "\n",
        "\n",
        "  def get_model_report(self, display=True):\n",
        "    \"\"\"\n",
        "    Calculate evaluation metrics.\n",
        "    \"\"\"\n",
        "    # Load true scores and predicted scores\n",
        "    true_scores = self.true_scores\n",
        "    pred_scores = self.pred_scores\n",
        "    # Check predictions and true scores are the same length\n",
        "    print(f\"true:{len(true_scores)},pred:{len(pred_scores)}\")\n",
        "    # Create confusion matrix\n",
        "    cm = confusion_matrix(true_scores, pred_scores)\n",
        "    # Fetch true/false positives and true/false negatives\n",
        "    TP = cm[1, 1]\n",
        "    FP = cm[0, 1]\n",
        "    TN = cm[0, 0]\n",
        "    # Create classification reports\n",
        "    report = classification_report(true_scores, pred_scores, output_dict=True)\n",
        "    try:\n",
        "      # Fetch evaluation metrics\n",
        "      F1_var = report['1']['f1-score']  # F1 score for class '1'\n",
        "      F1_avg = report['weighted avg']['f1-score']  # Weighted average F1 score\n",
        "      Precision = report['1']['precision']\n",
        "      Recall = report['1']['recall']\n",
        "    except:\n",
        "      F1_var = report['1.0']['f1-score']  # F1 score for class '1'\n",
        "      F1_avg = report['weighted avg']['f1-score']  # Weighted average F1 score\n",
        "      Precision = report['1.0']['precision']\n",
        "      Recall = report['1.0']['recall']\n",
        "    # Calculate precision_recall_curve\n",
        "    precision, recall, thresholds = precision_recall_curve(true_scores, pred_scores)\n",
        "    # Get auea under precision recall curve\n",
        "    AUC_PR = auc(recall, precision)\n",
        "    # Get area under ROC\n",
        "    AUC_ROC = roc_auc_score(true_scores, pred_scores)\n",
        "    mcc = matthews_corrcoef(self.true_scores, self.pred_scores)\n",
        "    # Print or save results\n",
        "    if display:\n",
        "      print(f'AUC-PR: {AUC_PR:.2f}\\n')\n",
        "      print(f'AUC-ROC: {AUC_ROC:.2f}\\n')\n",
        "      print(f'MCC: {mcc:.2f}\\n')\n",
        "      print(classification_report(true_scores, pred_scores))\n",
        "    else:\n",
        "      outdf = pd.DataFrame({\"Precision\":[Precision],\n",
        "                            \"Recall\":[Recall],\n",
        "                            \"MCC\":[mcc],\n",
        "                            \"AUC_PR\":[AUC_PR],\n",
        "                            \"AUC_ROC\":[AUC_ROC],\n",
        "                            \"F1_avg\":[F1_avg],\n",
        "                            \"F1_var\":[F1_var],\n",
        "                            \"TP\":[TP],\n",
        "                            \"TN\":[TN],\n",
        "                            \"FP\":[FP],\n",
        "                            \"FN\":[FN]})\n",
        "      return outdf\n",
        "\n",
        "  def return_results(self):\n",
        "    return self.pred_scores\n",
        "\n",
        "  def run_model(self, display=True):\n",
        "    self.run_classifier()\n",
        "    self.get_model_report(display)\n",
        "\n",
        "  def classify_with_SML(self):\n",
        "    \"\"\"\n",
        "    Perform classification using the configured supervised machine learning predictor.\n",
        "    \"\"\"\n",
        "    preds = self.predictor.predict(self.texts)\n",
        "    self.pred_scores = [0 if \"not\" in pred.lower() else 1 for pred in preds]\n",
        "\n",
        "  def add_pred_scores(self,pred_scores):\n",
        "    self.pred_scores = pred_scores\n",
        "\n"
      ],
      "metadata": {
        "id": "cblDp_zPwBVS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The below shows how to train the supervised classifier on the training texts and check performance on the validation data."
      ],
      "metadata": {
        "id": "RX3_VmV7AL3G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For exploring the hyperparameters used in the throughput\n",
        "supervised_hyperparam = St2Through[St2Through[\"Classifier\"] == \"supervised\"]\n",
        "supervised_hyperparam = supervised_hyperparam[['Classifier', 'Order','batch_size', 'epochs', 'learning_rate', 'validation_size']]\n",
        "supervised_hyperparam.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "xg8wtnpLALAv",
        "outputId": "2f525958-ea5a-4c41-e172-d2d0b7561c08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Classifier  Order  batch_size  epochs  learning_rate  validation_size\n",
              "42  supervised      1        32.0     5.0        0.00005              0.3\n",
              "43  supervised      2        16.0     5.0        0.00005              0.3\n",
              "44  supervised      3        64.0     5.0        0.00004              0.3\n",
              "45  supervised      4        64.0     5.0        0.00003              0.3\n",
              "46  supervised      5        64.0     5.0        0.00002              0.3"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-727456ce-5a78-4609-937d-ee4cea2f8c10\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Classifier</th>\n",
              "      <th>Order</th>\n",
              "      <th>batch_size</th>\n",
              "      <th>epochs</th>\n",
              "      <th>learning_rate</th>\n",
              "      <th>validation_size</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>supervised</td>\n",
              "      <td>1</td>\n",
              "      <td>32.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.00005</td>\n",
              "      <td>0.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>supervised</td>\n",
              "      <td>2</td>\n",
              "      <td>16.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.00005</td>\n",
              "      <td>0.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>supervised</td>\n",
              "      <td>3</td>\n",
              "      <td>64.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.00004</td>\n",
              "      <td>0.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>supervised</td>\n",
              "      <td>4</td>\n",
              "      <td>64.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.00003</td>\n",
              "      <td>0.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>supervised</td>\n",
              "      <td>5</td>\n",
              "      <td>64.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.00002</td>\n",
              "      <td>0.3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-727456ce-5a78-4609-937d-ee4cea2f8c10')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-727456ce-5a78-4609-937d-ee4cea2f8c10 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-727456ce-5a78-4609-937d-ee4cea2f8c10');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-99c30a4d-1603-4bf3-808d-c92ef42ad4eb\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-99c30a4d-1603-4bf3-808d-c92ef42ad4eb')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-99c30a4d-1603-4bf3-808d-c92ef42ad4eb button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "supervised_hyperparam",
              "summary": "{\n  \"name\": \"supervised_hyperparam\",\n  \"rows\": 21,\n  \"fields\": [\n    {\n      \"column\": \"Classifier\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"supervised\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Order\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6,\n        \"min\": 1,\n        \"max\": 21,\n        \"num_unique_values\": 21,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"batch_size\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 23.88544087334973,\n        \"min\": 16.0,\n        \"max\": 128.0,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          16.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"epochs\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.6796357567879738,\n        \"min\": 3.0,\n        \"max\": 6.0,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          6.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"learning_rate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0235326314383183e-05,\n        \"min\": 1e-05,\n        \"max\": 5e-05,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          4e-05\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"validation_size\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.047809144373375745,\n        \"min\": 0.1,\n        \"max\": 0.3,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the classifier using the best hyperparameters from the RAMP method throughput (loop 20)."
      ],
      "metadata": {
        "id": "Hsrl6AaI973Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training data texts and true scores\n",
        "texts = train[\"text\"].to_list()\n",
        "true_scores = train[\"Misunderstanding\"].to_list()\n",
        "\n",
        "# Proportion of data used for validation\n",
        "validation_size=0.30\n",
        "batch_size=128\n",
        "learning_rate=2e-5\n",
        "epochs=4\n",
        "\n",
        "# Run the classifier\n",
        "SML_Loop20 = supervised_classifier(texts=texts,true_scores=true_scores)\n",
        "SML_Loop20.add_SML_params(validation_size=validation_size,\n",
        "                          batch_size=batch_size,\n",
        "                          learning_rate=learning_rate,\n",
        "                          epochs=epochs)\n",
        "\n",
        "SML_Loop20.run_model()"
      ],
      "metadata": {
        "id": "v6WvY1_k97gf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### LLM development"
      ],
      "metadata": {
        "id": "FAcWi6TZwBl8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LLM_classifier:\n",
        "  \"\"\"\n",
        "  Class for running the LLM classifier.\n",
        "  \"\"\"\n",
        "  def __init__(self,texts,true_scores):\n",
        "\n",
        "    \"\"\"\n",
        "    Initializes the Classifier with texts and their true classification scores.\n",
        "    \"\"\"\n",
        "    self.texts = texts\n",
        "    self.true_scores = true_scores\n",
        "    self.train_size = len(texts)\n",
        "\n",
        "  # LLMclassifier\n",
        "  def add_prompt_param(self,GPTmodel,role,prompt,suffix,examples=\"\"):\n",
        "    \"\"\"\n",
        "    Add prompt to class.\n",
        "    \"\"\"\n",
        "    self.GPTmodel = GPTmodel\n",
        "    # Join prompt and examples.\n",
        "    self.prompt = \"\\n\".join([prompt,examples,suffix])\n",
        "    self.role = role\n",
        "    self.cost = 0\n",
        "    self.total_tokens = 0\n",
        "\n",
        "  def gptActualCost(self, response):\n",
        "    \"\"\"\n",
        "    Calculates the gpt cost.\n",
        "    \"\"\"\n",
        "    engine = self.GPTmodel\n",
        "    total_tokens=response.usage.total_tokens\n",
        "    total_tokens_1M_units = total_tokens/1000000\n",
        "    if engine=='gpt-4o-2024-05-13':\n",
        "        cost=total_tokens_1M_units*7\n",
        "    elif engine=='gpt-4o-mini':\n",
        "        cost=total_tokens_1M_units*0.15\n",
        "    else:\n",
        "        print('getCost error: engine not found')\n",
        "        return\n",
        "    return cost, total_tokens\n",
        "\n",
        "  def get_llm_response(self,messages,temperature=0, max_tokens = 100, max_attempts = 3):\n",
        "    '''\n",
        "    Function that takes messages format for ChatGPT input and returns the response text.\n",
        "    '''\n",
        "    GPTmodel = self.GPTmodel\n",
        "    for attempt in range(0, max_attempts):\n",
        "      try:\n",
        "        #. request timeout ADD IN\n",
        "        response = openai.chat.completions.create(model=GPTmodel, messages = messages, temperature=temperature, max_tokens=max_tokens)\n",
        "        response_text = response.choices[0].message.content\n",
        "        self.LLMScores.append(response_text)\n",
        "        response_cost, token_count = self.gptActualCost(response)\n",
        "        self.cost += response_cost\n",
        "        self.total_tokens += token_count\n",
        "        break  # If analysis was successful, break out of the retry loop\n",
        "      except Exception as e:\n",
        "        print(f\"Error processing text on attempt {attempt+1}: {e}\")\n",
        "        if attempt + 1 == max_attempts:\n",
        "          print(f\"Skipping text after {max_attempts} failed attempts.\")\n",
        "          response_text\n",
        "    return response_text\n",
        "\n",
        "\n",
        "  def define_messages(self, text_to_classify):\n",
        "    '''\n",
        "    Function for creating a basic messages format from a prompt, a role, and a text to classify (all strings)\n",
        "    '''\n",
        "    prompt = self.prompt\n",
        "    role = self.role\n",
        "    prompt = prompt.format(text_to_classify)\n",
        "    messages = [{'role': 'system', 'content': role},\n",
        "                {'role': 'user', 'content' : prompt}]\n",
        "    return messages\n",
        "\n",
        "  def convert_llm_scores_binary(self, return_scores = False):\n",
        "    '''\n",
        "    Function for converting a string \"Yes\" or \"No\" into binary format - used for the clarification requests\n",
        "    '''\n",
        "    llm_scores = self.pred_scores\n",
        "    new_scores = []\n",
        "    for s in llm_scores:\n",
        "      if \"yes\" in s.lower():\n",
        "        new_scores.append(1)\n",
        "      else:\n",
        "        new_scores.append(0)\n",
        "    if not return_scores:\n",
        "      self.pred_scores = new_scores\n",
        "    else:\n",
        "      return new_scores\n",
        "\n",
        "  def classify_with_fewshot(self,  max_tokens = 100, max_attempts = 3, temperature = 0):\n",
        "    '''\n",
        "    Function for running a prompt over a series of texts (expects a list)\n",
        "    '''\n",
        "\n",
        "    prompt = self.prompt\n",
        "    role = self.role\n",
        "    input_texts = self.texts\n",
        "    GPTmodel = self.GPTmodel\n",
        "    scores = []\n",
        "    for txt in tqdm(input_texts):\n",
        "      message = self.define_messages(txt)\n",
        "      try:\n",
        "        response = self.get_llm_response(message,temperature=temperature,\n",
        "                                         max_tokens=max_tokens, max_attempts=max_attempts)\n",
        "      except:\n",
        "        response = \"Error in response\"\n",
        "      scores.append(response)\n",
        "    self.pred_scores = scores\n",
        "    self.convert_llm_scores_binary()\n",
        "\n",
        "\n",
        "  # _____________________\n",
        "  # Functions for running classifiers\n",
        "  def run_classifier(self):\n",
        "    \"\"\"\n",
        "    Determines the type of classification to use and applies it.\n",
        "    \"\"\"\n",
        "    self.classify_with_fewshot()\n",
        "    cost = self.cost\n",
        "    total_tokens = self.total_tokens\n",
        "    avg_tokens = self.total_tokens / self.train_size\n",
        "    print(f\"This run cost {cost:.2f}$ for {total_tokens} tokens. Average tokens: {avg_tokens:.2f}\")\n",
        "\n",
        "  def get_model_report(self, display=True):\n",
        "    \"\"\"\n",
        "    Calculate evaluation metrics.\n",
        "    \"\"\"\n",
        "    # Load true scores and predicted scores\n",
        "    true_scores = self.true_scores\n",
        "    pred_scores = self.pred_scores\n",
        "    # Check predictions and true scores are the same length\n",
        "    print(f\"true:{len(true_scores)},pred:{len(pred_scores)}\")\n",
        "    # Create confusion matrix\n",
        "    cm = confusion_matrix(true_scores, pred_scores)\n",
        "    # Fetch true/false positives and true/false negatives\n",
        "    TP = cm[1, 1]\n",
        "    FP = cm[0, 1]\n",
        "    TN = cm[0, 0]\n",
        "    # Create classification reports\n",
        "    report = classification_report(true_scores, pred_scores, output_dict=True)\n",
        "    try:\n",
        "      # Fetch evaluation metrics\n",
        "      F1_var = report['1']['f1-score']  # F1 score for class '1'\n",
        "      F1_avg = report['weighted avg']['f1-score']  # Weighted average F1 score\n",
        "      Precision = report['1']['precision']\n",
        "      Recall = report['1']['recall']\n",
        "    except:\n",
        "      F1_var = report['1.0']['f1-score']  # F1 score for class '1'\n",
        "      F1_avg = report['weighted avg']['f1-score']  # Weighted average F1 score\n",
        "      Precision = report['1.0']['precision']\n",
        "      Recall = report['1.0']['recall']\n",
        "    # Calculate precision_recall_curve\n",
        "    precision, recall, thresholds = precision_recall_curve(true_scores, pred_scores)\n",
        "    # Get auea under precision recall curve\n",
        "    AUC_PR = auc(recall, precision)\n",
        "    # Get area under ROC\n",
        "    AUC_ROC = roc_auc_score(true_scores, pred_scores)\n",
        "    mcc = matthews_corrcoef(self.true_scores, self.pred_scores)\n",
        "    # Print or save results\n",
        "    if display:\n",
        "      print(f'AUC-PR: {AUC_PR:.2f}\\n')\n",
        "      print(f'AUC-ROC: {AUC_ROC:.2f}\\n')\n",
        "      print(f'MCC: {mcc:.2f}\\n')\n",
        "      print(classification_report(true_scores, pred_scores))\n",
        "    else:\n",
        "      outdf = pd.DataFrame({\"Precision\":[Precision],\n",
        "                            \"Recall\":[Recall],\n",
        "                            \"MCC\":[mcc],\n",
        "                            \"AUC_PR\":[AUC_PR],\n",
        "                            \"AUC_ROC\":[AUC_ROC],\n",
        "                            \"F1_avg\":[F1_avg],\n",
        "                            \"F1_var\":[F1_var],\n",
        "                            \"TP\":[TP],\n",
        "                            \"TN\":[TN],\n",
        "                            \"FP\":[FP],\n",
        "                            \"FN\":[FN]})\n",
        "      return outdf\n",
        "\n",
        "  def run_model(self, display=True):\n",
        "    \"\"\"\n",
        "    Run the classifier and print model report.\n",
        "    \"\"\"\n",
        "    self.run_classifier()\n",
        "    self.get_model_report(display)\n",
        "\n",
        "  def get_misclassification(self, return_all = False):\n",
        "    df = pd.DataFrame({\"text\":self.texts,\"true\":self.true_scores,\n",
        "                       \"pred\":self.pred_scores})\n",
        "    # Function to classify each row\n",
        "    def classify_row(row):\n",
        "      if row['true'] == 1 and row['pred'] == 1:\n",
        "        return 'TP'\n",
        "      elif row['true'] == 0 and row['pred'] == 1:\n",
        "        return 'FP'\n",
        "      elif row['true'] == 1 and row['pred'] == 0:\n",
        "        return 'FN'\n",
        "      elif row['true'] == 0 and row['pred'] == 0:\n",
        "        return 'TN'\n",
        "    df['Classification'] = df.apply(classify_row, axis=1)\n",
        "    if return_all:\n",
        "      return df\n",
        "    else:\n",
        "      return df[df[\"Classification\"].isin([\"FP\",\"FN\"])]\n",
        "\n",
        "  def preprocess_text(self, text):\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    words = nltk.word_tokenize(text)\n",
        "    cleaned_text = [lemmatizer.lemmatize(word.lower()) for word in words if word.isalnum() and word.lower() not in stop_words]\n",
        "    return ' '.join(cleaned_text)\n",
        "\n",
        "  def plot_misclassifications(self, df, FN_FP=\"FN\"):\n",
        "    df['cleaned_text'] = df['text'].apply(self.preprocess_text)\n",
        "    if FN_FP == \"FN\":\n",
        "      print(\"Word Cloud for False Negatives:\")\n",
        "      texts = \" \".join(df[df['Classification'] == 'FN']['cleaned_text'])\n",
        "    else:\n",
        "      print(\"Word Cloud for False Positives:\")\n",
        "      texts = \" \".join(df[df['Classification'] == 'FP']['cleaned_text'])\n",
        "    wordcloud = WordCloud(width = 800, height = 400, background_color ='white').generate(texts)\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.imshow(wordcloud, interpolation='bilinear')\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "  def return_LLMscores(self):\n",
        "    # For returning the raw LLM output.\n",
        "    return self.LLMScores\n",
        "\n",
        "  def add_pred_scores(self,pred_scores):\n",
        "    self.pred_scores = pred_scores\n",
        "\n",
        "  def return_results(self):\n",
        "    return self.pred_scores"
      ],
      "metadata": {
        "id": "s_PNk8VYwB1m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The below shows how to run the classifier and check performance on the training texts."
      ],
      "metadata": {
        "id": "VbsHtctNDCBA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For exploring the prompts and examples used in the throughput\n",
        "LLM_param = St2Through[St2Through[\"Classifier\"] == \"few-shot\"]\n",
        "LLM_param = LLM_param[['Classifier', 'Order','role', 'prompt']]\n",
        "LLM_param.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "uRAKZ_gSDB1j",
        "outputId": "a910fb34-fa1a-4cfa-d6e9-95f281699ec1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  Classifier  Order                                               role  \\\n",
              "0   few-shot      1  \\nYou are a research assistant tasked with ide...   \n",
              "1   few-shot      2  \\nYou are a research assistant tasked with ide...   \n",
              "2   few-shot      3  \\nYou are a research assistant tasked with ide...   \n",
              "3   few-shot      4  \\nYou are a research assistant tasked with ide...   \n",
              "4   few-shot      5  \\nYou are a research assistant tasked with ide...   \n",
              "\n",
              "                                              prompt  \n",
              "0  \\n\\n\\nDoes the below sentence contain a misund...  \n",
              "1  \\n\\n\\nDoes the below sentence indicate a possi...  \n",
              "2  \\n\\n\\nDoes the below sentence indicate a possi...  \n",
              "3  \\n\\n\\nDoes the below sentence indicate a possi...  \n",
              "4  \\n*Your role*\\nYou are a research assistant ta...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5c2d39f7-0b1f-4151-86fb-c1e7f754b939\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Classifier</th>\n",
              "      <th>Order</th>\n",
              "      <th>role</th>\n",
              "      <th>prompt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>few-shot</td>\n",
              "      <td>1</td>\n",
              "      <td>\\nYou are a research assistant tasked with ide...</td>\n",
              "      <td>\\n\\n\\nDoes the below sentence contain a misund...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>few-shot</td>\n",
              "      <td>2</td>\n",
              "      <td>\\nYou are a research assistant tasked with ide...</td>\n",
              "      <td>\\n\\n\\nDoes the below sentence indicate a possi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>few-shot</td>\n",
              "      <td>3</td>\n",
              "      <td>\\nYou are a research assistant tasked with ide...</td>\n",
              "      <td>\\n\\n\\nDoes the below sentence indicate a possi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>few-shot</td>\n",
              "      <td>4</td>\n",
              "      <td>\\nYou are a research assistant tasked with ide...</td>\n",
              "      <td>\\n\\n\\nDoes the below sentence indicate a possi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>few-shot</td>\n",
              "      <td>5</td>\n",
              "      <td>\\nYou are a research assistant tasked with ide...</td>\n",
              "      <td>\\n*Your role*\\nYou are a research assistant ta...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5c2d39f7-0b1f-4151-86fb-c1e7f754b939')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5c2d39f7-0b1f-4151-86fb-c1e7f754b939 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5c2d39f7-0b1f-4151-86fb-c1e7f754b939');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2c3b6e52-b126-4692-a31d-4053f574e708\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2c3b6e52-b126-4692-a31d-4053f574e708')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2c3b6e52-b126-4692-a31d-4053f574e708 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "LLM_param",
              "summary": "{\n  \"name\": \"LLM_param\",\n  \"rows\": 21,\n  \"fields\": [\n    {\n      \"column\": \"Classifier\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"few-shot\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Order\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6,\n        \"min\": 1,\n        \"max\": 21,\n        \"num_unique_values\": 21,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"role\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 12,\n        \"samples\": [\n          \"\\n*Role*\\nYou are a research assistant tasked with identifying whether a sentence indicates a misunderstanding. \\n*Misunderstanding definition*\\nA misunderstanding occurs during dialogue when one participant has an incorrect understanding of another\\u2019s perspective.\\nThere are two categories of misunderstanding: 1.  \\u201cDirect\\u201d misunderstandings. These occur when a participant evidences a misunderstanding of another participant\\u2019s point. \\n2.  \\u201cFelt\\u201d misunderstandings. These occur when a participant feels their previous turn was misunderstood by another participant.  \\nThis is a non-exhaustive list of possible sentences indicating misunderstanding. \\n1. Explicit statement: The sentence explicitly indicates the speaker doesn't understand another\\u2019s perspective (e.g., \\\"I don't get what you're trying to say about the dog\\\") \\n2. Clarification question: The question seeks to clarify the other\\u2019s perspective (e.g., \\\"What do you mean?\\\")\\n3. Request for confirmation: A question that seeks confirmation on the other\\u2019s understanding of the speaker\\u2019s previous turn(e.g., \\\"You really think that I meant all dogs?\\\") \\n4. Correction of Other: Correcting another speaker\\u2019s misunderstanding of the present speaker\\u2019s previous turn(e.g., \\\"You've misunderstood my point\\\", \\u201cYou don\\u2019t get it.\\u201d) \\n5. Clarification or apology about speaker's intentions: Clarifying the meaning of what the speaker previously said (e.g., \\\"Sorry, I meant to say X\\\") \\n6. Misunderstanding due to lack of response (e.g., \\\"Why did you change the subject?\\\") \\n7. Editing a message at a later time: This is when a speaker in text-based dialogue comes back to edit their comment after the fact (e.g., \\\"EDIT\\\": That's what I said)\\nHere are some examples of sentences indicating misunderstandings::\\n- Jane, that article was what I was talking about.\\n- Why not go further? \\n- Do you think that was ok? \\n- I apologise for saying that, but I meant the other stuff. \\n- @John But when? \\n- @John Please tell me why I've been stuck here for so long. \\n- What drove that thought? \\n- I actually said \\\"sure thing\\\". \\n- You serious? \\n- I'm not sure what I could have done differently.\\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"prompt\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 16,\n        \"samples\": [\n          \"\\n\\n\\nDoes the below sentence contain a misunderstanding?\\nOnly respond with \\\"Yes\\\" or \\\"No\\\"\\nSentence: {} \\nResponse:\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run classifier on training data for best prompt (Loop 13)"
      ],
      "metadata": {
        "id": "AtsFrojUEAgX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training data texts and true scores\n",
        "texts = train[\"text\"].to_list()\n",
        "true_scores = train[\"Misunderstanding\"].to_list()\n",
        "\n",
        "# GPT model\n",
        "GPTmodel = \"gpt-4o-2024-05-13\"\n",
        "# fetch role from the LLM_param dataframe (loop 13)\n",
        "role = LLM_param[LLM_param[\"Order\"] == 13][\"role\"].iloc[0]\n",
        "# fetch prompt from the LLM_param dataframe (loop 13)\n",
        "prompt = LLM_param[LLM_param[\"Order\"] == 13][\"prompt\"].iloc[0]\n",
        "\n",
        "# Run classifier\n",
        "FS_Loop13 = LLM_classifier(texts=texts,true_scores=true_scores)\n",
        "FS_Loop13.add_prompt_param(GPTmodel=GPTmodel,role=role,prompt=prompt)\n",
        "FS_Loop13.run_model()"
      ],
      "metadata": {
        "id": "XIkYROhzEJVu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2.2 Results"
      ],
      "metadata": {
        "id": "_7Vgu5ejwDgP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "These two plots show the classifier performance on the Matthews Correlation Coefficient (MCC) and the Weighted F1 for the classifiers.\n",
        "\n",
        "Each point indicates a change in the input parameters of the classifier. For the rule-based classifier, this was adding and altering the words. For the supervised classifier, this was altering the hyper-parameters. For the few-shot classifier, this was changing the prompt."
      ],
      "metadata": {
        "id": "V5L9q5tqNzpR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "target_cols = [\"Order\",\"Classifier\",\"F1_avg\",\"F1_var\",\"AUC_PR\", \"AUC_ROC\",\"Precision\",\"Recall\",\"FP\",\"FN\",\"TP\",\"TN\"]\n",
        "ThroughRes = St2Through[target_cols].round(2).sort_values(\"AUC_PR\", ascending = False)\n",
        "ThroughRes[\"Matthews Correlation Coefficient\"] = ThroughRes.apply(lambda row: matthews_correlation_coefficient(row[\"TP\"],row[\"TN\"],row[\"FP\"],row[\"FN\"]), axis=1)\n",
        "ThroughRes = ThroughRes.rename(columns={\"F1_avg\": \"Weighted F1\"})\n",
        "tdf = ThroughRes.sort_values(by=[\"Order\",\"Classifier\"])"
      ],
      "metadata": {
        "id": "9Jw2GCMswDKH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tdf = tdf.replace({\"few-shot\":\"LLM\"})\n",
        "tds = TextDataStats(tdf)\n",
        "tds.RAMP_plot(\"Order\", \"Matthews Correlation Coefficient\",\"Classifier\", width=1100,height=700, font_size = 20, tick_size=17)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 717
        },
        "id": "Z27OqtmMvw0T",
        "outputId": "29c17f2e-ca8f-42ce-e8dd-25198ea75b84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"dafd6d19-eb6e-4537-88f3-dc9bfcf54e08\" class=\"plotly-graph-div\" style=\"height:700px; width:1100px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"dafd6d19-eb6e-4537-88f3-dc9bfcf54e08\")) {                    Plotly.newPlot(                        \"dafd6d19-eb6e-4537-88f3-dc9bfcf54e08\",                        [{\"hovertemplate\":\"Classifier=LLM\\u003cbr\\u003eOrder=%{x}\\u003cbr\\u003eMatthews Correlation Coefficient=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"LLM\",\"line\":{\"color\":\"#77B5FE\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines+markers\",\"name\":\"LLM\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21],\"xaxis\":\"x\",\"y\":[0.04155057467859536,0.23253419377124737,0.2872648322419155,0.3788620955042638,0.45050226031417195,0.45622944725159137,0.4388519509665063,0.4297266920675937,0.43390417958812666,0.4226985961116316,0.38181025231378946,0.37195016180963997,0.5103408004015701,0.4513002843209721,0.4223994623196093,0.3760396575601762,0.4100377518375483,0.44933985572791046,0.4867082070959006,0.4396002217946111,0.4469235978386974],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":\"Classifier=rule-based\\u003cbr\\u003eOrder=%{x}\\u003cbr\\u003eMatthews Correlation Coefficient=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"rule-based\",\"line\":{\"color\":\"#FF6961\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines+markers\",\"name\":\"rule-based\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21],\"xaxis\":\"x\",\"y\":[0.015568081914519931,0.06295492360573066,0.12544249960349563,0.1339989857899664,0.18756566942339511,0.20992750561486523,0.20992750561486523,0.21061803720203995,0.21061803720203995,0.2133748599824115,0.2133748599824115,0.21406274533684738,0.21406274533684738,0.21526051222535336,0.17458096995085534,0.15103669048887527,0.187213025740682,0.13644631346657118,0.1883649275156507,0.17092233631676323,0.1814268484369643],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":\"Classifier=supervised\\u003cbr\\u003eOrder=%{x}\\u003cbr\\u003eMatthews Correlation Coefficient=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"supervised\",\"line\":{\"color\":\"#B19CD9\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines+markers\",\"name\":\"supervised\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21],\"xaxis\":\"x\",\"y\":[0.5754351411550477,0.5861444096527617,0.5904565786928206,0.6107896411354067,0.6374342425993592,0.6313637360269997,0.6164541426816715,0.6327040852450997,0.6442486824149336,0.6153172923741053,0.6143894156366835,0.6376964437031357,0.6280373432660777,0.5987459987395344,0.6063771273032497,0.5912067350962279,0.6416549304497944,0.6174259758483488,0.6220384979247013,0.6467041398429002,0.623007382245237],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"line\":{\"color\":\"#77B5FE\",\"dash\":\"dash\",\"width\":2},\"mode\":\"lines\",\"name\":\"LLM - Range Line\",\"opacity\":0.5,\"showlegend\":false,\"x\":[1,21],\"y\":[0.04155057467859536,0.4469235978386974],\"type\":\"scatter\"},{\"line\":{\"color\":\"#FF6961\",\"dash\":\"dash\",\"width\":2},\"mode\":\"lines\",\"name\":\"rule-based - Range Line\",\"opacity\":0.5,\"showlegend\":false,\"x\":[1,21],\"y\":[0.015568081914519931,0.1814268484369643],\"type\":\"scatter\"},{\"line\":{\"color\":\"#B19CD9\",\"dash\":\"dash\",\"width\":2},\"mode\":\"lines\",\"name\":\"supervised - Range Line\",\"opacity\":0.5,\"showlegend\":false,\"x\":[1,21],\"y\":[0.5754351411550477,0.623007382245237],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Order\",\"font\":{\"size\":20}},\"tickfont\":{\"size\":17}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Matthews Correlation Coefficient\",\"font\":{\"size\":20}},\"tickfont\":{\"size\":17}},\"legend\":{\"title\":{\"text\":\"Classifier\"},\"tracegroupgap\":0,\"font\":{\"size\":20}},\"margin\":{\"t\":60},\"title\":{\"font\":{\"size\":20},\"text\":\"\"},\"width\":1100,\"height\":700},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('dafd6d19-eb6e-4537-88f3-dc9bfcf54e08');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tds.RAMP_plot(\"Order\", \"Weighted F1\",\"Classifier\", width=1100,height=700)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 717
        },
        "id": "-Df58n1mN0Nq",
        "outputId": "c49ca026-47a5-4771-b686-73bd018eaf3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"f178306f-37c8-4f04-8f28-14a0bcf2caa9\" class=\"plotly-graph-div\" style=\"height:700px; width:1100px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"f178306f-37c8-4f04-8f28-14a0bcf2caa9\")) {                    Plotly.newPlot(                        \"f178306f-37c8-4f04-8f28-14a0bcf2caa9\",                        [{\"hovertemplate\":\"Classifier=LLM\\u003cbr\\u003eOrder=%{x}\\u003cbr\\u003eWeighted F1=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"LLM\",\"line\":{\"color\":\"#77B5FE\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines+markers\",\"name\":\"LLM\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21],\"xaxis\":\"x\",\"y\":[0.79,0.78,0.86,0.87,0.88,0.91,0.88,0.88,0.87,0.88,0.88,0.86,0.91,0.91,0.88,0.84,0.87,0.9,0.91,0.88,0.9],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":\"Classifier=rule-based\\u003cbr\\u003eOrder=%{x}\\u003cbr\\u003eWeighted F1=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"rule-based\",\"line\":{\"color\":\"#FF6961\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines+markers\",\"name\":\"rule-based\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21],\"xaxis\":\"x\",\"y\":[0.85,0.85,0.82,0.81,0.82,0.87,0.87,0.87,0.87,0.87,0.87,0.87,0.87,0.87,0.83,0.79,0.78,0.78,0.76,0.75,0.74],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":\"Classifier=supervised\\u003cbr\\u003eOrder=%{x}\\u003cbr\\u003eWeighted F1=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"supervised\",\"line\":{\"color\":\"#B19CD9\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines+markers\",\"name\":\"supervised\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21],\"xaxis\":\"x\",\"y\":[0.93,0.93,0.93,0.93,0.94,0.94,0.93,0.94,0.94,0.93,0.93,0.94,0.93,0.93,0.93,0.93,0.94,0.93,0.93,0.94,0.93],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"line\":{\"color\":\"#77B5FE\",\"dash\":\"dash\",\"width\":2},\"mode\":\"lines\",\"name\":\"LLM - Range Line\",\"opacity\":0.5,\"showlegend\":false,\"x\":[1,21],\"y\":[0.79,0.9],\"type\":\"scatter\"},{\"line\":{\"color\":\"#FF6961\",\"dash\":\"dash\",\"width\":2},\"mode\":\"lines\",\"name\":\"rule-based - Range Line\",\"opacity\":0.5,\"showlegend\":false,\"x\":[1,21],\"y\":[0.85,0.74],\"type\":\"scatter\"},{\"line\":{\"color\":\"#B19CD9\",\"dash\":\"dash\",\"width\":2},\"mode\":\"lines\",\"name\":\"supervised - Range Line\",\"opacity\":0.5,\"showlegend\":false,\"x\":[1,21],\"y\":[0.93,0.93],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Order\",\"font\":{\"size\":14}},\"tickfont\":{\"size\":12}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Weighted F1\",\"font\":{\"size\":14}},\"tickfont\":{\"size\":12}},\"legend\":{\"title\":{\"text\":\"Classifier\"},\"tracegroupgap\":0,\"font\":{\"size\":14}},\"margin\":{\"t\":60},\"title\":{\"font\":{\"size\":14},\"text\":\"\"},\"width\":1100,\"height\":700},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('f178306f-37c8-4f04-8f28-14a0bcf2caa9');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The below shows the best classifiers from the throughput section, calculated on validation data (i.e., proportion of the training data)."
      ],
      "metadata": {
        "id": "QQc2PRSeRMSG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate MCC\n",
        "St2Through[\"MCC\"] = St2Through.apply(lambda row: matthews_correlation_coefficient(row[\"TP\"],row[\"TN\"],row[\"FP\"],row[\"FN\"]), axis=1)"
      ],
      "metadata": {
        "id": "8dmxTv58Rw9-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Best rule-based classifier (loop 14)\n",
        "ruleBased_best = St2Through[[\"Order\",\"Classifier\",\"F1_avg\",\"AUC_PR\",\"MCC\", \"Precision\",\"Recall\",\"PatternOrLemma\",\"train_size\",\"nTerms\"]].rename(columns={\"train_size\":\"validation_N\"})\n",
        "ruleBased_best[ruleBased_best[\"Classifier\"]==\"rule-based\"].sort_values(\"MCC\", ascending = False).head(1).round(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "d3nA3yfCRlu1",
        "outputId": "f557a9e1-8644-4ebe-8646-50d9c3d7d274"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Order  Classifier  F1_avg  AUC_PR   MCC  Precision  Recall PatternOrLemma  \\\n",
              "34     14  rule-based    0.87    0.32  0.22       0.33    0.24        pattern   \n",
              "\n",
              "    validation_N  nTerms  \n",
              "34         14728    10.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b9719df9-0a22-4949-a5d5-f82343e95b1d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Order</th>\n",
              "      <th>Classifier</th>\n",
              "      <th>F1_avg</th>\n",
              "      <th>AUC_PR</th>\n",
              "      <th>MCC</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>PatternOrLemma</th>\n",
              "      <th>validation_N</th>\n",
              "      <th>nTerms</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>14</td>\n",
              "      <td>rule-based</td>\n",
              "      <td>0.87</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.33</td>\n",
              "      <td>0.24</td>\n",
              "      <td>pattern</td>\n",
              "      <td>14728</td>\n",
              "      <td>10.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b9719df9-0a22-4949-a5d5-f82343e95b1d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b9719df9-0a22-4949-a5d5-f82343e95b1d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b9719df9-0a22-4949-a5d5-f82343e95b1d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"rbdf[rbdf[\\\"Classifier\\\"]==\\\"rule-based\\\"]\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"Order\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 14,\n        \"max\": 14,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          14\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Classifier\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"rule-based\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1_avg\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.87,\n        \"max\": 0.87,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.87\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AUC_PR\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.32,\n        \"max\": 0.32,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.32\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MCC\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.22,\n        \"max\": 0.22,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.22\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.33,\n        \"max\": 0.33,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.33\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.24,\n        \"max\": 0.24,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.24\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"PatternOrLemma\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"pattern\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"validation_N\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 14728,\n        \"max\": 14728,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          14728\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"nTerms\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 10.0,\n        \"max\": 10.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          10.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Best supervised classifier and parameters (loop 20)\n",
        "supervised_best = St2Through[[\"Order\",\"Classifier\",\"F1_avg\",\"AUC_PR\", \"MCC\",\"Precision\",\"Recall\",\"validation_size\",\"epochs\",\"learning_rate\",\"batch_size\"]].rename(columns={\"validation_size\":\"validation_proportion\"})\n",
        "supervised_best[supervised_best[\"Classifier\"]==\"supervised\"].sort_values(\"MCC\", ascending = False).head(1).round(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "S9ULYcXXN04r",
        "outputId": "1724e0cc-f6ae-4e34-ffad-26b3c672e1b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Order  Classifier  F1_avg  AUC_PR   MCC  Precision  Recall  \\\n",
              "61     20  supervised    0.94     0.7  0.65       0.74    0.62   \n",
              "\n",
              "    validation_size  epochs  learning_rate  batch_size  \n",
              "61              0.3     4.0            0.0       128.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1dba216f-30c3-4634-bb3f-d930f7f0f25b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Order</th>\n",
              "      <th>Classifier</th>\n",
              "      <th>F1_avg</th>\n",
              "      <th>AUC_PR</th>\n",
              "      <th>MCC</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>validation_size</th>\n",
              "      <th>epochs</th>\n",
              "      <th>learning_rate</th>\n",
              "      <th>batch_size</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>20</td>\n",
              "      <td>supervised</td>\n",
              "      <td>0.94</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.74</td>\n",
              "      <td>0.62</td>\n",
              "      <td>0.3</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>128.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1dba216f-30c3-4634-bb3f-d930f7f0f25b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1dba216f-30c3-4634-bb3f-d930f7f0f25b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1dba216f-30c3-4634-bb3f-d930f7f0f25b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"supdf[supdf[\\\"Classifier\\\"]==\\\"supervised\\\"]\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"Order\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 20,\n        \"max\": 20,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          20\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Classifier\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"supervised\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1_avg\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.94,\n        \"max\": 0.94,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.94\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AUC_PR\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.7,\n        \"max\": 0.7,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MCC\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.65,\n        \"max\": 0.65,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.65\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.74,\n        \"max\": 0.74,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.74\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.62,\n        \"max\": 0.62,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.62\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"validation_size\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.3,\n        \"max\": 0.3,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"epochs\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 4.0,\n        \"max\": 4.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          4.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"learning_rate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"batch_size\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 128.0,\n        \"max\": 128.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          128.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Best LLM classifiers (loop 13)\n",
        "LLM_best = St2Through[[\"Order\",\"Classifier\",\"F1_avg\",\"AUC_PR\", \"MCC\",\"Precision\",\"Recall\", \"train_size\",\"GPTmodel\"]].rename(columns={\"train_size\":\"validation_N\"})\n",
        "LLM_best[LLM_best[\"Classifier\"]==\"few-shot\"].sort_values(\"MCC\", ascending = False).head(1).round(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "U6v7caJSN02T",
        "outputId": "4ed4caa4-5e46-4a9a-e759-47b3cf61dec7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Order Classifier  F1_avg  AUC_PR   MCC  Precision  Recall  validation_N  \\\n",
              "12     13   few-shot    0.91    0.58  0.51       0.54    0.59          1000   \n",
              "\n",
              "       GPTmodel  \n",
              "12  gpt-4-turbo  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-683b3869-3615-4998-984f-87d11df6d0de\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Order</th>\n",
              "      <th>Classifier</th>\n",
              "      <th>F1_avg</th>\n",
              "      <th>AUC_PR</th>\n",
              "      <th>MCC</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>validation_N</th>\n",
              "      <th>GPTmodel</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>13</td>\n",
              "      <td>few-shot</td>\n",
              "      <td>0.91</td>\n",
              "      <td>0.58</td>\n",
              "      <td>0.51</td>\n",
              "      <td>0.54</td>\n",
              "      <td>0.59</td>\n",
              "      <td>1000</td>\n",
              "      <td>gpt-4-turbo</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-683b3869-3615-4998-984f-87d11df6d0de')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-683b3869-3615-4998-984f-87d11df6d0de button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-683b3869-3615-4998-984f-87d11df6d0de');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"rbdf[rbdf[\\\"Classifier\\\"]==\\\"few-shot\\\"]\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"Order\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 13,\n        \"max\": 13,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          13\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Classifier\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"few-shot\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1_avg\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.91,\n        \"max\": 0.91,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.91\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AUC_PR\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.58,\n        \"max\": 0.58,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.58\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MCC\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.51,\n        \"max\": 0.51,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.51\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.54,\n        \"max\": 0.54,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.54\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.59,\n        \"max\": 0.59,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.59\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"validation_N\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 1000,\n        \"max\": 1000,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1000\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"GPTmodel\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"gpt-4-turbo\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.3 Output\n",
        "\n",
        "The below details the evaluation of the three classifiers on the test data, withheld from the throughput stage. We fetch the true scores from the test data:"
      ],
      "metadata": {
        "id": "rLGzncfnSdhu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "true_scores = out.Misunderstanding.to_list()"
      ],
      "metadata": {
        "id": "L0_sPDW1T4ZB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3.1 Rule-based classifier"
      ],
      "metadata": {
        "id": "IXqrWohnSvde"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set the terms (from throughput loop 14):"
      ],
      "metadata": {
        "id": "gjDLkgtjULem"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "terms = [{\"label\":\"MISUNDERSTANDING\",\"pattern\":[{\"LOWER\":{\"IN\":[\"what\",\"why\"]}},{\"OP\":\"*\",\"POS\":\"AUX\"},{\"POS\":\"VERB\",\"OP\":\"*\"},{\"IS_PUNCT\":True,\"OP\":\"?\"}]},\n",
        "          {\"label\":\"MISUNDERSTANDING\",\"pattern\":[{\"LOWER\":\"what\"},{\"LOWER\":\"do\"},{\"LOWER\":\"you\"},{\"LOWER\":\"mean\"},{\"IS_PUNCT\":True,\"OP\":\"?\"}]},\n",
        "            {\"label\":\"MISUNDERSTANDING\",\"pattern\":[{\"LOWER\":\"could\"},{\"LOWER\":\"you\"},{\"LEMMA\":{\"IN\":[\"elaborate\",\"expand\",\"explain\"]}},{\"OP\":\"?\",\"IS_PUNCT\":True}]},\n",
        "             {\"label\":\"MISUNDERSTANDING\",\"pattern\":[{\"LOWER\":\"i\"},{\"LOWER\":\"don't\"},{\"LEMMA\":\"understand\"}]},\n",
        "              {\"label\":\"MISUNDERSTANDING\",\"pattern\":[{\"LOWER\":{\"IN\":[\"sorry\",\"pardon\",\"excuse\"]}},{\"LOWER\":\"me\"},{\"LOWER\":\"could\"},{\"LOWER\":\"you\"},{\"LOWER\":\"repeat\"},{\"OP\":\"?\",\"IS_PUNCT\":True}]},\n",
        "               {\"label\":\"MISUNDERSTANDING\",\"pattern\":[{\"LOWER\":\"are\"},{\"LOWER\":\"you\"},{\"LOWER\":\"saying\"},{\"IS_ALPHA\":True,\"OP\":\"+\"},{\"OP\":\"?\",\"IS_PUNCT\":True}]},\n",
        "                {\"label\":\"MISUNDERSTANDING\",\"pattern\":[{\"LEMMA\":{\"IN\":[\"misinterpret\",\"misunderstand\",\"misconstrue\"]}},{\"POS\":\"ADP\"},{\"IS_ALPHA\":True,\"OP\":\"+\"}]},\n",
        "                 {\"label\":\"MISUNDERSTANDING\",\"pattern\":[{\"LOWER\":{\"IN\":[\"did\",\"do\",\"does\"]}},{\"LOWER\":\"you\"},{\"LEMMA\":\"mean\"},{\"OP\":\"?\",\"IS_PUNCT\":True}]},\n",
        "                  {\"label\":\"MISUNDERSTANDING\",\"pattern\":[{\"LOWER\":\"let's\"},{\"LOWER\":\"talk\"},{\"LOWER\":\"about\"},{\"IS_ALPHA\":True,\"OP\":\"+\"}]},\n",
        "                   {\"label\":\"MISUNDERSTANDING\",\"pattern\":[{\"LOWER\":\"to\"},{\"LOWER\":\"clarify\"},{\"OP\":\"?\",\"IS_PUNCT\":True}]}]"
      ],
      "metadata": {
        "id": "fygLHLOeTo_H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the classifier (unhash to replicate - takes a long time)."
      ],
      "metadata": {
        "id": "-wldyjTKUJUx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#RB_Loop14_train = Rule_based_classifier(texts=texts,true_scores=true_scores)\n",
        "#RB_Loop14_train.add_rule_based_terms(terms, \"pattern\")\n",
        "#RB_Loop14_train.run_classifier()\n",
        "#RB_Loop14_train.get_model_report()"
      ],
      "metadata": {
        "id": "3QxY2jO1TZJA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Results (saved for convenience)"
      ],
      "metadata": {
        "id": "fTTJJsymT5ad"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred_scores = out[\"rule-based\"].to_list()\n",
        "get_model_report(true_scores, pred_scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nsf_1XrwSbAC",
        "outputId": "8c614ab1-704b-427b-8637-2dca69e1602a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "true:6420,pred:6420\n",
            "AUC-PR: 0.31\n",
            "\n",
            "AUC-ROC: 0.61\n",
            "\n",
            "MCC: 0.22\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.94      0.94      5909\n",
            "           1       0.29      0.27      0.28       511\n",
            "\n",
            "    accuracy                           0.89      6420\n",
            "   macro avg       0.62      0.61      0.61      6420\n",
            "weighted avg       0.89      0.89      0.89      6420\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3.2 Supervised classifier\n",
        "\n",
        "The classifier was trained during the throughput (loop 20) so to run it on the test data requires loading it into the runtime."
      ],
      "metadata": {
        "id": "gXBsDJ9zS3DS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load trained supervised model (downloaded in section 0.2)\n",
        "predictor = ktrain.load_predictor('supervised_model')"
      ],
      "metadata": {
        "id": "y-9anp-8Vo9Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test the classifier has been correctly loaded"
      ],
      "metadata": {
        "id": "0o5ShHNUWHqg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Misunderstanding example\n",
        "predictor.predict(\"I don't understand your point.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "XZN6yRjmWJ2h",
        "outputId": "63aac323-8ce7-49fe-b1b8-d61d0f69e09b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Misunderstanding'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Not misunderstanding example\n",
        "predictor.predict(\"Cats are not the same as dogs.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "gzgUQDURV-G5",
        "outputId": "154d556c-9b8b-4dce-f691-1f78cf4b432a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'not_Misunderstanding'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the classifier (unhash to replicate)."
      ],
      "metadata": {
        "id": "uenYFjGOWQyn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#smlClassifier = supervised_classifier(texts, true_scores)\n",
        "#smlClassifier.add_SML_classifier(predictor)\n",
        "#smlClassifier.classify_with_SML()\n",
        "#smlClassifier.get_model_report()"
      ],
      "metadata": {
        "id": "0sAPW9wYUW1Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Results saved for convenience:"
      ],
      "metadata": {
        "id": "DxXS8AcnUxIw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "true_scores = out.Misunderstanding.to_list()\n",
        "pred_scores = out[\"supervised\"].to_list()\n",
        "get_model_report(true_scores, pred_scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6B_nyQKaS5B-",
        "outputId": "debb7003-9796-43b6-c95f-5a97de362390"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "true:6420,pred:6420\n",
            "AUC-PR: 0.73\n",
            "\n",
            "AUC-ROC: 0.88\n",
            "\n",
            "MCC: 0.69\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.96      0.97      5909\n",
            "           1       0.65      0.79      0.71       511\n",
            "\n",
            "    accuracy                           0.95      6420\n",
            "   macro avg       0.81      0.88      0.84      6420\n",
            "weighted avg       0.95      0.95      0.95      6420\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3.3 LLM classifier\n"
      ],
      "metadata": {
        "id": "lVMM_HDmS85T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the role and prompt (loop 13):"
      ],
      "metadata": {
        "id": "FndGec7hVCmh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "role = \"\"\"\n",
        "*Role* You are a research assistant tasked with identifying whether a sentence indicates a misunderstanding.\n",
        "*Misunderstanding definition* A misunderstanding occurs during dialogue when one participant has an incorrect understanding of another’s perspective.\n",
        "\"\"\"\n",
        "prompt = \"\"\"\n",
        "There are two categories of misunderstanding:\n",
        "1. “Direct” misunderstandings. These occur when a participant evidences a misunderstanding of another participant’s point.\n",
        "2. “Felt” misunderstandings. These occur when a participant feels their previous turn was misunderstood by another participant.\n",
        "This is a non-exhaustive list of possible sentences indicating misunderstanding.\n",
        "1. Explicit statement: The sentence explicitly indicates the speaker doesn't understand another’s perspective (e.g., \"I don't get what you're trying to say about the dog\")\n",
        "2. Clarification question: The question seeks to clarify the other’s perspective (e.g., \"What do you mean?\")\n",
        "3. Request for confirmation: A question that seeks confirmation on the other’s understanding of the speaker’s previous turn(e.g., \"You really think that I meant all dogs?\")\n",
        "4. Correction of Other: Correcting another speaker’s misunderstanding of the present speaker’s previous turn(e.g., \"You've misunderstood my point\", “You don’t get it.”)\n",
        "5. Clarification or apology about speaker's intentions: Clarifying the meaning of what the speaker previously said (e.g., \"Sorry, I meant to say X\")\n",
        "6. Misunderstanding due to lack of response (e.g., \"Why did you change the subject?\")\n",
        "7. Editing a message at a later time: This is when a speaker in text-based dialogue comes back to edit their comment after the fact (e.g., \"EDIT\": That's what I said)\n",
        "Here are some examples of sentences indicating misunderstandings:\n",
        "- Jane, that article was what I was talking about.\n",
        "- Why not go further? - Do you think that was ok?\n",
        "- I apologise for saying that, but I meant the other stuff.\n",
        "- @John But when? - @John Please tell me why I've been stuck here for so long.\n",
        "- What drove that thought? - I actually said \"sure thing\".\n",
        "- You serious?\n",
        "- I'm not sure what I could have done differently.\n",
        "TASK:\n",
        "Does the below sentence indicate a possible misunderstanding?\n",
        "Only respond with \"Yes\" or \"No\"\n",
        "Sentence: {}\n",
        "Response:\"\"\""
      ],
      "metadata": {
        "id": "uyoPYGoZVHVI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the classifier. Unhash to replicate; results are likely to be marginally different due to the LLM's stochastic behavior."
      ],
      "metadata": {
        "id": "ljb1t4RYVXKV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## GPT model\n",
        "#GPTmodel = \"gpt-4o-2024-05-13\"\n",
        "## Run classifier\n",
        "#LLmclass = LLM_classifier(texts=texts,true_scores=true_scores)\n",
        "#LLmclass.add_prompt_param(GPTmodel=GPTmodel,role=role,prompt=prompt)\n",
        "#LLmclass.run_model()"
      ],
      "metadata": {
        "id": "yGkwh5GZVQiG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "true_scores = out.Misunderstanding.to_list()\n",
        "pred_scores = out[\"few-shot\"].to_list()\n",
        "get_model_report(true_scores, pred_scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RT3xgUltS-2D",
        "outputId": "06739b64-0c68-4ecd-b44a-6f80f6b1f5fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "true:6420,pred:6420\n",
            "AUC-PR: 0.56\n",
            "\n",
            "AUC-ROC: 0.80\n",
            "\n",
            "MCC: 0.47\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.91      0.94      5909\n",
            "           1       0.39      0.69      0.50       511\n",
            "\n",
            "    accuracy                           0.89      6420\n",
            "   macro avg       0.68      0.80      0.72      6420\n",
            "weighted avg       0.93      0.89      0.90      6420\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Integrative evaluation (RAMP method)\n",
        "\n",
        "This section looks at disagreements and misclassifications in order to inform the final stage of RAMP. These are used to infer surprising findings from which to identify potential problems of construct and concept validity.\n",
        "\n",
        "This analysis is qualitative and is informed by the below disagreements and misclassifications"
      ],
      "metadata": {
        "id": "5QvklA8-nEJT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1 Inter-rater discrepancies"
      ],
      "metadata": {
        "id": "j4wwlA44mblb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get sample of disagreements\n",
        "tds = TextDataStats(IRR_final)\n",
        "tds.get_disagreements(25)"
      ],
      "metadata": {
        "id": "TKmaQbQ8mgYh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7458db7-d719-434a-c525-6c982d3a4c2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------\n",
            "In any case, everyone has different things they find satisfying to do on Wikipedia; why don't you spend time on things that give you pleasure?\n",
            "----------\n",
            "@Ask_Spectrum I've gave your company enough of my patience ive had enough, you just lost a customer!.\n",
            "----------\n",
            "Update: as a few have pointed out, the term racist was a poor choice of words.\n",
            "----------\n",
            "this is amc, but i feel you\n",
            "----------\n",
            "Well, I'm not talking about Western Sahara specifically.\n",
            "----------\n",
            "We wouldn't be able to comment further than what was discussed yesterday, until Omniserve come back.\n",
            "----------\n",
            "The rest not so rightÔ£ø√º√≤√ë thanks for correcting me!\n",
            "----------\n",
            "The article is actually a lot better and resourceful than it originally appeared but I believe my edits have improved it, even if I picked up a few horses in Jutland rather than Jutland horse and probably needed minor copyedits.\n",
            "----------\n",
            "Why go from zero to 100 today?\n",
            "----------\n",
            "I mean is there proof for that third one?\n",
            "----------\n",
            "You seem to have misread the guidelines.\n",
            "----------\n",
            "Are you suggesting otherwise?\n",
            "----------\n",
            "I forgot that we are on earth and that there are forces applied on objects that arent present in space lol.\n",
            "----------\n",
            "Now it's clear to me.\n",
            "----------\n",
            "The discrepancy between the UK self-esteem and the view the rest of the world has.\n",
            "----------\n",
            "Rather, the point I'm making is that you're applying an overly-simplified lens to this.\n",
            "----------\n",
            "If part of your point relates to the idea that religion makes it so you don't question the belief system and also divides people up into different groups by virtue of being a different religion then that could be true but even post religious societies have that aspect such as nationalism.\n",
            "----------\n",
            "Why now?\n",
            "----------\n",
            "So the service is worse than usual but its more expensive to travel?\n",
            "----------\n",
            "I understand that, but we don't need twenty plus pages to solve that problem.\n",
            "----------\n",
            "However on looking at the relevant AN\\/I section, discussion on it appears to have dried up, and given the topic of the dispute and its sheer irrelevance to anything remotely related to making Barack Obama an encyclopaedic article, and given some editors' (on both sides) single-minded obsession with the one article and the debates in and around it, I don't feel any great regrets about the action taken.\n",
            "----------\n",
            "What do you know?\n",
            "----------\n",
            "Now refusing to send elsewhere?\n",
            "----------\n",
            "So the article [[Jackal]] is wrong then?\n",
            "----------\n",
            "@361567 Hi, not to worry it will not be charged.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2 Supervised misclassifications"
      ],
      "metadata": {
        "id": "Ym2-GFNumkRr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "out2 = out.copy()\n",
        "out2 = out2.rename(columns={\"Misunderstanding\":\"Manual\", \"few-shot\":\"LLM\"})"
      ],
      "metadata": {
        "id": "NRF8EStoCdmG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tds = TextDataStats(out2)\n",
        "misdf = tds.get_misclassifications(return_all = True)"
      ],
      "metadata": {
        "id": "1e47fC2YZ1Gs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For printing rule-based misclassifications - these are fairly arbitrary\n",
        "for i in misdf[misdf[\"Manual\"]==1][misdf[\"rule-based\"]==0].sample(10).text.values:\n",
        "  print(i)"
      ],
      "metadata": {
        "id": "mhrPActSaBn0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3d434ab-2bf5-42ba-fab6-e83810cd2f24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "btw I'm not Ronald!\n",
            "hehe, whoops!\n",
            "No news is good news?\n",
            "@Company_Handle For the type of issue reported I thought I may have at least been contacted for some information.\n",
            "Do you steal from seniors too or just kids?\n",
            "Am I missing something?\n",
            "Isn't this to show pics we've taken??\n",
            "We don't think it is.\n",
            "Like John hasn't exhibited a consistent attitude conducive to collaboration?\n",
            "Oh, I see.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-3b1cc0282d4c>:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
            "  for i in misdf[misdf[\"Manual\"]==1][misdf[\"rule-based\"]==0].sample(10).text.values:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For supervised and few shot classifiers\n",
        "tds = TextDataStats(out2)\n",
        "tds.get_misclassifications(n=25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7Fvi5Aenrj-",
        "outputId": "a5a72773-f585-4cbd-bc76-f8458dedefcf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- FP (All) count: -- 53\n",
            "--- FP (supervised) count: -- 111\n",
            "--- FP (LLM) count: -- 436\n",
            "--- FN (All) count: -- 111\n",
            "--- FN (supervised) count: -- 53\n",
            "--- FN (LLM) count: -- 0\n",
            "\n",
            "Printing 25 examples of each classifier type.\n",
            "\n",
            "------ FP (ALL) ------\n",
            "- Sure, do you want me to?\n",
            "- This is completely unacceptable and to worsen it is that you lot do not respond quick enough.\n",
            "- I am very patient as to what-will-happen-next, although I don't seem to manage it with spur-of-the-moment replies (oops).\n",
            "- I'm not really committed to extensive rewriting as it's only wiki and can be edited anyway.\n",
            "- I take that back.\n",
            "- hahahahaha my apologies\n",
            "- How can you fame a Wikipedian?\n",
            "- @Company_Handle @Company_Handle What type of ticket have you bought?\n",
            "- Again, Industry Canada is a reliable source, even if not the preferred one, and those numbers are much better than no numbers at all.\n",
            "- Anything you can do to make him believe that I mean no ill will would be very helpful.\n",
            "- For one i didn't even know the person \\\"personally\\\".\n",
            "- I thought it was a clear-cut case of \\\"notability not proven\\\" the way it stood, but if he can improve it, it's no problem as far as I'm concerned.\n",
            "- Hrafn's a constructive editor who is on my watchlist. . .\n",
            "- What's going on with the import script?\n",
            "- I want to know the cause of this delay.\n",
            "- I am the person that added all the attendances(at least most of it), I have no reason to fabricate attendances.\n",
            "- Thank you for explaining why, I withdraw my complaint.\n",
            "- Remember, I was just helping Michael with the ''Origin'', but ''Orchids'' was mostly me with a great deal of help from both of you.\n",
            "- I get there's no real answer but which option has more support?\n",
            "- No put stickers on things that changed the perception of them Like he would put a woodchuck sticker on the hand operated pencil sharpener and stickers that read, \"Lies?\" on the globe because despite being a science teacher he was a flat earther.\n",
            "- @Company_Handle Oh, okay.\n",
            "- I already have and he has done it multiple times.\n",
            "- It's not specific enough, I need something that doesn't require ps plus or Nintendo online\n",
            "- I don't really think it's necessary; I wouldn't have added the tag if I were editing the article by hand.\n",
            "- It was mostly the \\\"community\\\" name and the unprofessional look of the webpage that caused me to remove it, plus I was in \\\"mass-delete\\\" mode as I went through dozens of vehicle articles looking for links that obviously violated the guideline.\n",
            "--------\n",
            "------ FP (SUPERVISED) ------\n",
            "- A google time-stamped prophecy is neither an opinion, experience nor is it an argument, so I can't see how it is original research.\n",
            "- I also have to admit that running into you has made this avocation less than enjoyable as I seek to begin to respond to the grain and chaff issue I referred to in a previous edit.\n",
            "- This proves my point too.\n",
            "- Indonesian organisations with english names as title of article and the indonesian name as the aka please?\n",
            "- Which will be better??\n",
            "- Are you having this issue with any other channels?\n",
            "- I don't care about martyrdom, etc., or any dramas.\n",
            "- If you can't, it's no problem; I just thought I'd ask.\n",
            "- @Company_Handle I did not hear back from you yet.\n",
            "- Now you're just being uncivil and insulting.\n",
            "- I wanted to talk to them, but didn't know where to start.\n",
            "- I understand your frustration at seeing a lot of what you've created slowly whittled away, but [http:\\/\\/en.wikipedia.org\\/w\\/index.php?title=Suzi_Suzuki&curid=4775796&diff=437390137&oldid=437364401 this] is 100% pure [[WP:POINT]].\n",
            "- &#x200B; It is true that they are wrong, but how should they know?\n",
            "- It's me, again.\n",
            "- Like you, I wrote on what I know, so it was easy.\n",
            "- Oh no!!\n",
            "- I thought not.\n",
            "- But yes obviously that Facebook whatever stuff is actually wrong i just wanted to point out that an actual number for the death rate exists and has actually existed for many months\n",
            "- My phone been on 1x for 2 fucking days wtf is 1x?\n",
            "- Yes, please do that, if you change it to non consensus then it stops people quoting it as if it was decided by the review when it wasn't.- \n",
            "- Do you think its function could be impoved?\n",
            "- :-) On an unrelated note, I've obviously read your user page -- is your daughter killing you the same way ours is killing us?\n",
            "- No, he didn't.\n",
            "- Add it to the category pages?\n",
            "- Oh yeah!\n",
            "--------\n",
            "------ FP (LLM) ------\n",
            "- @Company_Handle We apologize for any confusion, it looks like this item sold out quickly!\n",
            "- And I am not some crazed guy out to mock and disrupt his life, regardless of what he says ot thinks.\n",
            "- But I do not think he really supports the semiprotection, neither does Sidaway or some other respected editors.\n",
            "- Where do you see the blog is sponsored by Parade Magazine.\n",
            "- Any clues as to how I can fix?\n",
            "- I have never once seen anyone on here mention anything about purchasing silver.\n",
            "- Thanks for the article, which does not in fact discuss ''how'' to distinguish empty matrices, although it does mention their distinctiveness.\n",
            "- @Company_Handle That's not okay.\n",
            "- They fought for you to be able to, not to require you to This phrase mostly comes up when you decide not to care about something someone else feels strongly about\n",
            "- Cant tell if that's the pilot or the undercarriage that gets fired out the front.\n",
            "- I was thinking the Piney Woods school article itself needed more additions, but you already did that too.\n",
            "- Just stop thinking your above others be you only listen to a few of biggie and Christopher's songs when you don't give anything else a try.\n",
            "- Don't fool yourself, that's what's going on.\n",
            "- If my words are not clear, please point out the parts which need further explaining.\n",
            "- @Company_Handle It say's I'm verified been when I click the user detail this is the next page.\n",
            "- So I continually request a discount that I'm entitled to with &amp; they don't give info.\n",
            "- @Company_Handle looks like am not only one having this issue!\n",
            "- There are bigger issues at hand - like maybe the fact that the masks are fake, not that the wearers are upset the masks are fake\n",
            "- I fail to see the danger.\n",
            "- (My memory might be wrong, but I'm sure I would not have allowed that photo to be used in the article without double-checking that it was okay.)\n",
            "- Hello, I have sent 2 coppies of my unblock request to arbcom, one in march, and one in early April, but no response, so I am seaking advice, what else is there for me to do, I'm totaly out of ideas and I have lost faith in wikipedia.\n",
            "- I don't recall EVER seeing how people also abandon their own parents when they're old.\n",
            "- @Company_Handle be nice though if the whole range was available esp in an Xtra store, I currently have to drive 10km to James for more choice.. @Company_Handle hi im interested in the new ones the peppercorn and \"goats\" cheese I already know where the existing Free From cheezes can.be got.\n",
            "- Please, could someone tell me what next?\n",
            "- As for your comment about Lisa Millerton people\\\", Wikipedia policy is that content is based on reliable sources, not what is insulting to any group of people (for example, we refer to that landlocked country north of East Michael as Harperport, even though that term seems to be offensive to many Greeks).\n",
            "--------\n",
            "------ FN (ALL) ------\n",
            "- Its happened a few times now.Is it supposed to be like that?\n",
            "- @Company_Handle That's so strange - clicked on the link and it isn't showing that late :( \n",
            "- So what about everyone else?\n",
            "- But why is that ideology so attractive?\n",
            "- @Company_Handle Will I still be getting a Scorpio editon?\n",
            "- I hope you didn't think it was serious.\n",
            "- I can't answer to all your questions since I don't think to have been involved in all the edits you talk about.\n",
            "- As for \\\"taking recentism to new heights\\\", I stand by that attack on the edit.\n",
            "- Was it still showing as downloading for you?\n",
            "- Belatedly, I've added the material I mentioned earlier concerning individual reactions to Laurie's books upon their publication.\n",
            "- Two flights in a row????\n",
            "- Does this mean that articles such as [[Duality (Song)]] and [[Mirrorcle World]] are invalid, as well as all of [[The Gazette]]'s other singles?\n",
            "- To customer CARE?\n",
            "- Is that right?\n",
            "- @Company_Handle ?\n",
            "- That's why I needed to double-check.\n",
            "- I was wondering this too, or if it's something you intentionally do to trick your brain?\n",
            "- > Okay, when I wrote this, I was a little too focused on deliberate acts of self expression rather than things people are born with.\n",
            "- I'm not saying don't thrift shop.\n",
            "- EDIT - wow, I can't spell apparently....\"known for being he Cofounder\" whoops.\n",
            "- why the elderly man refused hot coffee ?\n",
            "- @Company_Handle can you tell me why I was promised a manager call me in 1 hour &amp; they haven't?\n",
            "- @Company_Handle I haven't order anything from you guys!\n",
            "- Why is that?\n",
            "- Wtf was that ending?\n",
            "--------\n",
            "------ FN (SUPERVISED) ------\n",
            "- Not sure what that is\n",
            "- But... they do.\n",
            "- To the user whose page this is, examine the situation as you will, but I thought I'd leave my two cents when the person above is trying to portray me as someone out to ruin the article.\n",
            "- Mark, the experience you are describing is something we'd never do.\n",
            "- What am I doing?\n",
            "- How is this photo relevant to Rachel's life?\n",
            "- How does it make it make Wikipedia more user friendly to alter [[Natasha]] to [[Kelly of England|Henry VIII]]?\n",
            "- FA work is fine and I'm sure WMC could assist in non CC related article improvement but once a bulls eye get painted on anyone of this high a profile on this project, someone is always going to be the ready to play smackdown if such an editor so much as twitches \\\"incorrectly\\\"...my understanding as it was clarified to me was that user talkpages, even your own user talkpage are taboo for issues related to the topic ban.--\n",
            "- @Company_Handle I provided you all with the info 5 hours ago\n",
            "- @Company_Handle We are not the bots you are looking for.\n",
            "- That may be (one can never be sure), but the editors don't seem to understand the serious problems with the page.\n",
            "- Hold up.\n",
            "- Can you elaborate the implications of your argument?\n",
            "- @Company_Handle this is the enough apologies you have sent, it's enough to last me a life time .. clean up your mess \n",
            "- Might I ask you to check out my responses to the issues you raised, specifically the questions I asked about images?\n",
            "- The rest not so right thanks for correcting me!\n",
            "- Could you confirm If you have contacted the support team through link provided earlier?\n",
            "- Edit: this is for areas that don't normally get freezing temperatures, where houses aren't designed for those temperatures.\n",
            "- I guess you think more highly of userboxes than myself.\n",
            "- @Company_Handle What number are you dialing?\n",
            "- @Company_Handle This is the same trip.\n",
            "- so, if the national cancer... has cancer, what's the problem\n",
            "- I understand that, but we don't need twenty plus pages to solve that problem.\n",
            "- However, at the [[Talk:List of Farscape episodes#Upcoming Merge & Redirect per Wikipedia Guidelines & Notability Standards|''Farscape'' talk page]], you stated that I was ''Anthony\"'' with these same policies.\n",
            "- And what's wrong with reading through five+ paragraphs?\n",
            "--------\n",
            "------ FN (LLM) ------\n",
            "--------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2.1 Using LIME to explore BERT classifier"
      ],
      "metadata": {
        "id": "C6djwU6rmv6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For assessing the supervised classifier FN and FP\n",
        "predictor.explain(\"It's me, again\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "id": "IxRV_yhTa7J9",
        "outputId": "417a389d-0e44-4625-a068-84e5a3a8ccec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <style>\n",
              "    table.eli5-weights tr:hover {\n",
              "        filter: brightness(85%);\n",
              "    }\n",
              "</style>\n",
              "\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "        \n",
              "\n",
              "    \n",
              "\n",
              "        \n",
              "\n",
              "        \n",
              "    \n",
              "        \n",
              "        \n",
              "    \n",
              "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
              "            <b>\n",
              "    \n",
              "        y=Misunderstanding\n",
              "    \n",
              "</b>\n",
              "\n",
              "    \n",
              "    (probability <b>0.799</b>, score <b>1.378</b>)\n",
              "\n",
              "top features\n",
              "        </p>\n",
              "    \n",
              "    <table class=\"eli5-weights\"\n",
              "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
              "        <thead>\n",
              "        <tr style=\"border: none;\">\n",
              "            \n",
              "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
              "                    Contribution<sup>?</sup>\n",
              "                </th>\n",
              "            \n",
              "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
              "            \n",
              "        </tr>\n",
              "        </thead>\n",
              "        <tbody>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +2.777\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        Highlighted in text (sum)\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "        \n",
              "\n",
              "        \n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 87.63%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -1.399\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        &lt;BIAS&gt;\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "\n",
              "        </tbody>\n",
              "    </table>\n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n",
              "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
              "        <span style=\"background-color: hsl(120, 100.00%, 74.54%); opacity: 0.90\" title=\"1.709\">it</span><span style=\"opacity: 0.80\">&#x27;</span><span style=\"background-color: hsl(0, 100.00%, 92.22%); opacity: 0.82\" title=\"-0.314\">s</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 87.68%); opacity: 0.84\" title=\"0.606\">me</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(120, 100.00%, 60.00%); opacity: 1.00\" title=\"3.259\">again</span>\n",
              "    </p>\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictor.explain(\"Mark, the experience you are describing is something we'd never do.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "id": "-FSv-aABefP8",
        "outputId": "25634fc7-81f2-4613-f5bd-70a469c8c583"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <style>\n",
              "    table.eli5-weights tr:hover {\n",
              "        filter: brightness(85%);\n",
              "    }\n",
              "</style>\n",
              "\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "        \n",
              "\n",
              "    \n",
              "\n",
              "        \n",
              "\n",
              "        \n",
              "    \n",
              "        \n",
              "        \n",
              "    \n",
              "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
              "            <b>\n",
              "    \n",
              "        y=not_Misunderstanding\n",
              "    \n",
              "</b>\n",
              "\n",
              "    \n",
              "    (probability <b>0.701</b>, score <b>-0.850</b>)\n",
              "\n",
              "top features\n",
              "        </p>\n",
              "    \n",
              "    <table class=\"eli5-weights\"\n",
              "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
              "        <thead>\n",
              "        <tr style=\"border: none;\">\n",
              "            \n",
              "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
              "                    Contribution<sup>?</sup>\n",
              "                </th>\n",
              "            \n",
              "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
              "            \n",
              "        </tr>\n",
              "        </thead>\n",
              "        <tbody>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +1.272\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        &lt;BIAS&gt;\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "        \n",
              "\n",
              "        \n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 90.76%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -0.422\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        Highlighted in text (sum)\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "\n",
              "        </tbody>\n",
              "    </table>\n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n",
              "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
              "        <span style=\"background-color: hsl(0, 100.00%, 91.80%); opacity: 0.82\" title=\"-0.289\">mark</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(0, 100.00%, 87.58%); opacity: 0.84\" title=\"-0.523\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 84.45%); opacity: 0.85\" title=\"0.721\">experience</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 65.61%); opacity: 0.96\" title=\"-2.240\">you</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.54%); opacity: 0.82\" title=\"-0.252\">are</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 60.00%); opacity: 1.00\" title=\"-2.780\">describing</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 87.81%); opacity: 0.84\" title=\"-0.509\">is</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.96%); opacity: 0.81\" title=\"-0.144\">something</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 71.82%); opacity: 0.92\" title=\"-1.685\">we</span><span style=\"opacity: 0.80\">&#x27;</span><span style=\"background-color: hsl(120, 100.00%, 77.01%); opacity: 0.89\" title=\"1.260\">d</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 70.08%); opacity: 0.93\" title=\"-1.836\">never</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.63%); opacity: 0.81\" title=\"0.118\">do</span><span style=\"opacity: 0.80\">.</span>\n",
              "    </p>\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For assessing the supervised classifier FN and FP\n",
        "predictor.explain(\"Not sure what that is\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "id": "CmZKiXyCbTMC",
        "outputId": "bf9a779d-be21-45e5-9202-adbcf1ee0978"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <style>\n",
              "    table.eli5-weights tr:hover {\n",
              "        filter: brightness(85%);\n",
              "    }\n",
              "</style>\n",
              "\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "        \n",
              "\n",
              "    \n",
              "\n",
              "        \n",
              "\n",
              "        \n",
              "    \n",
              "        \n",
              "        \n",
              "    \n",
              "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
              "            <b>\n",
              "    \n",
              "        y=not_Misunderstanding\n",
              "    \n",
              "</b>\n",
              "\n",
              "    \n",
              "    (probability <b>0.432</b>, score <b>0.275</b>)\n",
              "\n",
              "top features\n",
              "        </p>\n",
              "    \n",
              "    <table class=\"eli5-weights\"\n",
              "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
              "        <thead>\n",
              "        <tr style=\"border: none;\">\n",
              "            \n",
              "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
              "                    Contribution<sup>?</sup>\n",
              "                </th>\n",
              "            \n",
              "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
              "            \n",
              "        </tr>\n",
              "        </thead>\n",
              "        <tbody>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 83.32%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +0.929\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        &lt;BIAS&gt;\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "        \n",
              "\n",
              "        \n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 80.00%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -1.204\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        Highlighted in text (sum)\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "\n",
              "        </tbody>\n",
              "    </table>\n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n",
              "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
              "        <span style=\"background-color: hsl(120, 100.00%, 81.83%); opacity: 0.86\" title=\"0.456\">not</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 71.37%); opacity: 0.92\" title=\"0.873\">sure</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 67.48%); opacity: 0.95\" title=\"-1.047\">what</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 60.00%); opacity: 1.00\" title=\"-1.407\">that</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 64.52%); opacity: 0.97\" title=\"-1.186\">is</span>\n",
              "    </p>\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For assessing the supervised classifier FN and FP\n",
        "predictor.explain(\"But... They do.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "id": "dWDBjWMGzCFk",
        "outputId": "2caca445-afc6-458c-c38e-067d452478d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <style>\n",
              "    table.eli5-weights tr:hover {\n",
              "        filter: brightness(85%);\n",
              "    }\n",
              "</style>\n",
              "\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "        \n",
              "\n",
              "    \n",
              "\n",
              "        \n",
              "\n",
              "        \n",
              "    \n",
              "        \n",
              "        \n",
              "    \n",
              "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
              "            <b>\n",
              "    \n",
              "        y=not_Misunderstanding\n",
              "    \n",
              "</b>\n",
              "\n",
              "    \n",
              "    (probability <b>0.997</b>, score <b>-5.930</b>)\n",
              "\n",
              "top features\n",
              "        </p>\n",
              "    \n",
              "    <table class=\"eli5-weights\"\n",
              "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
              "        <thead>\n",
              "        <tr style=\"border: none;\">\n",
              "            \n",
              "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
              "                    Contribution<sup>?</sup>\n",
              "                </th>\n",
              "            \n",
              "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
              "            \n",
              "        </tr>\n",
              "        </thead>\n",
              "        <tbody>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +5.248\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        Highlighted in text (sum)\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 95.21%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +0.682\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        &lt;BIAS&gt;\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "        \n",
              "\n",
              "        \n",
              "        \n",
              "\n",
              "        </tbody>\n",
              "    </table>\n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n",
              "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
              "        <span style=\"background-color: hsl(120, 100.00%, 84.97%); opacity: 0.85\" title=\"0.600\">but</span><span style=\"opacity: 0.80\">... </span><span style=\"background-color: hsl(120, 100.00%, 72.94%); opacity: 0.91\" title=\"1.390\">they</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 60.00%); opacity: 1.00\" title=\"2.429\">do</span><span style=\"opacity: 0.80\">.</span>\n",
              "    </p>\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Non-iterative method results\n",
        "\n",
        "To compare the RAMP approach, we had two coders separately score the entire dataset using the original version of the manual codebook, prior to the changes integrated during the inference loops. We then use this data to test three classifiers.\n",
        "\n",
        "The rule-based classifier uses the terms from loop 1 of RAMP method troughput (prior to any iterations), the supervised classifier was trained on 70% of the data (30% of the data used for validation) using the hyperparameters from loop 1 of RAMP method troughput, and the few-shot classifier uses the prompt from loop 1 of RAMP method troughput."
      ],
      "metadata": {
        "id": "hf28QA-VLCpI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.1 Manual coding"
      ],
      "metadata": {
        "id": "bl9ZsGWlLIL-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nMis_oneShot = train_test.Misunderstanding_OneShot.sum()\n",
        "pct_misOneShot = round(100*(nMis_oneShot/len(train_test)),2)\n",
        "print(f\"Identified {nMis_oneShot} misunderstandings in the one-shot, accounting for {pct_misOneShot}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZHgGr_nLL1p",
        "outputId": "2cd65447-35f1-4a5a-e908-03fff378dabe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Identified 592.0 misunderstandings in the one-shot, accounting for 2.69\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "one_shot_MC = St1Through[St1Through.Round == \"one-shot\"]\n",
        "tds = TextDataStats(one_shot_MC, IRR_columns = [\"Coder5\",\"Coder6\"])\n",
        "tds.IRRreport().round(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        },
        "id": "Gvs5W9X8LR87",
        "outputId": "9791bae4-5d4b-4801-ad94-25a0c02932e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<irrCAC.raw.CAC Subjects: 2000, Raters: 2, Categories: [0, 1], Weights: \"identity\">\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            Round  Sample size  Agreement               K's Alpha  \\\n",
              "0  Round one-shot         2000       0.95  0.28 CI = (0.18, 0.39)   \n",
              "\n",
              "  K's Alpha significance              Gwet's AC1 Gwet's AC1 significance  \n",
              "0    z = 5.41; p < 0.001  0.95 CI = (0.94, 0.96)   z = 179.07; p < 0.001  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9fe612e9-3851-472d-bdf2-97d225f05d65\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Round</th>\n",
              "      <th>Sample size</th>\n",
              "      <th>Agreement</th>\n",
              "      <th>K's Alpha</th>\n",
              "      <th>K's Alpha significance</th>\n",
              "      <th>Gwet's AC1</th>\n",
              "      <th>Gwet's AC1 significance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Round one-shot</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.95</td>\n",
              "      <td>0.28 CI = (0.18, 0.39)</td>\n",
              "      <td>z = 5.41; p &lt; 0.001</td>\n",
              "      <td>0.95 CI = (0.94, 0.96)</td>\n",
              "      <td>z = 179.07; p &lt; 0.001</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9fe612e9-3851-472d-bdf2-97d225f05d65')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9fe612e9-3851-472d-bdf2-97d225f05d65 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9fe612e9-3851-472d-bdf2-97d225f05d65');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"tds\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"Round\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Round one-shot\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sample size\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 2000,\n        \"max\": 2000,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          2000\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Agreement\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.95,\n        \"max\": 0.95,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.95\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"K's Alpha\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"0.28 CI = (0.18, 0.39)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"K's Alpha significance\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"z = 5.41; p < 0.001\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Gwet's AC1\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"0.95 CI = (0.94, 0.96)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Gwet's AC1 significance\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"z = 179.07; p < 0.001\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We found that the inter-rater reliability is, on the whole, worse for the one-shot group than any of the iterations of RAMP (including Round 1)."
      ],
      "metadata": {
        "id": "MAQnDNVvMHuX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1.1 Compare RAMP and non-iterative manual coding\n",
        "\n",
        "The below examines the differences between the RAMP and non-iterative  method manual coding so that we can see where the coders differed in their codes of misunderstanding."
      ],
      "metadata": {
        "id": "e8F_rO_6YVJB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming true scores are the RAMP scores\n",
        "data_to_compare = train_test[[\"Misunderstanding\", \"Misunderstanding_OneShot\"]]\n",
        "print(classification_report(data_to_compare[\"Misunderstanding\"], data_to_compare[\"Misunderstanding_OneShot\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WOSwmHXeYZD0",
        "outputId": "c3bca79c-d479-4f6e-f32b-a07759cacfc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.99      0.97     20267\n",
            "           1       0.72      0.25      0.37      1715\n",
            "\n",
            "    accuracy                           0.93     21982\n",
            "   macro avg       0.83      0.62      0.67     21982\n",
            "weighted avg       0.92      0.93      0.92     21982\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cm_compare = confusion_matrix(data_to_compare[\"Misunderstanding\"], data_to_compare[\"Misunderstanding_OneShot\"])\n",
        "TP = cm_compare[1, 1]\n",
        "FN = cm_compare[1, 0]\n",
        "FP = cm_compare[0, 1]\n",
        "TN = cm_compare[0, 0]\n",
        "total_shared = TP + TN\n",
        "pct_shared = round(100*(total_shared/len(data_to_compare)),2)\n",
        "print(f\"One-shot and RAMP coding share {total_shared} ({pct_shared}%) codes.\\n\")\n",
        "total_disagree = FP + FN\n",
        "pct_disagree = round(100*(total_disagree/len(data_to_compare)),2)\n",
        "print(f\"One-shot and RAMP coding disagree on {total_disagree} ({pct_disagree}%) codes.\\n\")\n",
        "pct_disagree_FN = round(100*(FN/total_disagree),2)\n",
        "print(f\"Of the disagreements {FN} ({pct_disagree_FN}%) were cases where one-shot coders DID NOT score for misunderstanding and RAMP coders didn't.\\n\")\n",
        "pct_disagree_FP = round(100*(FP/total_disagree),2)\n",
        "print(f\"Of the disagreements {FP} ({pct_disagree_FP}%) were cases where one-shot coders DID SCORE for misunderstanding and RAMP coders did.\\n\")\n",
        "print(f\"Instances of misunderstandings identified by positive coders (true positives): {TP}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbP8ioupYaaE",
        "outputId": "9378d78f-317e-4c59-f7d9-06f933c86847"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "One-shot and RAMP coding share 20529 (93.39%) codes.\n",
            "\n",
            "One-shot and RAMP coding disagree on 1453 (6.61%) codes.\n",
            "\n",
            "Of the disagreements 1288 (88.64%) were cases where one-shot coders DID NOT score for misunderstanding and RAMP coders didn't.\n",
            "\n",
            "Of the disagreements 165 (11.36%) were cases where one-shot coders DID SCORE for misunderstanding and RAMP coders did.\n",
            "\n",
            "Instances of misunderstandings identified by positive coders (true positives): 427\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.2 Classifier development"
      ],
      "metadata": {
        "id": "vTckTVXjMPh8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.2.1 Training and developing classifiers\n",
        "\n",
        "The below provides the code for training the supervised classifier. The rule-based and LLM classifier were only tested as the terms and prompt (respectively) were already created."
      ],
      "metadata": {
        "id": "BHcGRbqhMSI2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training data texts and true scores for non-iterative method\n",
        "texts_NonIterative = train_NonIterative[\"text\"].values\n",
        "true_scores_NonIterative  = train_NonIterative[\"Misunderstanding_OneShot\"].values\n",
        "\n",
        "# Set hyperparameters and validation size\n",
        "validation_size=0.30 # Proportion of data used for validation\n",
        "batch_size= 32\n",
        "learning_rate=5e-5\n",
        "epochs=5\n",
        "\n",
        "# Run the classifier\n",
        "SML_NonIterative = supervised_classifier(texts=texts_NonIterative,true_scores=true_scores_NonIterative)\n",
        "SML_NonIterative.add_SML_params(validation_size=validation_size,\n",
        "                                batch_size=batch_size,\n",
        "                                learning_rate=learning_rate,\n",
        "                                epochs=epochs)\n",
        "# << Unhash below to train new model >>\n",
        "\n",
        "#SML_NonIterative.run_model()"
      ],
      "metadata": {
        "id": "ymNfTnn_MHaZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also see the Rule-based classifier terms:"
      ],
      "metadata": {
        "id": "rqr3RMs8Woi7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "One_shot_terms = St2Through[St2Through[\"Classifier\"] == \"rule-based\"]\n",
        "One_shot_terms = One_shot_terms[One_shot_terms[\"Order\"]==1]\n",
        "One_shot_terms.Terms.values[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "6mwEcVrvWqiv",
        "outputId": "f02ee0eb-53eb-49b0-f687-43fb3407d2fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'[\"mistook\",\"misunderstood\",\"misread\",\"wtf\",\"mistake\",\"response\",\"stumped\",\"uncertain\",\"restate\",\"revise\"]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "And the prompt used for the LLM classifier:"
      ],
      "metadata": {
        "id": "BwSUScpoWtM9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "One_shot_LLM = St2Through[St2Through[\"Classifier\"] == \"few-shot\"]\n",
        "One_shot_LLM = One_shot_LLM[One_shot_LLM[\"Order\"]==1]\n",
        "print(One_shot_LLM.role.values[0])\n",
        "print(One_shot_LLM.prompt.values[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qSZIsneQW39y",
        "outputId": "f6045669-915b-464c-8f53-ee73aaa9f43b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "You are a research assistant tasked with identifying whether a sentence indicates a misunderstanding\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Does the below sentence contain a misunderstanding?\n",
            "Only respond with \"Yes\" or \"No\"\n",
            "Sentence: {} \n",
            "Response:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.2.2 Output\n",
        "\n",
        "The below prints the classification reports and evaluation metrics for the non-iterative test data."
      ],
      "metadata": {
        "id": "DneDbUf3M5NB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fetch test data misunderstanding manual coding scores\n",
        "true_values_NonIterative = out_NonIterative[\"Misunderstanding_OneShot\"]"
      ],
      "metadata": {
        "id": "eHOodI3TNBFz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Test size for one-shot group: {len(out_NonIterative)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gcCj94fiNSIq",
        "outputId": "ce33608b-211e-4e30-eaeb-5e0a9515893b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test size for one-shot group: 6595\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Rule-based classification report:"
      ],
      "metadata": {
        "id": "1sJNSWSFXU1s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rule_based_NonIterative=  out_NonIterative[\"Rule_based_preds\"]\n",
        "get_model_report(true_values_NonIterative, rule_based_NonIterative)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "idt1H4ATXQ0x",
        "outputId": "e8fab916-72cf-4759-bc0e-5512eeca3106"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "true:6595,pred:6595\n",
            "AUC-PR: 0.06\n",
            "\n",
            "AUC-ROC: 0.51\n",
            "\n",
            "MCC: 0.03\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.97      0.99      0.98      6417\n",
            "         1.0       0.07      0.02      0.03       178\n",
            "\n",
            "    accuracy                           0.97      6595\n",
            "   macro avg       0.52      0.51      0.51      6595\n",
            "weighted avg       0.95      0.97      0.96      6595\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Supervised classification report"
      ],
      "metadata": {
        "id": "mOcYYHfvXWp9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "supervised_NonIterative =  out_NonIterative[\"SML_preds\"]\n",
        "get_model_report(true_values_NonIterative, supervised_NonIterative)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XGKa2Kb5XbEE",
        "outputId": "9a2a59d3-569f-4acd-c93f-c602a1d5b768"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "true:6595,pred:6595\n",
            "AUC-PR: 0.39\n",
            "\n",
            "AUC-ROC: 0.64\n",
            "\n",
            "MCC: 0.35\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.98      0.99      0.99      6417\n",
            "         1.0       0.46      0.30      0.36       178\n",
            "\n",
            "    accuracy                           0.97      6595\n",
            "   macro avg       0.72      0.64      0.67      6595\n",
            "weighted avg       0.97      0.97      0.97      6595\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LLM classification report:"
      ],
      "metadata": {
        "id": "j6LNLAu3Xbr3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LLM_NonIterative =  out_NonIterative[\"LLM_scores\"]\n",
        "get_model_report(true_values_NonIterative, LLM_NonIterative)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5PWj3407Xf-9",
        "outputId": "cb952711-2c48-4cc2-a549-79242449ad8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "true:6595,pred:6595\n",
            "AUC-PR: 0.16\n",
            "\n",
            "AUC-ROC: 0.47\n",
            "\n",
            "MCC: -0.02\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.97      0.66      0.79      6417\n",
            "         1.0       0.02      0.28      0.04       178\n",
            "\n",
            "    accuracy                           0.65      6595\n",
            "   macro avg       0.50      0.47      0.41      6595\n",
            "weighted avg       0.94      0.65      0.77      6595\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Conclusions\n",
        "\n",
        "For the RAMP method, the manual coding stage found acceptable inter-rater reliability (Krippendorff's Alpha = 0.79) following 5 training rounds; the classifier development stage found that the supervised  classifier is much better than either the LLM and rule-based classifiers. The supervised classifier's performance is acceptable (MCC = 0.69) with room for improvement. For the RAMP method's integrative evaluation stage, we found that the false negatives are missing some key clarification questions (e.g., \"So what about everyone else?\"). We also found that the classifiers are picking up on \"new information\" questions, not directed at another's perspeective (e.g., \"Are you having this issue with any other channels?\"). The misclassifications indicate that the classifier is generally struggling with edge cases more than explicit cases.\n",
        "\n",
        "When comparing the RAMP method with the non-iterative method, we found that the RAMP method performs better in both the manual coding and classifier development stages. We also found that the non-iterative manual coders found fewer instances of misunderstanding but, those they did find, were mostly identified by the RAMP coders.\n",
        "\n"
      ],
      "metadata": {
        "id": "VbMaI0IKk_0H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. References\n",
        "\n",
        "\n",
        "> Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J. D., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A., Agarwal, S., Herbert-Voss, A., Krueger, G., Henighan, T., Child, R., Ramesh, A., Ziegler, D., Wu, J., Winter, C., … Amodei, D. (2020). Language models are few-shot learners. Advances in Neural Information Processing Systems, 33, 1877–1901. https://proceedings.neurips.cc/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html\n",
        "\n",
        "> Danescu-Niculescu-Mizil, C., Lee, L., Pang, B., & Kleinberg, J. (2012). Echoes of power: Language effects and power differences in social interaction. Proceedings of the 21st International Conference on World Wide Web, 699–708. https://doi.org/10.1145/2187836.2187931\n",
        "\n",
        "> Devlin, J., Chang, M.-W., Lee, K., & Toutanova, K. (2019). BERT: Pre-training of deep bidirectional transformers for language understanding. Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), 4171–4186. https://doi.org/10.18653/v1/N19-1423\n",
        "\n",
        "> Honnibal, M., Montani, I., Van Landeghem, S., & Boyd, A. (2022). SpaCy: Industrial-Strength Natural Language Processing in Python. Explosion.\n",
        "\n",
        "> Korobov, M. (Presenter). (2017). Explaining behavior of Machine Learning models with eli5 library. EuroPython.\n",
        "\n",
        "> Korobov, M., & Lopuhin, K. (2024). eli5: Debug machine learning classifiers and explain their predictions (0.13.0) [Python; OS Independent]. https://github.com/eli5-org/eli5\n",
        "\n",
        "> Krippendorff, K. (1970). Estimating the reliability, systematic error and random error of interval data. Educational and Psychological Measurement, 30(1), 61–70. https://doi.org/10.1177/001316447003000105\n",
        "\n",
        "> Maiya, A. S. (2022). ktrain: A low-code library for augmented machine learning (arXiv:2004.10703). arXiv. https://doi.org/10.48550/arXiv.2004.10703\n",
        "\n",
        "> OpenAI, Achiam, J., Adler, S., Agarwal, S., Ahmad, L., Akkaya, I., Aleman, F. L., Almeida, D., Altenschmidt, J., Altman, S., Anadkat, S., Avila, R., Babuschkin, I., Balaji, S., Balcom, V., Baltescu, P., Bao, H., Bavarian, M., Belgum, J., … Zoph, B. (2024). GPT-4 Technical Report (arXiv:2303.08774). arXiv. https://doi.org/10.48550/arXiv.2303.08774\n",
        "\n",
        "> Pennebaker, J. W., Francis, M. E., & Booth, R. J. (2001). Linguistic Inquiry and Word Count: LIWC. Mahway: Lawrence Erlbaum Associates, 71(2001).\n",
        "\n",
        "> Ribeiro, M. T., Singh, S., & Guestrin, C. (2016). ‘Why should I trust you?’: Explaining the predictions of any classifier (arXiv:1602.04938). arXiv. https://doi.org/10.48550/arXiv.1602.04938\n",
        "\n",
        "> Shivan, B., & Chaitanya, A. (2024). textstat: Calculate statistical features from text (0.7.3) [Python]. https://github.com/shivam5992/textstat\n",
        "\n"
      ],
      "metadata": {
        "id": "bulsXEAaP83Z"
      }
    }
  ]
}